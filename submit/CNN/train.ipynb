{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3, 32, 32)\n",
      "(40000,)\n",
      "(10000, 3, 32, 32)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "import pickle\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 10000 # 반복 횟수를 적절히 설정한다.\n",
    "train_size = 40000  # 40000장은 train 10000장은 test\n",
    "batch_size = 400  \n",
    "learning_rate = 0.01\n",
    "RGB =3\n",
    "PIxEL = 32\n",
    "HIDDEN_SIZE =50\n",
    "OUTPUT_SIZE = 10\n",
    "\n",
    "title = 'CNN_ReLU__iters_num={}__batchSize_{}__learning_rate_{}__HIDDEN_SIZE ={}'.format(iters_num,batch_size,learning_rate,HIDDEN_SIZE)\n",
    "\n",
    "pickle_name = \"CIRFAR_10_CNN_32.pickle\"\n",
    "# 데이터 읽기 data = [50000, 2] one hot encoding 되어 있음 (data, label)\n",
    "with open(pickle_name,\"rb\") as fr:\n",
    "    data = pickle.load(fr)\n",
    "# 무작위로 섞는 부분\n",
    "data = pd.DataFrame(data)\n",
    "data = data.sample(frac=1, replace=False)\n",
    "# 다시 numpy 로 만들어준다.\n",
    "data = data.to_numpy()\n",
    "# label 과 data를 분리\n",
    "label = [x[1] for x in data]\n",
    "data = [x[0] for x in data]\n",
    "# normalize 하는 부분\n",
    "data = np.array(data, dtype='float64')\n",
    "label = np.array(label)\n",
    "x_train = data[:train_size]\n",
    "t_train = label[:train_size]\n",
    "x_test = data[train_size:]\n",
    "t_test = label[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2989430818558767\n",
      "=== epoch:1, train acc:0.094, test acc:0.098 ===\n",
      "train loss:2.300693144949424\n",
      "train loss:2.299235620174359\n",
      "train loss:2.2985830773900595\n",
      "train loss:2.298997296909322\n",
      "train loss:2.2920353470632633\n",
      "train loss:2.299027371668609\n",
      "train loss:2.3025793925211544\n",
      "train loss:2.3032798774740213\n",
      "train loss:2.2879179263405414\n",
      "train loss:2.281832456317407\n",
      "train loss:2.294991108396391\n",
      "train loss:2.288685522771307\n",
      "train loss:2.2978835067066354\n",
      "train loss:2.2786171514723055\n",
      "train loss:2.2869931685052247\n",
      "train loss:2.2559049483942415\n",
      "train loss:2.2531244107531325\n",
      "train loss:2.2836251937902845\n",
      "train loss:2.2387880446942416\n",
      "train loss:2.250505281770559\n",
      "train loss:2.277823533198191\n",
      "train loss:2.2161759810913715\n",
      "train loss:2.204072946455197\n",
      "train loss:2.1975479152710222\n",
      "train loss:2.212315835825299\n",
      "train loss:2.1383976760463392\n",
      "train loss:2.1680962130029973\n",
      "train loss:2.2665664185625114\n",
      "train loss:2.1804097928830104\n",
      "train loss:2.1604351531022425\n",
      "train loss:2.2016516101425907\n",
      "train loss:2.142902043696643\n",
      "train loss:2.1126372952883763\n",
      "train loss:2.0693732963288753\n",
      "train loss:2.136979444771071\n",
      "train loss:2.123085307881429\n",
      "train loss:2.0496347927789444\n",
      "train loss:2.0910773348623737\n",
      "train loss:2.018036390829961\n",
      "train loss:2.025785564207043\n",
      "train loss:1.9862918750415728\n",
      "train loss:1.9775321019693295\n",
      "train loss:2.055947829217678\n",
      "train loss:2.1132293417554493\n",
      "train loss:2.0378156100353237\n",
      "train loss:2.122384368741359\n",
      "train loss:1.9589770891934808\n",
      "train loss:2.09985959388529\n",
      "train loss:1.9708719741331557\n",
      "train loss:1.9566866799944131\n",
      "train loss:2.048122563472947\n",
      "train loss:2.0020248628411816\n",
      "train loss:1.976039002931017\n",
      "train loss:1.9954797722560513\n",
      "train loss:1.9708274914362764\n",
      "train loss:2.1248093733073152\n",
      "train loss:1.959407929421649\n",
      "train loss:2.033412355935248\n",
      "train loss:1.9731076720662342\n",
      "train loss:1.9008062231268559\n",
      "train loss:2.039258835129971\n",
      "train loss:1.9574720524046074\n",
      "train loss:1.9521409572954573\n",
      "train loss:2.1267837759722266\n",
      "train loss:2.0886404149112687\n",
      "train loss:1.9549631186403613\n",
      "train loss:1.9937665694885294\n",
      "train loss:2.089342936628648\n",
      "train loss:2.0717919951225627\n",
      "train loss:2.089995396015512\n",
      "train loss:2.007082032822038\n",
      "train loss:2.079637718148743\n",
      "train loss:1.9211666925576085\n",
      "train loss:1.9734711605109019\n",
      "train loss:1.9348722793751512\n",
      "train loss:1.9565429760258\n",
      "train loss:1.9682037355105158\n",
      "train loss:2.009274119544506\n",
      "train loss:2.0369003036296878\n",
      "train loss:2.017137801438529\n",
      "train loss:1.9705864856913815\n",
      "train loss:2.0378038300856\n",
      "train loss:1.9350476481288785\n",
      "train loss:1.8853248056079732\n",
      "train loss:1.8988709948124685\n",
      "train loss:1.9745436454061596\n",
      "train loss:1.9502003049497914\n",
      "train loss:1.8681520132264995\n",
      "train loss:1.8529442295534906\n",
      "train loss:1.9096018426994892\n",
      "train loss:1.9657527750970936\n",
      "train loss:1.9213129905990554\n",
      "train loss:1.877697502128225\n",
      "train loss:1.9375934640774681\n",
      "train loss:2.0060829268598384\n",
      "train loss:1.9380318155731526\n",
      "train loss:1.9591077755253605\n",
      "train loss:1.8560036218171416\n",
      "train loss:1.8905190946473533\n",
      "train loss:1.9873265565956344\n",
      "train loss:1.9295762872830762\n",
      "train loss:1.912253356591354\n",
      "train loss:1.9051033390544405\n",
      "train loss:1.846358885776977\n",
      "train loss:1.9505054975350355\n",
      "train loss:1.834911489523087\n",
      "train loss:1.9605519563341363\n",
      "train loss:1.9975667841481755\n",
      "train loss:1.8132698930656952\n",
      "train loss:1.970381458433913\n",
      "train loss:1.910961322090557\n",
      "train loss:1.9689283066589045\n",
      "train loss:1.9422372278685682\n",
      "train loss:1.8109477191585206\n",
      "train loss:1.9324750281172598\n",
      "train loss:1.8699420227589498\n",
      "train loss:1.820167842327804\n",
      "train loss:1.8102121494353085\n",
      "train loss:1.8719177631900032\n",
      "train loss:2.0924794189995297\n",
      "train loss:1.8412488382546188\n",
      "train loss:1.8723738936520669\n",
      "train loss:1.876180429119386\n",
      "train loss:1.899180563472882\n",
      "train loss:1.8639265187783642\n",
      "train loss:1.762343557056062\n",
      "train loss:1.8480278601028663\n",
      "train loss:1.7361274978777195\n",
      "train loss:1.8757592539513925\n",
      "train loss:1.8084213802416493\n",
      "train loss:1.8900290785225053\n",
      "train loss:1.7597595757578222\n",
      "train loss:1.9626685567065123\n",
      "train loss:1.7852475641230956\n",
      "train loss:1.8255201071726597\n",
      "train loss:1.7795228121458118\n",
      "train loss:1.7951471775294998\n",
      "train loss:1.8144727576754258\n",
      "train loss:1.8311707909383523\n",
      "train loss:1.856251872669085\n",
      "train loss:1.8171879038308552\n",
      "train loss:1.9073683821703877\n",
      "train loss:1.8612676731256708\n",
      "train loss:1.8361679024853101\n",
      "train loss:1.902279503958078\n",
      "train loss:1.856460256864122\n",
      "train loss:1.8929494575436268\n",
      "train loss:1.7548584439243038\n",
      "train loss:1.8695928683461411\n",
      "train loss:1.8117463543259773\n",
      "train loss:1.8864442836902457\n",
      "train loss:1.8482788720775676\n",
      "train loss:1.8342169779648847\n",
      "train loss:1.7700478968290758\n",
      "train loss:1.9522111381028486\n",
      "train loss:1.8632700807690554\n",
      "train loss:1.769616018163721\n",
      "train loss:1.7701940223473813\n",
      "train loss:1.738275723336463\n",
      "train loss:1.777391385237799\n",
      "train loss:1.8691605582971078\n",
      "train loss:1.6772739117540942\n",
      "train loss:1.7326288315540237\n",
      "train loss:1.9688055909319007\n",
      "train loss:1.6194670697795783\n",
      "train loss:1.7859440764839647\n",
      "train loss:1.8292401360345247\n",
      "train loss:1.8329817647955828\n",
      "train loss:1.7168444608141271\n",
      "train loss:1.7950930357777222\n",
      "train loss:1.8803713893081684\n",
      "train loss:1.7052435100339387\n",
      "train loss:1.776805174474991\n",
      "train loss:1.956832903070928\n",
      "train loss:1.921384060823312\n",
      "train loss:1.8117638040938595\n",
      "train loss:1.7915178825545022\n",
      "train loss:1.8405969636934818\n",
      "train loss:1.8245705770774978\n",
      "train loss:1.7767636849089519\n",
      "train loss:1.8062001311012705\n",
      "train loss:1.711972337438407\n",
      "train loss:1.7733479928825482\n",
      "train loss:1.7948032558906408\n",
      "train loss:1.8245925479150231\n",
      "train loss:1.6644634812908965\n",
      "train loss:1.8020582435026775\n",
      "train loss:1.7300673653867171\n",
      "train loss:1.7431193514068841\n",
      "train loss:1.7760144314775672\n",
      "train loss:1.7583986338749182\n",
      "train loss:1.7692401846287837\n",
      "train loss:1.7141501684482783\n",
      "train loss:1.8300418048107685\n",
      "train loss:1.833814715095999\n",
      "train loss:1.8187071209653212\n",
      "train loss:1.7307937260580104\n",
      "train loss:1.65978488689967\n",
      "train loss:1.7413885953957275\n",
      "train loss:1.7812831597441785\n",
      "train loss:1.8059080010372772\n",
      "train loss:1.8442355075184844\n",
      "train loss:1.659585893998216\n",
      "train loss:1.8992946151705257\n",
      "train loss:1.8387286009312198\n",
      "train loss:1.720114679907494\n",
      "train loss:1.9083008516298299\n",
      "train loss:1.6489019340429467\n",
      "train loss:1.823035774908286\n",
      "train loss:1.6381967406964266\n",
      "train loss:1.928980312401613\n",
      "train loss:1.6577542745212428\n",
      "train loss:1.7816081136160415\n",
      "train loss:1.6485295568784772\n",
      "train loss:1.7507945773004614\n",
      "train loss:1.7132792070881988\n",
      "train loss:1.662960535537074\n",
      "train loss:1.7832966136040875\n",
      "train loss:1.7436709109866921\n",
      "train loss:1.7609423352964166\n",
      "train loss:1.6888242615873037\n",
      "train loss:1.7289550894371488\n",
      "train loss:1.6548553716396182\n",
      "train loss:1.5529528981500136\n",
      "train loss:1.6391449539191203\n",
      "train loss:1.7233917487324901\n",
      "train loss:1.7851150518445578\n",
      "train loss:1.7333883328756645\n",
      "train loss:1.6994137114584462\n",
      "train loss:1.6220220799387162\n",
      "train loss:1.6700941378746688\n",
      "train loss:1.7393388276245623\n",
      "train loss:1.671672904763148\n",
      "train loss:1.6076310883894667\n",
      "train loss:1.7529463158369958\n",
      "train loss:1.8608295469810914\n",
      "train loss:1.7020176524231831\n",
      "train loss:1.7278437049996505\n",
      "train loss:1.7246438296332294\n",
      "train loss:1.8349939440744623\n",
      "train loss:1.6376902373877464\n",
      "train loss:1.5987536836839182\n",
      "train loss:1.6156589237208598\n",
      "train loss:1.697264033463535\n",
      "train loss:1.6038184261308948\n",
      "train loss:1.7262060217221056\n",
      "train loss:1.7302271852022455\n",
      "train loss:1.6165440788686578\n",
      "train loss:1.6388716551804823\n",
      "train loss:1.7003653316730205\n",
      "train loss:1.6395968909906327\n",
      "train loss:1.6481771514950563\n",
      "train loss:1.7839091683710464\n",
      "train loss:1.7342200433167927\n",
      "train loss:1.6376847706086577\n",
      "train loss:1.6881764189122195\n",
      "train loss:1.7030768315246616\n",
      "train loss:1.4796121659584798\n",
      "train loss:1.7535102866988397\n",
      "train loss:1.5196976843018006\n",
      "train loss:1.6253139093599753\n",
      "train loss:1.6389280747977415\n",
      "train loss:1.620565400692924\n",
      "train loss:1.643820167302642\n",
      "train loss:1.8354039710093684\n",
      "train loss:1.6622784925519962\n",
      "train loss:1.6578455509002747\n",
      "train loss:1.7019442822026454\n",
      "train loss:1.7445692787184348\n",
      "train loss:1.6058340310971841\n",
      "train loss:1.6428178386455283\n",
      "train loss:1.615228693033312\n",
      "train loss:1.7067387315324396\n",
      "train loss:1.6064482796503534\n",
      "train loss:1.710799825840308\n",
      "train loss:1.6288155064337784\n",
      "train loss:1.6913681768582622\n",
      "train loss:1.579656737691102\n",
      "train loss:1.6069435309816098\n",
      "train loss:1.602775158093124\n",
      "train loss:1.5929919334612248\n",
      "train loss:1.5797772617938233\n",
      "train loss:1.5235837718838767\n",
      "train loss:1.5602599155671515\n",
      "train loss:1.7259846990980654\n",
      "train loss:1.6266514404608947\n",
      "train loss:1.6920824490051216\n",
      "train loss:1.6905888469675352\n",
      "train loss:1.5270287143961765\n",
      "train loss:1.6249779038311067\n",
      "train loss:1.6735993929195396\n",
      "train loss:1.73792743167609\n",
      "train loss:1.5880313597682547\n",
      "train loss:1.733001632928427\n",
      "train loss:1.5012535912836362\n",
      "train loss:1.5255230196512883\n",
      "train loss:1.6015236056588538\n",
      "train loss:1.6329157858446985\n",
      "train loss:1.760864103096519\n",
      "train loss:1.71496855260064\n",
      "train loss:1.7024378894737353\n",
      "train loss:1.694331923854495\n",
      "train loss:1.6718510048312138\n",
      "train loss:1.5947332328691919\n",
      "train loss:1.6589852727033005\n",
      "train loss:1.6913205159078764\n",
      "train loss:1.6080653454664509\n",
      "train loss:1.7727796240855236\n",
      "train loss:1.5660945150372934\n",
      "train loss:1.7031792040240727\n",
      "train loss:1.572522926633728\n",
      "train loss:1.6841434758117935\n",
      "train loss:1.7401010331969693\n",
      "train loss:1.527716487212618\n",
      "train loss:1.6379440391512272\n",
      "train loss:1.5692918280588928\n",
      "train loss:1.6788631351104484\n",
      "train loss:1.7112682507410835\n",
      "train loss:1.4729928225383195\n",
      "train loss:1.6613781301278363\n",
      "train loss:1.6843164229322292\n",
      "train loss:1.5328403070905638\n",
      "train loss:1.7471297392321146\n",
      "train loss:1.845642871354826\n",
      "train loss:1.4769676578520392\n",
      "train loss:1.7161684984204841\n",
      "train loss:1.6940447983336842\n",
      "train loss:1.5112943544595492\n",
      "train loss:1.7552341504131994\n",
      "train loss:1.706826716608453\n",
      "train loss:1.4941392523375694\n",
      "train loss:1.704667579582332\n",
      "train loss:1.7527440285455467\n",
      "train loss:1.628876645575549\n",
      "train loss:1.5686862238540842\n",
      "train loss:1.6534202018602264\n",
      "train loss:1.5830393289878069\n",
      "train loss:1.6627769298108837\n",
      "train loss:1.5375304629735016\n",
      "train loss:1.6342165550084211\n",
      "train loss:1.575480348948032\n",
      "train loss:1.6645357471921658\n",
      "train loss:1.5743470649421412\n",
      "train loss:1.6069257851146812\n",
      "train loss:1.6864239701086567\n",
      "train loss:1.5602586333390616\n",
      "train loss:1.5664738205145752\n",
      "train loss:1.5471078900512603\n",
      "train loss:1.5294887474418772\n",
      "train loss:1.4707484164320086\n",
      "train loss:1.6373725805716768\n",
      "train loss:1.7672908504376401\n",
      "train loss:1.5033896466696468\n",
      "train loss:1.5237759064138672\n",
      "train loss:1.6013643549116576\n",
      "train loss:1.525723680659639\n",
      "train loss:1.6016657610257317\n",
      "train loss:1.7613058923489038\n",
      "train loss:1.6078946517061548\n",
      "train loss:1.6513222189552172\n",
      "train loss:1.5603587752739636\n",
      "train loss:1.5350800850410296\n",
      "train loss:1.61687973187038\n",
      "train loss:1.4617294652043762\n",
      "train loss:1.6436236127836217\n",
      "train loss:1.5395404061470919\n",
      "train loss:1.5807692928667634\n",
      "train loss:1.5739892491567449\n",
      "train loss:1.6874347404622523\n",
      "train loss:1.7197848725483873\n",
      "train loss:1.569078969530059\n",
      "train loss:1.5586847728575626\n",
      "train loss:1.706051899299853\n",
      "train loss:1.7167173292777058\n",
      "train loss:1.5864224103689382\n",
      "train loss:1.5994017647594025\n",
      "train loss:1.5757392699978356\n",
      "train loss:1.5830808563406285\n",
      "train loss:1.5370732404767276\n",
      "train loss:1.6463814955640321\n",
      "train loss:1.56627376883645\n",
      "train loss:1.6127624488694903\n",
      "train loss:1.4608621766918486\n",
      "train loss:1.5165817541159239\n",
      "train loss:1.5808593624800933\n",
      "train loss:1.6372550796470953\n",
      "train loss:1.4703971593304148\n",
      "train loss:1.5143211816715183\n",
      "train loss:1.474434779376645\n",
      "train loss:1.469940868849652\n",
      "train loss:1.6140768483180352\n",
      "train loss:1.6265690000146995\n",
      "train loss:1.5622674619285772\n",
      "train loss:1.6677961954601224\n",
      "train loss:1.7639555029761331\n",
      "train loss:1.6063796909238033\n",
      "train loss:1.5040514064918693\n",
      "train loss:1.712592778419266\n",
      "train loss:1.5083318605425908\n",
      "train loss:1.7260227742727077\n",
      "=== epoch:2, train acc:0.449, test acc:0.44 ===\n",
      "train loss:1.4517828468285714\n",
      "train loss:1.611092046099203\n",
      "train loss:1.7103877357363815\n",
      "train loss:1.335795501417014\n",
      "train loss:1.6999459071314045\n",
      "train loss:1.7080483640931123\n",
      "train loss:1.5714717435373922\n",
      "train loss:1.5635531555225939\n",
      "train loss:1.4523796894237373\n",
      "train loss:1.49826679476983\n",
      "train loss:1.519246474781175\n",
      "train loss:1.4652548939105992\n",
      "train loss:1.540546868813006\n",
      "train loss:1.6342635400682939\n",
      "train loss:1.4386651957625285\n",
      "train loss:1.6187112045321408\n",
      "train loss:1.5044094316440433\n",
      "train loss:1.6562487641776562\n",
      "train loss:1.4990855781165675\n",
      "train loss:1.4741846436881039\n",
      "train loss:1.522203807759341\n",
      "train loss:1.5210149476372337\n",
      "train loss:1.508920196728001\n",
      "train loss:1.5084296138534483\n",
      "train loss:1.5640778663247332\n",
      "train loss:1.7082337668944252\n",
      "train loss:1.6137432286899327\n",
      "train loss:1.747037141560197\n",
      "train loss:1.6845057936502241\n",
      "train loss:1.5066699427540733\n",
      "train loss:1.6566037645211265\n",
      "train loss:1.6036761329167222\n",
      "train loss:1.478344997669618\n",
      "train loss:1.4471002977875365\n",
      "train loss:1.486174378579222\n",
      "train loss:1.5614476839507674\n",
      "train loss:1.4089372855824636\n",
      "train loss:1.638741176120339\n",
      "train loss:1.4715534139871167\n",
      "train loss:1.527433999635073\n",
      "train loss:1.555052742172404\n",
      "train loss:1.3708868841956667\n",
      "train loss:1.6477329517684154\n",
      "train loss:1.5762576282069056\n",
      "train loss:1.3994411345871711\n",
      "train loss:1.53165548585824\n",
      "train loss:1.5323678435349908\n",
      "train loss:1.587335069493742\n",
      "train loss:1.504236762447039\n",
      "train loss:1.475964418587827\n",
      "train loss:1.6006680054020688\n",
      "train loss:1.3730539751843889\n",
      "train loss:1.4626045321961876\n",
      "train loss:1.6521927746990621\n",
      "train loss:1.5684527191384625\n",
      "train loss:1.4239523834183045\n",
      "train loss:1.3216742743878331\n",
      "train loss:1.4773699802083624\n",
      "train loss:1.523643543650837\n",
      "train loss:1.4539748156606243\n",
      "train loss:1.643561637086396\n",
      "train loss:1.4341984838864983\n",
      "train loss:1.4650546462604241\n",
      "train loss:1.5370607821303213\n",
      "train loss:1.351230452686495\n",
      "train loss:1.525394616260637\n",
      "train loss:1.5067709958968067\n",
      "train loss:1.486583409857239\n",
      "train loss:1.561247824209116\n",
      "train loss:1.5806197489980425\n",
      "train loss:1.7153508384711709\n",
      "train loss:1.495933197206937\n",
      "train loss:1.5826168698735976\n",
      "train loss:1.3943126885137704\n",
      "train loss:1.5459662138515278\n",
      "train loss:1.4185767511139833\n",
      "train loss:1.6494385958811921\n",
      "train loss:1.429068742151359\n",
      "train loss:1.580312210814187\n",
      "train loss:1.4726410086442527\n",
      "train loss:1.6317699028074955\n",
      "train loss:1.5851229369558493\n",
      "train loss:1.3708897868176724\n",
      "train loss:1.4584268621943721\n",
      "train loss:1.4548128158832532\n",
      "train loss:1.5320723592265368\n",
      "train loss:1.6409519737943736\n",
      "train loss:1.632730636471754\n",
      "train loss:1.5556215119036818\n",
      "train loss:1.639081543345084\n",
      "train loss:1.3967047344525576\n",
      "train loss:1.654514845253616\n",
      "train loss:1.5635819944683615\n",
      "train loss:1.348764711296966\n",
      "train loss:1.62703251063382\n",
      "train loss:1.5306030205920431\n",
      "train loss:1.641906449803575\n",
      "train loss:1.4835403126753384\n",
      "train loss:1.6377250667124377\n",
      "train loss:1.5674726638632024\n",
      "train loss:1.4357479477424948\n",
      "train loss:1.506033442663623\n",
      "train loss:1.5590338347739872\n",
      "train loss:1.3522612271762213\n",
      "train loss:1.5603562256204149\n",
      "train loss:1.569879684986768\n",
      "train loss:1.3538711522229483\n",
      "train loss:1.6590394637842956\n",
      "train loss:1.5000817610476969\n",
      "train loss:1.5426092108995335\n",
      "train loss:1.4065651437122282\n",
      "train loss:1.4564148505386445\n",
      "train loss:1.5973481170412647\n",
      "train loss:1.5130175352701607\n",
      "train loss:1.3586760641280688\n",
      "train loss:1.4778530988336143\n",
      "train loss:1.5799932668494097\n",
      "train loss:1.4975521117200135\n",
      "train loss:1.4876963914596244\n",
      "train loss:1.5445081304592765\n",
      "train loss:1.438691624466738\n",
      "train loss:1.348694974713907\n",
      "train loss:1.5023610563255034\n",
      "train loss:1.5916386769750748\n",
      "train loss:1.477191649267732\n",
      "train loss:1.6107272162368573\n",
      "train loss:1.4445182876943334\n",
      "train loss:1.6795405117055815\n",
      "train loss:1.6622864475451644\n",
      "train loss:1.4217331647152802\n",
      "train loss:1.4971301591251804\n",
      "train loss:1.5011070087110712\n",
      "train loss:1.473841659943002\n",
      "train loss:1.5667606698379344\n",
      "train loss:1.3728200429759283\n",
      "train loss:1.6235458229475084\n",
      "train loss:1.5955455509824754\n",
      "train loss:1.5040597049194417\n",
      "train loss:1.459350789229742\n",
      "train loss:1.4475581622927884\n",
      "train loss:1.3875886528077137\n",
      "train loss:1.5692586854136499\n",
      "train loss:1.5298818246003287\n",
      "train loss:1.382925837008074\n",
      "train loss:1.4806330792776814\n",
      "train loss:1.6048068335612709\n",
      "train loss:1.5058576848547849\n",
      "train loss:1.5775424818884074\n",
      "train loss:1.379644041481445\n",
      "train loss:1.5498209485569925\n",
      "train loss:1.4724850889158492\n",
      "train loss:1.40763731964987\n",
      "train loss:1.5254777842276648\n",
      "train loss:1.5660184682418299\n",
      "train loss:1.5861016931321053\n",
      "train loss:1.613887452775563\n",
      "train loss:1.5741476364565556\n",
      "train loss:1.4534397675837918\n",
      "train loss:1.5177067124187442\n",
      "train loss:1.4298865972132828\n",
      "train loss:1.4163831785984076\n",
      "train loss:1.6011348983069271\n",
      "train loss:1.5528305807790341\n",
      "train loss:1.4736489457763653\n",
      "train loss:1.521845088469185\n",
      "train loss:1.5640780808529249\n",
      "train loss:1.6804967239526056\n",
      "train loss:1.4360969449681853\n",
      "train loss:1.4208393734314655\n",
      "train loss:1.4889702976515435\n",
      "train loss:1.4416948007080936\n",
      "train loss:1.4469900080294673\n",
      "train loss:1.379529935749322\n",
      "train loss:1.6043886210957425\n",
      "train loss:1.4814203935886439\n",
      "train loss:1.4277585822448504\n",
      "train loss:1.4721370441476045\n",
      "train loss:1.5985990588890966\n",
      "train loss:1.4260919088328554\n",
      "train loss:1.5481453344459657\n",
      "train loss:1.4818293099525948\n",
      "train loss:1.416758753778921\n",
      "train loss:1.516619223871696\n",
      "train loss:1.402238696130587\n",
      "train loss:1.4639723615373523\n",
      "train loss:1.3267852625191288\n",
      "train loss:1.5169717156181854\n",
      "train loss:1.5406190770598445\n",
      "train loss:1.4237906371404625\n",
      "train loss:1.356546836490131\n",
      "train loss:1.6006154555147634\n",
      "train loss:1.4999792004920451\n",
      "train loss:1.435966253243742\n",
      "train loss:1.4930651363282414\n",
      "train loss:1.4879912460852642\n",
      "train loss:1.499762416105742\n",
      "train loss:1.4800141290660485\n",
      "train loss:1.4189508602460241\n",
      "train loss:1.3663077523004066\n",
      "train loss:1.6058996176031541\n",
      "train loss:1.5177276950117096\n",
      "train loss:1.3317125809728594\n",
      "train loss:1.6408052692459842\n",
      "train loss:1.5526556167348473\n",
      "train loss:1.4319674019782564\n",
      "train loss:1.5352643281797163\n",
      "train loss:1.2878025456039686\n",
      "train loss:1.5045908131355037\n",
      "train loss:1.5279951160476886\n",
      "train loss:1.3113998636509576\n",
      "train loss:1.4331435534845196\n",
      "train loss:1.4578236793957462\n",
      "train loss:1.4923624276652587\n",
      "train loss:1.3574982158609714\n",
      "train loss:1.2439029015115808\n",
      "train loss:1.4304666560244326\n",
      "train loss:1.3030685384464227\n",
      "train loss:1.379346274519638\n",
      "train loss:1.4144657708280262\n",
      "train loss:1.369060111485381\n",
      "train loss:1.6124922110134532\n",
      "train loss:1.5317341929873132\n",
      "train loss:1.4539599205369456\n",
      "train loss:1.5397231850053554\n",
      "train loss:1.5201597055882714\n",
      "train loss:1.240909232508297\n",
      "train loss:1.4714860919627992\n",
      "train loss:1.431593911207953\n",
      "train loss:1.486942288028429\n",
      "train loss:1.2973837229732683\n",
      "train loss:1.4252495186273852\n",
      "train loss:1.403155738586392\n",
      "train loss:1.4389730684085829\n",
      "train loss:1.62005256347659\n",
      "train loss:1.4869671212121884\n",
      "train loss:1.388106305932489\n",
      "train loss:1.3330130735080277\n",
      "train loss:1.4379575479066147\n",
      "train loss:1.4811662048197451\n",
      "train loss:1.4868917795866563\n",
      "train loss:1.4526436845273722\n",
      "train loss:1.4974985663952862\n",
      "train loss:1.4664935679832\n",
      "train loss:1.3986996329115902\n",
      "train loss:1.401574161776415\n",
      "train loss:1.3343865787321585\n",
      "train loss:1.596517622666581\n",
      "train loss:1.4260075202293996\n",
      "train loss:1.321940442714066\n",
      "train loss:1.3691200211071832\n",
      "train loss:1.3381200229104373\n",
      "train loss:1.3091978062615086\n",
      "train loss:1.470903847644023\n",
      "train loss:1.3889555286404323\n",
      "train loss:1.5060077420514497\n",
      "train loss:1.4551361730660504\n",
      "train loss:1.3294360478598821\n",
      "train loss:1.5151788730277267\n",
      "train loss:1.5642282598345207\n",
      "train loss:1.350904959140346\n",
      "train loss:1.2615300221222043\n",
      "train loss:1.4660817769738173\n",
      "train loss:1.4291886355379808\n",
      "train loss:1.4060409441122415\n",
      "train loss:1.5201280661734802\n",
      "train loss:1.586628089259313\n",
      "train loss:1.2405143499913143\n",
      "train loss:1.6815619373736466\n",
      "train loss:1.294421965715541\n",
      "train loss:1.3719724314537607\n",
      "train loss:1.4760169166189785\n",
      "train loss:1.3213574312115477\n",
      "train loss:1.5455579700498807\n",
      "train loss:1.5263287879657852\n",
      "train loss:1.385097019041257\n",
      "train loss:1.5256599543339238\n",
      "train loss:1.2383910061928367\n",
      "train loss:1.4614066695080894\n",
      "train loss:1.3865914839713036\n",
      "train loss:1.50190625923892\n",
      "train loss:1.4060034805318944\n",
      "train loss:1.4773737559456441\n",
      "train loss:1.3395901597498052\n",
      "train loss:1.2851371614964089\n",
      "train loss:1.3538005589653657\n",
      "train loss:1.3633789497285214\n",
      "train loss:1.5062393250553534\n",
      "train loss:1.6386773564060104\n",
      "train loss:1.4183871313877274\n",
      "train loss:1.5218687110667946\n",
      "train loss:1.3457706146178925\n",
      "train loss:1.499893740013636\n",
      "train loss:1.4532801220944997\n",
      "train loss:1.4919275041080844\n",
      "train loss:1.6614165165859638\n",
      "train loss:1.3353158768704885\n",
      "train loss:1.4124255353785642\n",
      "train loss:1.3409739843014987\n",
      "train loss:1.2506742233649957\n",
      "train loss:1.4149493695051674\n",
      "train loss:1.348512076336873\n",
      "train loss:1.4777696809048104\n",
      "train loss:1.4713598777140882\n",
      "train loss:1.4816028063291395\n",
      "train loss:1.3301557730714757\n",
      "train loss:1.5643116359110179\n",
      "train loss:1.2702997290581675\n",
      "train loss:1.5393766415083272\n",
      "train loss:1.3944706515202214\n",
      "train loss:1.2747506092329632\n",
      "train loss:1.5209535806134857\n",
      "train loss:1.3996965357192712\n",
      "train loss:1.5163730034928207\n",
      "train loss:1.3731371314967467\n",
      "train loss:1.1576911221925474\n",
      "train loss:1.5784125096117965\n",
      "train loss:1.2943550737620138\n",
      "train loss:1.4729143565017708\n",
      "train loss:1.273509385251919\n",
      "train loss:1.4727154578543227\n",
      "train loss:1.3004271499457873\n",
      "train loss:1.4436420956015583\n",
      "train loss:1.1660057619143451\n",
      "train loss:1.4567995165925902\n",
      "train loss:1.462047467134983\n",
      "train loss:1.4149948961442933\n",
      "train loss:1.4862173559971046\n",
      "train loss:1.4710706124993482\n",
      "train loss:1.5796018425230987\n",
      "train loss:1.2996897083146908\n",
      "train loss:1.3941889846855908\n",
      "train loss:1.4413506314866127\n",
      "train loss:1.3606309885129988\n",
      "train loss:1.4589764561809968\n",
      "train loss:1.2925849715919595\n",
      "train loss:1.6051264829101515\n",
      "train loss:1.4410407581839382\n",
      "train loss:1.5378149265655718\n",
      "train loss:1.3658854135481777\n",
      "train loss:1.452813536214386\n",
      "train loss:1.4717332870169988\n",
      "train loss:1.3646270431092256\n",
      "train loss:1.5829258456575386\n",
      "train loss:1.2961681725985372\n",
      "train loss:1.4409347022773247\n",
      "train loss:1.3731264828501732\n",
      "train loss:1.6202339167380055\n",
      "train loss:1.396748839445396\n",
      "train loss:1.4867028853917699\n",
      "train loss:1.467312829064371\n",
      "train loss:1.2785835615143626\n",
      "train loss:1.3270610738712\n",
      "train loss:1.3298421161535001\n",
      "train loss:1.436605225456193\n",
      "train loss:1.3587686036689426\n",
      "train loss:1.4786528101139509\n",
      "train loss:1.582488081788783\n",
      "train loss:1.3586440308259176\n",
      "train loss:1.2555006010529797\n",
      "train loss:1.3563459620640341\n",
      "train loss:1.49409706999188\n",
      "train loss:1.2764914972697858\n",
      "train loss:1.5886000612357105\n",
      "train loss:1.3750445609003408\n",
      "train loss:1.4131831150108911\n",
      "train loss:1.2978915794499115\n",
      "train loss:1.4598460068517654\n",
      "train loss:1.2725971663120843\n",
      "train loss:1.3346915809550186\n",
      "train loss:1.3668918779020793\n",
      "train loss:1.5381260314465535\n",
      "train loss:1.4085636006487205\n",
      "train loss:1.265510609119442\n",
      "train loss:1.4089205409323113\n",
      "train loss:1.3602631316777356\n",
      "train loss:1.2777648765065444\n",
      "train loss:1.420231319103903\n",
      "train loss:1.2919331656880368\n",
      "train loss:1.2794380723587742\n",
      "train loss:1.2555121573597123\n",
      "train loss:1.1830619846428172\n",
      "train loss:1.3686994177945784\n",
      "train loss:1.314168681247005\n",
      "train loss:1.5113835017761719\n",
      "train loss:1.301118965158526\n",
      "train loss:1.4038141317151045\n",
      "train loss:1.5122620546316279\n",
      "train loss:1.4380582782085267\n",
      "train loss:1.5470218232652453\n",
      "train loss:1.37553883172312\n",
      "train loss:1.6254730075355295\n",
      "train loss:1.4244045414978814\n",
      "train loss:1.390398956331134\n",
      "train loss:1.3830920831608544\n",
      "train loss:1.4865608523180176\n",
      "train loss:1.6225522114303264\n",
      "train loss:1.27457333722728\n",
      "train loss:1.409834613990141\n",
      "train loss:1.3477375454332243\n",
      "train loss:1.4498517083544027\n",
      "=== epoch:3, train acc:0.508, test acc:0.481 ===\n",
      "train loss:1.321652919911378\n",
      "train loss:1.3169594207873891\n",
      "train loss:1.4015339858413296\n",
      "train loss:1.4191133743576472\n",
      "train loss:1.3092487142228737\n",
      "train loss:1.3798225724133177\n",
      "train loss:1.3488864333893884\n",
      "train loss:1.3549913956259692\n",
      "train loss:1.3742857075469397\n",
      "train loss:1.4038047199047534\n",
      "train loss:1.4559287943068793\n",
      "train loss:1.4996366740938323\n",
      "train loss:1.4737706597678217\n",
      "train loss:1.5020123124413387\n",
      "train loss:1.3306748221190388\n",
      "train loss:1.4722734435030398\n",
      "train loss:1.277628280409177\n",
      "train loss:1.3068980221443776\n",
      "train loss:1.323460768704022\n",
      "train loss:1.514881647470082\n",
      "train loss:1.4248776828815017\n",
      "train loss:1.2861765753540422\n",
      "train loss:1.228939189799186\n",
      "train loss:1.4123736019683186\n",
      "train loss:1.253735531788783\n",
      "train loss:1.2931443652086074\n",
      "train loss:1.4795156589310352\n",
      "train loss:1.33290723799728\n",
      "train loss:1.4228635542788604\n",
      "train loss:1.3285580972958189\n",
      "train loss:1.4798948546667023\n",
      "train loss:1.3942154985083268\n",
      "train loss:1.2363954555352192\n",
      "train loss:1.459134209429501\n",
      "train loss:1.4298777295282423\n",
      "train loss:1.2888996356703637\n",
      "train loss:1.3594701754754814\n",
      "train loss:1.4340423303252248\n",
      "train loss:1.242030191441311\n",
      "train loss:1.5170922301217689\n",
      "train loss:1.4613595441272245\n",
      "train loss:1.5545867125733155\n",
      "train loss:1.5272710478759615\n",
      "train loss:1.2734891872389646\n",
      "train loss:1.3043614773203316\n",
      "train loss:1.385458830941017\n",
      "train loss:1.443982117912598\n",
      "train loss:1.40639515366649\n",
      "train loss:1.5087813433443586\n",
      "train loss:1.3736292654130373\n",
      "train loss:1.3252763284746587\n",
      "train loss:1.5794929278568128\n",
      "train loss:1.4903532975893423\n",
      "train loss:1.4453070363070526\n",
      "train loss:1.3528036517610638\n",
      "train loss:1.2740941750417725\n",
      "train loss:1.477766463450599\n",
      "train loss:1.3910821461620893\n",
      "train loss:1.4810720874798124\n",
      "train loss:1.3236644085815816\n",
      "train loss:1.2733608607076101\n",
      "train loss:1.5169720002568465\n",
      "train loss:1.3341136048673734\n",
      "train loss:1.2809403418342362\n",
      "train loss:1.452079350919739\n",
      "train loss:1.3016142880898038\n",
      "train loss:1.2524682548381112\n",
      "train loss:1.4182912183883598\n",
      "train loss:1.363922178255491\n",
      "train loss:1.3790061140142438\n",
      "train loss:1.4588582694464436\n",
      "train loss:1.292050372250186\n",
      "train loss:1.2359557731231614\n",
      "train loss:1.3894891070787019\n",
      "train loss:1.3396769951066472\n",
      "train loss:1.4122869698000755\n",
      "train loss:1.4467446940954358\n",
      "train loss:1.420092420162009\n",
      "train loss:1.5470321764980748\n",
      "train loss:1.3795792139184524\n",
      "train loss:1.3246642969049147\n",
      "train loss:1.4274455191057656\n",
      "train loss:1.4028140747245785\n",
      "train loss:1.331377275596052\n",
      "train loss:1.4048198086562016\n",
      "train loss:1.2480380013981172\n",
      "train loss:1.247849290523642\n",
      "train loss:1.2344668315746457\n",
      "train loss:1.5584171525430193\n",
      "train loss:1.348825237797041\n",
      "train loss:1.3593754368203677\n",
      "train loss:1.4481913709106604\n",
      "train loss:1.4104638353447012\n",
      "train loss:1.2883046263707627\n",
      "train loss:1.4198934130483145\n",
      "train loss:1.2471845217458983\n",
      "train loss:1.3863252835674025\n",
      "train loss:1.3814500253709485\n",
      "train loss:1.3322327969534515\n",
      "train loss:1.3197013474469492\n",
      "train loss:1.3494966589386772\n",
      "train loss:1.3151335361481515\n",
      "train loss:1.3939048125480484\n",
      "train loss:1.292278089842145\n",
      "train loss:1.386277142357511\n",
      "train loss:1.4221316736723861\n",
      "train loss:1.4187447268390434\n",
      "train loss:1.4283474636990194\n",
      "train loss:1.4333411848850854\n",
      "train loss:1.4088271155022083\n",
      "train loss:1.345880888813967\n",
      "train loss:1.5083238117618358\n",
      "train loss:1.5260734442522468\n",
      "train loss:1.4533070476240944\n",
      "train loss:1.3043541661885525\n",
      "train loss:1.5600154928099217\n",
      "train loss:1.3292388544641103\n",
      "train loss:1.240239911824507\n",
      "train loss:1.1893422362589103\n",
      "train loss:1.4512250130306905\n",
      "train loss:1.4237878325871351\n",
      "train loss:1.3574807617041948\n",
      "train loss:1.3204425390581214\n",
      "train loss:1.233383884219906\n",
      "train loss:1.2581874080705509\n",
      "train loss:1.376222866547388\n",
      "train loss:1.4654340504274952\n",
      "train loss:1.4626041549998843\n",
      "train loss:1.3368200177666416\n",
      "train loss:1.205925864081197\n",
      "train loss:1.4061091410401148\n",
      "train loss:1.4487572917344098\n",
      "train loss:1.311187730201911\n",
      "train loss:1.2882932361624975\n",
      "train loss:1.3536884797866702\n",
      "train loss:1.2025773514955596\n",
      "train loss:1.5280007300583134\n",
      "train loss:1.3156575959487233\n",
      "train loss:1.615780157219276\n",
      "train loss:1.4571680590496576\n",
      "train loss:1.3387164951869075\n",
      "train loss:1.457246602983466\n",
      "train loss:1.2655485106947162\n",
      "train loss:1.3986259336309705\n",
      "train loss:1.3955154631270852\n",
      "train loss:1.4214664015914207\n",
      "train loss:1.4319044116680981\n",
      "train loss:1.4260870311903566\n",
      "train loss:1.34617819844494\n",
      "train loss:1.3810270183201294\n",
      "train loss:1.3801035577175003\n",
      "train loss:1.3683920258232773\n",
      "train loss:1.270250677054027\n",
      "train loss:1.2550080979801304\n",
      "train loss:1.4189625259774121\n",
      "train loss:1.2949611463560404\n",
      "train loss:1.3304025140769433\n",
      "train loss:1.289213466230845\n",
      "train loss:1.3622911505714272\n",
      "train loss:1.1910321351742374\n",
      "train loss:1.4303303234266078\n",
      "train loss:1.3020981130145062\n",
      "train loss:1.272623402162133\n",
      "train loss:1.2244137369130164\n",
      "train loss:1.3597420154731839\n",
      "train loss:1.2260399354836669\n",
      "train loss:1.3017599947679344\n",
      "train loss:1.1980846324343157\n",
      "train loss:1.3119552985661658\n",
      "train loss:1.2186444307927307\n",
      "train loss:1.4585201097625213\n",
      "train loss:1.4469796176701935\n",
      "train loss:1.3260251038497863\n",
      "train loss:1.647898271060443\n",
      "train loss:1.3067850676217985\n",
      "train loss:1.224505648322486\n",
      "train loss:1.1927535171454782\n",
      "train loss:1.298916675406523\n",
      "train loss:1.3457385926451662\n",
      "train loss:1.4912004072743223\n",
      "train loss:1.3156504299856746\n",
      "train loss:1.0728374244342929\n",
      "train loss:1.313575467421846\n",
      "train loss:1.508894762259932\n",
      "train loss:1.4237413655957838\n",
      "train loss:1.245104002978438\n",
      "train loss:1.2497922344224952\n",
      "train loss:1.1950575839251516\n",
      "train loss:1.5314089762701306\n",
      "train loss:1.2850592452582341\n",
      "train loss:1.39630688147712\n",
      "train loss:1.4236567985288027\n",
      "train loss:1.3016634265288374\n",
      "train loss:1.2668380431262636\n",
      "train loss:1.3466745008585324\n",
      "train loss:1.3013402328612693\n",
      "train loss:1.304779123850098\n",
      "train loss:1.40162499335937\n",
      "train loss:1.2080109512616886\n",
      "train loss:1.4390539634101376\n",
      "train loss:1.4765391323011834\n",
      "train loss:1.3379375557202713\n",
      "train loss:1.3328471484695938\n",
      "train loss:1.5792500733246653\n",
      "train loss:1.238928030809317\n",
      "train loss:1.4027757797286051\n",
      "train loss:1.439942947332013\n",
      "train loss:1.3140890884334535\n",
      "train loss:1.436760475889237\n",
      "train loss:1.4077527415386533\n",
      "train loss:1.4785473942388507\n",
      "train loss:1.634680616109513\n",
      "train loss:1.3079266210944227\n",
      "train loss:1.361180762529372\n",
      "train loss:1.3248880456221\n",
      "train loss:1.1681266219907607\n",
      "train loss:1.3264106239323061\n",
      "train loss:1.0674243983850598\n",
      "train loss:1.4332529799343054\n",
      "train loss:1.3640047278694083\n",
      "train loss:1.349679037231804\n",
      "train loss:1.305240830385346\n",
      "train loss:1.3220477675956612\n",
      "train loss:1.3030783831979718\n",
      "train loss:1.2165109803837357\n",
      "train loss:1.4041759970367775\n",
      "train loss:1.2794104980538927\n",
      "train loss:1.210905935648008\n",
      "train loss:1.4413201594667533\n",
      "train loss:1.2891587407104288\n",
      "train loss:1.3666111347626562\n",
      "train loss:1.1535786103832364\n",
      "train loss:1.4993252730191688\n",
      "train loss:1.3561092868716538\n",
      "train loss:1.3066189808183484\n",
      "train loss:1.3602575783264095\n",
      "train loss:1.237967890494595\n",
      "train loss:1.3503257617960929\n",
      "train loss:1.3814556810137584\n",
      "train loss:1.1261691198687347\n",
      "train loss:1.4304805998557546\n",
      "train loss:1.281986122681645\n",
      "train loss:1.180295292698494\n",
      "train loss:1.2980699826811406\n",
      "train loss:1.568135466152167\n",
      "train loss:1.4008138136988117\n",
      "train loss:1.2150545352886208\n",
      "train loss:1.2856254213753429\n",
      "train loss:1.3863330603963016\n",
      "train loss:1.1404797382740532\n",
      "train loss:1.2258865166370643\n",
      "train loss:1.1472390340008098\n",
      "train loss:1.3101765759663826\n",
      "train loss:1.151959957027033\n",
      "train loss:1.3638154777707323\n",
      "train loss:1.2647522479367692\n",
      "train loss:1.3773624355514653\n",
      "train loss:1.3847446506981236\n",
      "train loss:1.4950712824096926\n",
      "train loss:1.3987503909778922\n",
      "train loss:1.2865458238450724\n",
      "train loss:1.378243915631788\n",
      "train loss:1.3157831638243511\n",
      "train loss:1.5012790202148685\n",
      "train loss:1.4204664231385535\n",
      "train loss:1.2795118967521923\n",
      "train loss:1.292115693720784\n",
      "train loss:1.1342842355708995\n",
      "train loss:1.4231579351329744\n",
      "train loss:1.3900353259458473\n",
      "train loss:1.3475399580103002\n",
      "train loss:1.411571181738435\n",
      "train loss:1.287175215101652\n",
      "train loss:1.446964183100364\n",
      "train loss:1.3294043978527441\n",
      "train loss:1.1691612799130673\n",
      "train loss:1.3381655160307688\n",
      "train loss:1.2142766081562615\n",
      "train loss:1.4045278467443998\n",
      "train loss:1.3573561452901717\n",
      "train loss:1.146986828848339\n",
      "train loss:1.347430730260983\n",
      "train loss:1.2664696037700056\n",
      "train loss:1.168594248703326\n",
      "train loss:1.2548347225812309\n",
      "train loss:1.3162071896739076\n",
      "train loss:1.2993989716545244\n",
      "train loss:1.361963967865964\n",
      "train loss:1.2978589087461656\n",
      "train loss:1.5200187040410942\n",
      "train loss:1.3291343484627003\n",
      "train loss:1.2444424113254593\n",
      "train loss:1.287239310778817\n",
      "train loss:1.2524862740305318\n",
      "train loss:1.3312021671937244\n",
      "train loss:1.5460294006503605\n",
      "train loss:1.2534527056966385\n",
      "train loss:1.2471658114318556\n",
      "train loss:1.2900151748635673\n",
      "train loss:1.3118527175649017\n",
      "train loss:1.3025924877768824\n",
      "train loss:1.2457032519293139\n",
      "train loss:1.3057735885660071\n",
      "train loss:1.2445141443838124\n",
      "train loss:1.4202546517203785\n",
      "train loss:1.4309852784099015\n",
      "train loss:1.5622598541211103\n",
      "train loss:1.468619712803491\n",
      "train loss:1.2715106531966065\n",
      "train loss:1.178297064090833\n",
      "train loss:1.440484645564937\n",
      "train loss:1.5797192818172894\n",
      "train loss:1.2165119125094261\n",
      "train loss:1.3942852737499416\n",
      "train loss:1.2895103144569422\n",
      "train loss:1.2856141993169568\n",
      "train loss:1.3097186499127662\n",
      "train loss:1.3954862148843297\n",
      "train loss:1.3300565842729808\n",
      "train loss:1.1698000413981524\n",
      "train loss:1.3864639828811076\n",
      "train loss:1.4789886258701892\n",
      "train loss:1.3223551211204887\n",
      "train loss:1.3268251324665676\n",
      "train loss:1.4033896790534108\n",
      "train loss:1.4082985244396216\n",
      "train loss:1.216324055074175\n",
      "train loss:1.4608042698132204\n",
      "train loss:1.3436171360127616\n",
      "train loss:1.3124604088566756\n",
      "train loss:1.316249082979005\n",
      "train loss:1.4162195618597822\n",
      "train loss:1.3991111328871784\n",
      "train loss:1.459350779023686\n",
      "train loss:1.4557312562609641\n",
      "train loss:1.4720029095799563\n",
      "train loss:1.3769243250396346\n",
      "train loss:1.5885999637218757\n",
      "train loss:1.3427656242030368\n",
      "train loss:1.2572729205859774\n",
      "train loss:1.4136430306905814\n",
      "train loss:1.4873809237167694\n",
      "train loss:1.1638188975654342\n",
      "train loss:1.347090048221134\n",
      "train loss:1.2471870302438584\n",
      "train loss:1.2114841306102375\n",
      "train loss:1.3450181447668907\n",
      "train loss:1.3242499432400265\n",
      "train loss:1.3291674033449357\n",
      "train loss:1.235210939859451\n",
      "train loss:1.3225978366577131\n",
      "train loss:1.3327318061347557\n",
      "train loss:1.3089919528441498\n",
      "train loss:1.2709983349097371\n",
      "train loss:1.3157099057755\n",
      "train loss:1.53708916949267\n",
      "train loss:1.2689283102956825\n",
      "train loss:1.2066811607543917\n",
      "train loss:1.0983861972828117\n",
      "train loss:1.304012948464071\n",
      "train loss:1.1724175934960184\n",
      "train loss:1.3928071284702552\n",
      "train loss:1.1140486948122201\n",
      "train loss:1.226257550364074\n",
      "train loss:1.2993049433195563\n",
      "train loss:1.3814792728050174\n",
      "train loss:1.4560274420827213\n",
      "train loss:1.2706280838119162\n",
      "train loss:1.1721874048406289\n",
      "train loss:1.2135770982589837\n",
      "train loss:1.2849726163982933\n",
      "train loss:1.3404523331876326\n",
      "train loss:1.1950148393134379\n",
      "train loss:1.3458543921708244\n",
      "train loss:1.2985035151428526\n",
      "train loss:1.3865574483597864\n",
      "train loss:1.2602542172777378\n",
      "train loss:1.3752881955988365\n",
      "train loss:1.4300302015653914\n",
      "train loss:1.2608145750244768\n",
      "train loss:1.4242331593373936\n",
      "train loss:1.2251047151505927\n",
      "train loss:1.2235378537481523\n",
      "train loss:1.3123429703382938\n",
      "train loss:1.3993567155380644\n",
      "train loss:1.2751548900621934\n",
      "train loss:1.445050809651625\n",
      "train loss:1.3777538697558285\n",
      "train loss:1.467499020258246\n",
      "train loss:1.4186123106723636\n",
      "train loss:1.2184143002121313\n",
      "train loss:1.417280885994391\n",
      "train loss:1.1411729978006655\n",
      "train loss:1.2259489406016622\n",
      "train loss:1.316600181591084\n",
      "train loss:1.4588641747240145\n",
      "train loss:1.4691171251413806\n",
      "train loss:1.21574814932146\n",
      "train loss:1.210732384905898\n",
      "train loss:1.1450862664909855\n",
      "=== epoch:4, train acc:0.537, test acc:0.507 ===\n",
      "train loss:1.1557268294271161\n",
      "train loss:1.354643088654742\n",
      "train loss:1.1363061955224385\n",
      "train loss:1.3201688064274646\n",
      "train loss:1.3212888207126385\n",
      "train loss:1.4199542381872527\n",
      "train loss:1.3088502647029288\n",
      "train loss:1.34730841047375\n",
      "train loss:1.2294926598336393\n",
      "train loss:1.2260524607675134\n",
      "train loss:1.2284834543729388\n",
      "train loss:1.2622220648231153\n",
      "train loss:1.3742130932548742\n",
      "train loss:1.3500886938765273\n",
      "train loss:1.2868532189077222\n",
      "train loss:1.3676434082814697\n",
      "train loss:1.335784784193776\n",
      "train loss:1.2097642971719609\n",
      "train loss:1.2957687887877072\n",
      "train loss:1.2680187763026987\n",
      "train loss:1.241912233870944\n",
      "train loss:1.4123958929013605\n",
      "train loss:1.3890389002713417\n",
      "train loss:1.4749494917730757\n",
      "train loss:1.2716219315997492\n",
      "train loss:1.3778417734583897\n",
      "train loss:1.3572759380951813\n",
      "train loss:1.1690142305127458\n",
      "train loss:1.2230641569178198\n",
      "train loss:1.451380553127394\n",
      "train loss:1.3273570057486057\n",
      "train loss:1.3589310852208625\n",
      "train loss:1.3820286015677588\n",
      "train loss:1.3074508055909804\n",
      "train loss:1.3367618382533804\n",
      "train loss:1.2465316855644504\n",
      "train loss:1.384906083796909\n",
      "train loss:1.256829172157052\n",
      "train loss:1.2970461086195826\n",
      "train loss:1.2068163321290843\n",
      "train loss:1.4301623051705008\n",
      "train loss:1.3289392846503447\n",
      "train loss:1.2750145558038202\n",
      "train loss:1.2980708500120854\n",
      "train loss:1.234839421523523\n",
      "train loss:1.2265648989069806\n",
      "train loss:1.1856421394959993\n",
      "train loss:1.2710905652824451\n",
      "train loss:1.3697846747958229\n",
      "train loss:1.1736833518285454\n",
      "train loss:1.1709981062877461\n",
      "train loss:1.3038837567015964\n",
      "train loss:1.3354741656636504\n",
      "train loss:1.2068976498851978\n",
      "train loss:1.3293115329084524\n",
      "train loss:1.2439424844650993\n",
      "train loss:1.233762148320618\n",
      "train loss:1.307211108892531\n",
      "train loss:1.290144152026107\n",
      "train loss:1.2757561837498532\n",
      "train loss:1.30953598963975\n",
      "train loss:1.309979870837932\n",
      "train loss:1.3025036213525119\n",
      "train loss:1.3325365688343482\n",
      "train loss:1.2090314271524045\n",
      "train loss:1.280911098755908\n",
      "train loss:1.3001492029326502\n",
      "train loss:1.291763790831177\n",
      "train loss:1.264134872699316\n",
      "train loss:1.3150142121575346\n",
      "train loss:1.053832469766342\n",
      "train loss:1.3008361622556712\n",
      "train loss:1.2613819222440454\n",
      "train loss:1.249904024407321\n",
      "train loss:1.1611580379379702\n",
      "train loss:1.2362287350388723\n",
      "train loss:1.3413116291583043\n",
      "train loss:1.5260795805830332\n",
      "train loss:1.4970291706562864\n",
      "train loss:1.4219690579441902\n",
      "train loss:1.177663175710398\n",
      "train loss:1.2925976125249408\n",
      "train loss:1.2755348154706343\n",
      "train loss:1.3488522972872632\n",
      "train loss:1.2777927442153534\n",
      "train loss:1.3117987097763464\n",
      "train loss:1.2752013145392673\n",
      "train loss:1.3873518319768643\n",
      "train loss:1.1467075702738443\n",
      "train loss:1.24212575447094\n",
      "train loss:1.1661960505271922\n",
      "train loss:1.3015601937865426\n",
      "train loss:1.4078041956036562\n",
      "train loss:1.365004854579791\n",
      "train loss:1.3030249705920918\n",
      "train loss:1.2046295250901315\n",
      "train loss:1.5774842359287715\n",
      "train loss:1.3666778081540085\n",
      "train loss:1.38868574843684\n",
      "train loss:1.4160900261101421\n",
      "train loss:1.2237370272643777\n",
      "train loss:1.313815295426553\n",
      "train loss:1.233663140409258\n",
      "train loss:1.1985876429514495\n",
      "train loss:1.2068567571806774\n",
      "train loss:1.239978564739519\n",
      "train loss:1.3330505034391746\n",
      "train loss:1.2966833454403635\n",
      "train loss:1.2175677715231525\n",
      "train loss:1.2539057741199107\n",
      "train loss:1.2043912954979716\n",
      "train loss:1.1897951071165007\n",
      "train loss:1.4038545783362972\n",
      "train loss:1.1545792484267003\n",
      "train loss:1.4146733054335587\n",
      "train loss:1.3917043442705777\n",
      "train loss:1.1465708762443707\n",
      "train loss:1.0790876137225929\n",
      "train loss:1.1141904263869034\n",
      "train loss:1.2683662967477713\n",
      "train loss:1.1880082531921337\n",
      "train loss:1.035467633136718\n",
      "train loss:1.365925190330766\n",
      "train loss:1.1767959040125093\n",
      "train loss:1.2336080805651597\n",
      "train loss:1.1514051225790707\n",
      "train loss:1.3255345863097616\n",
      "train loss:1.292754837855511\n",
      "train loss:1.2561914312919629\n",
      "train loss:1.2128963957531498\n",
      "train loss:1.231579641918231\n",
      "train loss:1.3908123410166464\n",
      "train loss:1.2267590936518904\n",
      "train loss:1.1257404217763354\n",
      "train loss:1.3003138267376833\n",
      "train loss:1.1925606712310128\n",
      "train loss:1.2314858497952783\n",
      "train loss:1.1468096346567607\n",
      "train loss:1.358684012903246\n",
      "train loss:1.2941337746534964\n",
      "train loss:1.2406260345648734\n",
      "train loss:1.2410871603753315\n",
      "train loss:1.1562980287250115\n",
      "train loss:1.2280085768462516\n",
      "train loss:1.313973031012786\n",
      "train loss:1.198895194486596\n",
      "train loss:1.2547126345411166\n",
      "train loss:1.373669107575501\n",
      "train loss:1.4910023403975716\n",
      "train loss:1.311936124144584\n",
      "train loss:1.1938751175154312\n",
      "train loss:1.3722432061047711\n",
      "train loss:1.2522796927486353\n",
      "train loss:1.3697558461332384\n",
      "train loss:1.2188062723386945\n",
      "train loss:1.459417790568189\n",
      "train loss:1.3596344135850003\n",
      "train loss:1.2580025757652047\n",
      "train loss:1.3148577804672286\n",
      "train loss:1.0433366423172898\n",
      "train loss:1.2369509770757185\n",
      "train loss:1.238462602363963\n",
      "train loss:1.265250931131479\n",
      "train loss:1.293946904072991\n",
      "train loss:1.0788268089505635\n",
      "train loss:1.2600237978682995\n",
      "train loss:1.2482224055242797\n",
      "train loss:1.1331924139344853\n",
      "train loss:1.3270566107297637\n",
      "train loss:1.162252041607737\n",
      "train loss:1.1132508684664746\n",
      "train loss:1.2067111211816302\n",
      "train loss:1.1181603808778993\n",
      "train loss:1.1479463178075973\n",
      "train loss:1.1042119860998219\n",
      "train loss:1.373621287124661\n",
      "train loss:1.4219379199397364\n",
      "train loss:1.249633838550121\n",
      "train loss:1.2168892913445581\n",
      "train loss:1.3820887692663861\n",
      "train loss:1.307953669366567\n",
      "train loss:1.159700878846685\n",
      "train loss:1.4305580509516869\n",
      "train loss:1.2212294897459266\n",
      "train loss:1.4317396046267883\n",
      "train loss:1.1918025146440072\n",
      "train loss:1.1774999211509773\n",
      "train loss:1.4001831278634194\n",
      "train loss:1.1707600657229436\n",
      "train loss:1.3141837216731518\n",
      "train loss:1.3107937939110477\n",
      "train loss:1.3086882535634419\n",
      "train loss:1.2281884824400628\n",
      "train loss:1.3226134385480888\n",
      "train loss:1.329328172252722\n",
      "train loss:1.2661823892600614\n",
      "train loss:1.2745170173260567\n",
      "train loss:1.1012000698149726\n",
      "train loss:1.3883220527389002\n",
      "train loss:1.2682637875100817\n",
      "train loss:1.1757768975170055\n",
      "train loss:1.1467298330415128\n",
      "train loss:1.2702886889010798\n",
      "train loss:1.1682642518100865\n",
      "train loss:1.2957394876389408\n",
      "train loss:1.1572081999697705\n",
      "train loss:1.2272093062767278\n",
      "train loss:1.1603977868171083\n",
      "train loss:1.5234941648815774\n",
      "train loss:1.2848937352429362\n",
      "train loss:1.305444220414589\n",
      "train loss:1.259389850548955\n",
      "train loss:1.2516823588311699\n",
      "train loss:1.1504737584403413\n",
      "train loss:1.3916489198483253\n",
      "train loss:1.334773107634295\n",
      "train loss:1.2797732066163712\n",
      "train loss:1.2688737616002492\n",
      "train loss:1.0584859906636654\n",
      "train loss:1.189480098388247\n",
      "train loss:1.2824494675101052\n",
      "train loss:1.3403016752562755\n",
      "train loss:1.250318983341125\n",
      "train loss:1.1662692651963342\n",
      "train loss:1.169221483986994\n",
      "train loss:1.261391652921236\n",
      "train loss:1.330615509379051\n",
      "train loss:1.2299348619565742\n",
      "train loss:1.2059861996137322\n",
      "train loss:1.27600492258289\n",
      "train loss:1.3156290369250143\n",
      "train loss:1.425752693862681\n",
      "train loss:1.3578447499111577\n",
      "train loss:1.2009843510911873\n",
      "train loss:1.5298407567892252\n",
      "train loss:1.2503324414489134\n",
      "train loss:1.3563685007451565\n",
      "train loss:1.1512678644749952\n",
      "train loss:1.3543703898465957\n",
      "train loss:1.240564471047032\n",
      "train loss:1.356584391285863\n",
      "train loss:1.2256464671372922\n",
      "train loss:1.3052726854268013\n",
      "train loss:1.1662678960298016\n",
      "train loss:1.336337040534623\n",
      "train loss:1.244801326190128\n",
      "train loss:1.272520291705502\n",
      "train loss:1.3221931215153306\n",
      "train loss:1.3440456727881773\n",
      "train loss:1.2835809909069373\n",
      "train loss:1.2496353113863152\n",
      "train loss:1.287906382737066\n",
      "train loss:1.2971276156774778\n",
      "train loss:1.1028694988737333\n",
      "train loss:1.146706003862992\n",
      "train loss:1.232147755581547\n",
      "train loss:1.1655445567990352\n",
      "train loss:1.0714329250157832\n",
      "train loss:1.2127259375530737\n",
      "train loss:1.2510197643767915\n",
      "train loss:1.3727859830937397\n",
      "train loss:1.1393882042686312\n",
      "train loss:1.2551343109076938\n",
      "train loss:1.1073285831330641\n",
      "train loss:1.2449799917958568\n",
      "train loss:1.2825703235936512\n",
      "train loss:1.1423089773716868\n",
      "train loss:1.3425428153276895\n",
      "train loss:1.1823715165437847\n",
      "train loss:1.3629059599470812\n",
      "train loss:1.1131230239978365\n",
      "train loss:1.2614217359113171\n",
      "train loss:1.135482145677048\n",
      "train loss:1.4170874706298349\n",
      "train loss:1.1848071272705394\n",
      "train loss:1.16987098149963\n",
      "train loss:1.3412252848539918\n",
      "train loss:1.2170787868430581\n",
      "train loss:1.2623854340198315\n",
      "train loss:1.1748748989539401\n",
      "train loss:1.2941727162458625\n",
      "train loss:1.2957182594384218\n",
      "train loss:1.1414295271019845\n",
      "train loss:1.2288697003976867\n",
      "train loss:1.1169395337207326\n",
      "train loss:1.495310882279528\n",
      "train loss:1.4787442369696633\n",
      "train loss:1.32153881471291\n",
      "train loss:1.472666696175797\n",
      "train loss:1.4754743977794416\n",
      "train loss:1.28607718889744\n",
      "train loss:1.3607959100353968\n",
      "train loss:1.310208255605821\n",
      "train loss:1.312720328044128\n",
      "train loss:1.2539729367319135\n",
      "train loss:1.1516181931495053\n",
      "train loss:1.1587140495238537\n",
      "train loss:1.2611535407786025\n",
      "train loss:1.1931539262849422\n",
      "train loss:1.1725717633238355\n",
      "train loss:1.2185920716243912\n",
      "train loss:1.338607205967094\n",
      "train loss:1.2055432960738692\n",
      "train loss:1.1620902235484385\n",
      "train loss:1.2329235338417297\n",
      "train loss:1.2072949966653008\n",
      "train loss:1.306141616913886\n",
      "train loss:1.2940278381223091\n",
      "train loss:1.0174873519800895\n",
      "train loss:1.217414047732215\n",
      "train loss:1.178480042166622\n",
      "train loss:1.09372862034848\n",
      "train loss:1.147112754426904\n",
      "train loss:1.1604923239236131\n",
      "train loss:1.2421745567310232\n",
      "train loss:1.1889994420164076\n",
      "train loss:1.3941393023613184\n",
      "train loss:1.119472819490967\n",
      "train loss:1.2066669139484794\n",
      "train loss:1.3886267885546408\n",
      "train loss:1.36387047348601\n",
      "train loss:1.298450336962571\n",
      "train loss:1.2087450062024192\n",
      "train loss:1.318318772116782\n",
      "train loss:1.2027923653160069\n",
      "train loss:1.1495213128420323\n",
      "train loss:1.296201550694236\n",
      "train loss:1.2389986155217054\n",
      "train loss:1.231959476886271\n",
      "train loss:1.1744750523441745\n",
      "train loss:1.0733705702180483\n",
      "train loss:1.1640219592827679\n",
      "train loss:1.107218350679204\n",
      "train loss:1.1880786441047584\n",
      "train loss:1.1954914317834335\n",
      "train loss:1.2029481942383156\n",
      "train loss:1.1971198833857841\n",
      "train loss:1.2431200793403538\n",
      "train loss:1.352749739054853\n",
      "train loss:1.1627088567591946\n",
      "train loss:1.2711237751003868\n",
      "train loss:1.1601195334622063\n",
      "train loss:1.2379575457446206\n",
      "train loss:1.1883491849249728\n",
      "train loss:1.0938657621275616\n",
      "train loss:1.1092820088292847\n",
      "train loss:1.4056871209566497\n",
      "train loss:1.3096126177105025\n",
      "train loss:1.2502485579498375\n",
      "train loss:1.1120746305809923\n",
      "train loss:1.294140750783081\n",
      "train loss:1.3514459249516628\n",
      "train loss:1.0151451257861779\n",
      "train loss:1.0267587246972232\n",
      "train loss:1.3217496696760145\n",
      "train loss:1.285110901801021\n",
      "train loss:1.3739081680123146\n",
      "train loss:1.2233158513996942\n",
      "train loss:1.313051894792859\n",
      "train loss:1.1913350502340838\n",
      "train loss:1.1453742521395696\n",
      "train loss:1.2743872417909197\n",
      "train loss:1.1136804815198271\n",
      "train loss:0.9991260452965242\n",
      "train loss:1.3164791902507305\n",
      "train loss:1.1775174485966005\n",
      "train loss:1.015762991105335\n",
      "train loss:1.2642914328625436\n",
      "train loss:1.171490288455977\n",
      "train loss:1.2933382403107556\n",
      "train loss:1.140433632867888\n",
      "train loss:1.2015420203122964\n",
      "train loss:1.2473123644343935\n",
      "train loss:1.299046502104387\n",
      "train loss:1.5021935137045808\n",
      "train loss:1.365606611267892\n",
      "train loss:1.3329655265267826\n",
      "train loss:1.3779185473964697\n",
      "train loss:1.1481198035652058\n",
      "train loss:1.0960255645394228\n",
      "train loss:1.18425881309824\n",
      "train loss:1.264952267128757\n",
      "train loss:1.3381080058780495\n",
      "train loss:1.412882090885625\n",
      "train loss:1.2075008537871978\n",
      "train loss:1.2747423170692722\n",
      "train loss:1.306987458058833\n",
      "train loss:1.1102809062066799\n",
      "train loss:1.2558457575619115\n",
      "train loss:1.2817756318503641\n",
      "train loss:1.3757203379887761\n",
      "train loss:1.335157104296952\n",
      "train loss:1.380950514569241\n",
      "train loss:1.2858930229307928\n",
      "train loss:1.3231027796923294\n",
      "train loss:1.2011421814021217\n",
      "train loss:1.1986238862422043\n",
      "train loss:1.219138337504174\n",
      "train loss:1.1862492548341341\n",
      "train loss:1.0093811651826488\n",
      "=== epoch:5, train acc:0.57, test acc:0.541 ===\n",
      "train loss:1.3162187232993394\n",
      "train loss:1.1974802635954171\n",
      "train loss:1.1694779736910312\n",
      "train loss:1.3590869921545525\n",
      "train loss:1.2144782251268524\n",
      "train loss:1.2128953207597404\n",
      "train loss:1.0483840701034952\n",
      "train loss:1.1183330163303298\n",
      "train loss:1.0929831473977318\n",
      "train loss:1.2345968255017352\n",
      "train loss:1.1473089351582064\n",
      "train loss:1.3673170973710327\n",
      "train loss:1.3525293872898863\n",
      "train loss:1.3749571659370192\n",
      "train loss:1.4430283663954544\n",
      "train loss:1.2929605199019334\n",
      "train loss:1.1785105467330617\n",
      "train loss:1.0106308886029622\n",
      "train loss:1.3392289089087288\n",
      "train loss:1.2284072042632006\n",
      "train loss:1.2944406098517027\n",
      "train loss:1.3087028343371898\n",
      "train loss:1.3132668510587673\n",
      "train loss:1.0249916710199933\n",
      "train loss:1.0714388316399428\n",
      "train loss:1.3043287699067196\n",
      "train loss:1.147680782835906\n",
      "train loss:1.234982741598291\n",
      "train loss:1.1587031594257398\n",
      "train loss:1.1836289038530743\n",
      "train loss:0.9644002905831909\n",
      "train loss:1.1976400480347238\n",
      "train loss:1.171000937241186\n",
      "train loss:1.1647799378241204\n",
      "train loss:1.3306767910293038\n",
      "train loss:1.3444642111765785\n",
      "train loss:1.1010850249296589\n",
      "train loss:1.1322936523488485\n",
      "train loss:1.4326027244880337\n",
      "train loss:1.2856477241644413\n",
      "train loss:1.3199115089286841\n",
      "train loss:1.1866407479398078\n",
      "train loss:1.2684654032344482\n",
      "train loss:1.1091157230311897\n",
      "train loss:1.3133180215916134\n",
      "train loss:1.1316756239798094\n",
      "train loss:1.339036588866669\n",
      "train loss:1.2078910140355323\n",
      "train loss:1.2345247866127258\n",
      "train loss:1.4354132389281729\n",
      "train loss:1.314483694672508\n",
      "train loss:1.2357883140885058\n",
      "train loss:1.1678833745609147\n",
      "train loss:1.105039907073873\n",
      "train loss:1.3459995141972803\n",
      "train loss:1.0895098317257506\n",
      "train loss:1.1634556262715383\n",
      "train loss:1.3896537945941534\n",
      "train loss:1.212068401846117\n",
      "train loss:1.266372906246791\n",
      "train loss:1.0102678596633603\n",
      "train loss:1.0618053594541796\n",
      "train loss:1.4067467380488563\n",
      "train loss:1.3560398342387048\n",
      "train loss:1.1464470245204816\n",
      "train loss:1.1377066914287932\n",
      "train loss:1.2537538578253922\n",
      "train loss:1.1604468356119397\n",
      "train loss:1.2060486395117607\n",
      "train loss:1.033255460030442\n",
      "train loss:1.1776067852578016\n",
      "train loss:1.3555506384708444\n",
      "train loss:1.2171826386069495\n",
      "train loss:1.1114370547346133\n",
      "train loss:1.0539647251865696\n",
      "train loss:1.2078844122154337\n",
      "train loss:1.2798229111617851\n",
      "train loss:1.3711995586689367\n",
      "train loss:1.195950122112292\n",
      "train loss:1.3550907087566406\n",
      "train loss:1.1538117232941854\n",
      "train loss:1.0873323366464456\n",
      "train loss:1.2035192600137439\n",
      "train loss:1.2356445083886924\n",
      "train loss:1.2970835400682705\n",
      "train loss:1.2753128216383158\n",
      "train loss:1.2207036319129474\n",
      "train loss:1.19600207963911\n",
      "train loss:1.437313453422541\n",
      "train loss:1.0460848028688836\n",
      "train loss:1.2358267540777244\n",
      "train loss:1.0059852003681566\n",
      "train loss:1.1681893784739996\n",
      "train loss:1.2309570373080612\n",
      "train loss:1.350162014241995\n",
      "train loss:1.1200954138564532\n",
      "train loss:1.2208653299885923\n",
      "train loss:0.9968346831673872\n",
      "train loss:1.2651589916517354\n",
      "train loss:1.2420014395826646\n",
      "train loss:1.0481245971436637\n",
      "train loss:1.2128432594543372\n",
      "train loss:1.1547974633514118\n",
      "train loss:1.32895127782986\n",
      "train loss:1.2311509159594467\n",
      "train loss:1.3410594703494667\n",
      "train loss:1.2682254182974015\n",
      "train loss:1.2647463844687097\n",
      "train loss:1.173167807386091\n",
      "train loss:1.0459082433184848\n",
      "train loss:1.1087336513303243\n",
      "train loss:1.123281981707417\n",
      "train loss:1.2377327911412417\n",
      "train loss:1.2212504302132532\n",
      "train loss:1.1685249590796034\n",
      "train loss:1.481092709443188\n",
      "train loss:1.261068853308636\n",
      "train loss:1.366689930023802\n",
      "train loss:1.1150389086680406\n",
      "train loss:1.0929786522291833\n",
      "train loss:1.3302934801917567\n",
      "train loss:1.1780437154281993\n",
      "train loss:1.2159634424826045\n",
      "train loss:1.2398306840252327\n",
      "train loss:1.1970291742598433\n",
      "train loss:1.3176637706667589\n",
      "train loss:1.0583687511680164\n",
      "train loss:1.2953338971476855\n",
      "train loss:1.2016838405907955\n",
      "train loss:1.1041572268484203\n",
      "train loss:1.209712829412327\n",
      "train loss:1.1874684602753869\n",
      "train loss:1.2250834546018008\n",
      "train loss:1.1003282035790598\n",
      "train loss:1.1919342635845884\n",
      "train loss:1.2362881743186316\n",
      "train loss:1.2727845833267495\n",
      "train loss:1.2271086425523041\n",
      "train loss:1.2084794737694802\n",
      "train loss:1.3027498380987017\n",
      "train loss:1.1539458738301398\n",
      "train loss:1.1134037083250101\n",
      "train loss:1.0590368753010901\n",
      "train loss:1.0329643913155042\n",
      "train loss:1.2026112636672623\n",
      "train loss:1.1557160692815887\n",
      "train loss:1.2112678154955945\n",
      "train loss:1.1230754810610355\n",
      "train loss:1.2424738808767295\n",
      "train loss:1.3573531232151794\n",
      "train loss:1.0203465948369128\n",
      "train loss:1.153774306833837\n",
      "train loss:1.10334638724311\n",
      "train loss:1.4018137199464482\n",
      "train loss:1.1785024356379843\n",
      "train loss:1.3221030397323994\n",
      "train loss:1.136495404975773\n",
      "train loss:1.0853070092355102\n",
      "train loss:1.1781199623609897\n",
      "train loss:1.1480731114475917\n",
      "train loss:1.0601631012067612\n",
      "train loss:1.0586332331054773\n",
      "train loss:1.1710901189076484\n",
      "train loss:1.1079541456057163\n",
      "train loss:1.3354845738616927\n",
      "train loss:1.1524193491472525\n",
      "train loss:1.2339125017205728\n",
      "train loss:1.2201802209801784\n",
      "train loss:1.1333647585297149\n",
      "train loss:1.1593309242328074\n",
      "train loss:1.1349884595334512\n",
      "train loss:1.1375117988667287\n",
      "train loss:1.192606119593039\n",
      "train loss:1.4294462684359794\n",
      "train loss:1.2733442309718597\n",
      "train loss:1.1479531685648632\n",
      "train loss:1.2202896427603187\n",
      "train loss:1.2346584180771358\n",
      "train loss:1.1728498836709471\n",
      "train loss:1.3139247010528323\n",
      "train loss:1.2439017857064973\n",
      "train loss:1.2162271872635797\n",
      "train loss:1.2849696393502603\n",
      "train loss:1.1850254434823215\n",
      "train loss:1.3234563582452423\n",
      "train loss:1.2441476292181006\n",
      "train loss:1.3701987047071438\n",
      "train loss:1.3762702485369447\n",
      "train loss:1.0577545430892545\n",
      "train loss:1.1497194710429968\n",
      "train loss:1.2989576720908174\n",
      "train loss:1.3784889006985523\n",
      "train loss:1.2442777738278321\n",
      "train loss:1.126235965341065\n",
      "train loss:1.2082792880081303\n",
      "train loss:1.2198689825469031\n",
      "train loss:1.2695737360921941\n",
      "train loss:1.1001765723491947\n",
      "train loss:1.1361226511297797\n",
      "train loss:1.3543669079297427\n",
      "train loss:1.0254889368685278\n",
      "train loss:1.1860692114956084\n",
      "train loss:1.1687243456513652\n",
      "train loss:1.347767468268806\n",
      "train loss:1.0996670466335596\n",
      "train loss:1.2255165298308701\n",
      "train loss:1.1562647623749198\n",
      "train loss:1.211078811839422\n",
      "train loss:1.214567028028573\n",
      "train loss:1.4695180600178188\n",
      "train loss:1.1922271734998053\n",
      "train loss:1.3329516118686144\n",
      "train loss:1.1941828902483567\n",
      "train loss:1.4497650286678083\n",
      "train loss:1.205218183269503\n",
      "train loss:1.3261484327380955\n",
      "train loss:1.1454274944991505\n",
      "train loss:1.2356033255348537\n",
      "train loss:1.3448394640879702\n",
      "train loss:1.1607568767692318\n",
      "train loss:1.2472757023374805\n",
      "train loss:1.2348101690516964\n",
      "train loss:1.3928614075290051\n",
      "train loss:1.1665768817899762\n",
      "train loss:1.1199771715230882\n",
      "train loss:1.1344061282836175\n",
      "train loss:1.195603900524499\n",
      "train loss:1.1724471809458976\n",
      "train loss:1.201728647382421\n",
      "train loss:1.1098908622886212\n",
      "train loss:1.0636422278190532\n",
      "train loss:1.2974635325367407\n",
      "train loss:1.225805367755668\n",
      "train loss:1.1595999616752486\n",
      "train loss:1.1377592795273546\n",
      "train loss:1.1340297255018141\n",
      "train loss:1.0718407209187506\n",
      "train loss:1.0391795975368021\n",
      "train loss:1.1865284376887677\n",
      "train loss:1.3797646974767201\n",
      "train loss:1.080406606423724\n",
      "train loss:1.2661462080635169\n",
      "train loss:1.1804476829617763\n",
      "train loss:1.1178765022231023\n",
      "train loss:1.1558407732526101\n",
      "train loss:1.1016767641419083\n",
      "train loss:1.104172611862129\n",
      "train loss:1.0365655346034743\n",
      "train loss:1.0860631196086925\n",
      "train loss:1.1420305270026656\n",
      "train loss:1.3171754121332275\n",
      "train loss:1.059081506476336\n",
      "train loss:1.2384295220980563\n",
      "train loss:1.2356670248781827\n",
      "train loss:1.0858173366213995\n",
      "train loss:1.1691577639544968\n",
      "train loss:1.2456129480423832\n",
      "train loss:0.9582922984872349\n",
      "train loss:1.314227714611346\n",
      "train loss:0.9506824710052841\n",
      "train loss:1.213804278187737\n",
      "train loss:1.1886122240209118\n",
      "train loss:1.06969135077119\n",
      "train loss:1.2143139675383177\n",
      "train loss:1.144073786904549\n",
      "train loss:1.3290180045103552\n",
      "train loss:1.0532241910983056\n",
      "train loss:1.1797647094690398\n",
      "train loss:0.9773950433178807\n",
      "train loss:1.1340109289848272\n",
      "train loss:1.2681593161902907\n",
      "train loss:1.2390832453926564\n",
      "train loss:1.2470408184335218\n",
      "train loss:1.1337827047392723\n",
      "train loss:1.1446312425687284\n",
      "train loss:1.0640707882029348\n",
      "train loss:1.3093698665525257\n",
      "train loss:1.118264311040556\n",
      "train loss:1.2177744306957285\n",
      "train loss:1.2179980250251452\n",
      "train loss:1.0310240420072077\n",
      "train loss:1.1355147226818005\n",
      "train loss:1.3937175856310637\n",
      "train loss:1.149763540498625\n",
      "train loss:1.1384344968318383\n",
      "train loss:1.2032407759030965\n",
      "train loss:1.435144198957274\n",
      "train loss:1.3135847525672435\n",
      "train loss:1.233321203310584\n",
      "train loss:1.2639681918471186\n",
      "train loss:1.2312145690079752\n",
      "train loss:1.1332990004571302\n",
      "train loss:1.123263846598033\n",
      "train loss:1.1629972278251797\n",
      "train loss:1.2536352937302544\n",
      "train loss:1.3154775913863939\n",
      "train loss:1.1542083703012156\n",
      "train loss:1.1694666030583054\n",
      "train loss:1.1169803144646087\n",
      "train loss:1.0219962284979318\n",
      "train loss:1.18187982006556\n",
      "train loss:1.2900387116887844\n",
      "train loss:1.2243519133356124\n",
      "train loss:1.185933000049091\n",
      "train loss:1.1742930958685696\n",
      "train loss:1.1523066447408827\n",
      "train loss:1.1886794442686337\n",
      "train loss:1.247377678475848\n",
      "train loss:1.0491019755269644\n",
      "train loss:1.219891659860281\n",
      "train loss:1.2135811887871721\n",
      "train loss:1.1836512779473294\n",
      "train loss:1.4206190099553258\n",
      "train loss:1.3321943684301252\n",
      "train loss:1.0688098075119188\n",
      "train loss:1.0370946240494567\n",
      "train loss:1.0980831947714804\n",
      "train loss:1.2570614993211684\n",
      "train loss:1.1354650897535203\n",
      "train loss:1.1610333016489873\n",
      "train loss:1.0546204877297773\n",
      "train loss:1.2804080378910387\n",
      "train loss:1.1915842091460325\n",
      "train loss:1.2235125565899594\n",
      "train loss:1.2289534455905815\n",
      "train loss:1.1197492784411494\n",
      "train loss:1.1928036029102023\n",
      "train loss:1.1542398365642461\n",
      "train loss:1.2187816089877255\n",
      "train loss:1.2630065027984996\n",
      "train loss:1.275630004050072\n",
      "train loss:1.1962955914815443\n",
      "train loss:1.2529552702397042\n",
      "train loss:1.1572232163438116\n",
      "train loss:1.0963509711223827\n",
      "train loss:1.165310555501035\n",
      "train loss:1.1374408606024677\n",
      "train loss:1.13207972358223\n",
      "train loss:1.1534592118491056\n",
      "train loss:1.248597275940954\n",
      "train loss:1.0057338151853328\n",
      "train loss:1.2534045294274598\n",
      "train loss:1.1976403542217249\n",
      "train loss:1.1981960488085626\n",
      "train loss:1.2801766066327005\n",
      "train loss:1.2367652754692617\n",
      "train loss:1.2510132538295387\n",
      "train loss:1.1315135485601733\n",
      "train loss:1.370483055302815\n",
      "train loss:1.246617693531501\n",
      "train loss:1.068513749782017\n",
      "train loss:1.2484713148714501\n",
      "train loss:1.110929687731567\n",
      "train loss:1.1278895438964152\n",
      "train loss:1.2505439954502067\n",
      "train loss:1.1275147831682266\n",
      "train loss:1.0311745341542515\n",
      "train loss:1.2018187680095267\n",
      "train loss:1.329575983565019\n",
      "train loss:1.1198915089169916\n",
      "train loss:1.1195391262067251\n",
      "train loss:1.0240992275043688\n",
      "train loss:1.0029369232311232\n",
      "train loss:1.1457436274529018\n",
      "train loss:1.1925722741999911\n",
      "train loss:1.2197148289038853\n",
      "train loss:1.022539484863785\n",
      "train loss:1.1847873626440286\n",
      "train loss:1.2151376266205787\n",
      "train loss:1.3031364376105279\n",
      "train loss:1.0566003465927762\n",
      "train loss:1.089044406745078\n",
      "train loss:1.3996339892648482\n",
      "train loss:1.3223825583116167\n",
      "train loss:1.0980312852429528\n",
      "train loss:1.1742951518373257\n",
      "train loss:1.2769583617870732\n",
      "train loss:1.3397404971905689\n",
      "train loss:1.1528074453229022\n",
      "train loss:1.183069954329514\n",
      "train loss:1.3710178584886108\n",
      "train loss:1.271544850174166\n",
      "train loss:1.1056205780313495\n",
      "train loss:1.0984411245875996\n",
      "train loss:1.150667932919811\n",
      "train loss:1.1313856366972868\n",
      "train loss:1.0642275720773704\n",
      "train loss:1.1217302024469442\n",
      "train loss:1.4872341361264154\n",
      "train loss:1.047119215062784\n",
      "train loss:1.3357882137482884\n",
      "train loss:1.1289454636639475\n",
      "train loss:1.1473724933912106\n",
      "train loss:1.096212408751759\n",
      "train loss:1.1550218214350427\n",
      "train loss:1.1961568155243387\n",
      "train loss:1.2458231642725164\n",
      "train loss:1.2993409239594305\n",
      "train loss:1.2157144601468501\n",
      "train loss:1.108075405005393\n",
      "=== epoch:6, train acc:0.598, test acc:0.561 ===\n",
      "train loss:1.1135670795342738\n",
      "train loss:1.224120629191148\n",
      "train loss:1.2823494720227007\n",
      "train loss:1.3109733405936403\n",
      "train loss:1.2425657214724324\n",
      "train loss:1.3018984055234537\n",
      "train loss:1.117608821592052\n",
      "train loss:1.12776341475145\n",
      "train loss:1.2236474765636083\n",
      "train loss:1.0200378497784939\n",
      "train loss:1.2441370214910368\n",
      "train loss:1.0570883699850326\n",
      "train loss:1.241365646815286\n",
      "train loss:1.1405119164803723\n",
      "train loss:1.245707349407066\n",
      "train loss:1.3380125745609823\n",
      "train loss:1.0940265931190059\n",
      "train loss:1.236152162120981\n",
      "train loss:1.1251637088898605\n",
      "train loss:1.2241171426571305\n",
      "train loss:1.2238888975939077\n",
      "train loss:1.126966016536423\n",
      "train loss:1.2473615327311516\n",
      "train loss:1.194533559589314\n",
      "train loss:1.0993532456926647\n",
      "train loss:1.1539126662260508\n",
      "train loss:1.0882551964396692\n",
      "train loss:1.1013518691526416\n",
      "train loss:1.071241269117114\n",
      "train loss:1.2370987132060514\n",
      "train loss:1.1155657402615122\n",
      "train loss:1.209250766297636\n",
      "train loss:1.2370555821960287\n",
      "train loss:1.5019090149119683\n",
      "train loss:1.4764936791089476\n",
      "train loss:1.3230514203369237\n",
      "train loss:1.0542180563639574\n",
      "train loss:1.1342353674798886\n",
      "train loss:1.095987269115105\n",
      "train loss:1.0591179278721239\n",
      "train loss:1.0279971452444014\n",
      "train loss:1.1640531309077002\n",
      "train loss:1.0727001564194354\n",
      "train loss:1.0970185955231593\n",
      "train loss:1.2291251750088241\n",
      "train loss:1.2698820412936032\n",
      "train loss:1.1624568719869757\n",
      "train loss:1.2764989851266717\n",
      "train loss:1.2414728876562051\n",
      "train loss:1.2386810482367325\n",
      "train loss:1.103769259934778\n",
      "train loss:1.1391290989215792\n",
      "train loss:1.2040408745132773\n",
      "train loss:1.1701942167936819\n",
      "train loss:1.1964666761671094\n",
      "train loss:1.0564968419428953\n",
      "train loss:1.1930618417692882\n",
      "train loss:1.222463983605976\n",
      "train loss:1.2141078616354861\n",
      "train loss:1.2976591937214916\n",
      "train loss:1.2575134152601968\n",
      "train loss:1.2229600063211947\n",
      "train loss:1.426989509584066\n",
      "train loss:1.320413575734681\n",
      "train loss:1.2674946457770409\n",
      "train loss:1.2337367522441176\n",
      "train loss:1.115281626626217\n",
      "train loss:1.103517448152239\n",
      "train loss:1.2328347581878447\n",
      "train loss:1.2222342703207654\n",
      "train loss:1.0266045455103008\n",
      "train loss:1.310605956381318\n",
      "train loss:1.0967297631543107\n",
      "train loss:1.056176585558297\n",
      "train loss:1.1522630628496677\n",
      "train loss:1.1324422877627434\n",
      "train loss:1.3353739812697614\n",
      "train loss:1.161455141095746\n",
      "train loss:1.0407440850017822\n",
      "train loss:1.0613470385541237\n",
      "train loss:1.089790980910419\n",
      "train loss:1.2367718361104547\n",
      "train loss:1.0513684371751908\n",
      "train loss:1.0497145042003668\n",
      "train loss:1.16139732498426\n",
      "train loss:1.1509079391364936\n",
      "train loss:1.1745756921722101\n",
      "train loss:1.044551726465854\n",
      "train loss:1.238674178591337\n",
      "train loss:1.2831435180649482\n",
      "train loss:1.3847089277101\n",
      "train loss:1.1084383197454495\n",
      "train loss:1.161138387706213\n",
      "train loss:1.122159201371994\n",
      "train loss:1.07171954083312\n",
      "train loss:1.2581951314270412\n",
      "train loss:1.0673326545775614\n",
      "train loss:1.034699489003648\n",
      "train loss:1.3037988742515947\n",
      "train loss:1.1113793003124486\n",
      "train loss:1.308241050355952\n",
      "train loss:1.3506370615282088\n",
      "train loss:1.105920515136856\n",
      "train loss:1.1186288101996567\n",
      "train loss:1.1139167280805848\n",
      "train loss:1.0263567637574778\n",
      "train loss:1.0183787665505706\n",
      "train loss:1.2692071134845864\n",
      "train loss:1.2257484968178505\n",
      "train loss:1.034907400460781\n",
      "train loss:1.3584908722619764\n",
      "train loss:1.093943302757652\n",
      "train loss:1.1111440821296725\n",
      "train loss:1.0155133954734652\n",
      "train loss:1.1990857089501537\n",
      "train loss:1.1239593494278763\n",
      "train loss:1.0894300863557653\n",
      "train loss:1.2446424078795746\n",
      "train loss:1.1068707126938642\n",
      "train loss:1.1796844989186481\n",
      "train loss:1.2151532464976584\n",
      "train loss:1.076868930929085\n",
      "train loss:1.107131740801956\n",
      "train loss:1.1122150507285766\n",
      "train loss:1.078537901146091\n",
      "train loss:1.2689938583457703\n",
      "train loss:1.056553070061148\n",
      "train loss:1.3243904963630109\n",
      "train loss:1.1906027633709244\n",
      "train loss:1.1090800217412935\n",
      "train loss:1.3030403970069964\n",
      "train loss:1.1956353835713265\n",
      "train loss:1.1502168625101588\n",
      "train loss:1.3025340152699962\n",
      "train loss:1.264415019545947\n",
      "train loss:1.112708586581335\n",
      "train loss:1.2172293879496408\n",
      "train loss:1.1370297859087726\n",
      "train loss:1.1671707164472211\n",
      "train loss:1.017673209985543\n",
      "train loss:1.1919103209265058\n",
      "train loss:1.2973889592388783\n",
      "train loss:0.997263676362484\n",
      "train loss:1.1533524481670665\n",
      "train loss:1.219793507015825\n",
      "train loss:0.9763417024813817\n",
      "train loss:1.2447161326680045\n",
      "train loss:1.2057281454098447\n",
      "train loss:1.3394717355481933\n",
      "train loss:1.2540459191875413\n",
      "train loss:1.1128657534929534\n",
      "train loss:1.2534722315254099\n",
      "train loss:1.2456769552211233\n",
      "train loss:1.2309724858217215\n",
      "train loss:1.2060128630113776\n",
      "train loss:1.1720232830884378\n",
      "train loss:1.050047370480651\n",
      "train loss:1.5246258372254018\n",
      "train loss:1.119004645934149\n",
      "train loss:1.176107376801267\n",
      "train loss:1.0618815579557752\n",
      "train loss:1.103729402031682\n",
      "train loss:1.1204830179640335\n",
      "train loss:0.9897534132360676\n",
      "train loss:1.335336691313155\n",
      "train loss:1.0432162824214561\n",
      "train loss:1.0422387746799209\n",
      "train loss:1.1623279157613469\n",
      "train loss:1.0169473559101494\n",
      "train loss:1.3154135476904332\n",
      "train loss:1.2001939825423844\n",
      "train loss:1.1069425718021335\n",
      "train loss:0.9219811140006244\n",
      "train loss:1.170257049035985\n",
      "train loss:1.2362463342374022\n",
      "train loss:1.3390365312509664\n",
      "train loss:1.1165607904454031\n",
      "train loss:1.1475181433633532\n",
      "train loss:1.0984672694892113\n",
      "train loss:1.0273265069400213\n",
      "train loss:1.0842897933621714\n",
      "train loss:1.2930657608940768\n",
      "train loss:1.226827406354606\n",
      "train loss:1.2480620622918472\n",
      "train loss:1.0995501497118183\n",
      "train loss:1.218198921872543\n",
      "train loss:1.0233991753674438\n",
      "train loss:1.2705675584941796\n",
      "train loss:0.9668654535699135\n",
      "train loss:1.230420495310014\n",
      "train loss:1.2125122834365683\n",
      "train loss:1.2863221180502555\n",
      "train loss:1.0878000931245808\n",
      "train loss:1.1851609324893173\n",
      "train loss:1.224883627144527\n",
      "train loss:1.1486356909901052\n",
      "train loss:1.2136358983599658\n",
      "train loss:1.274410542449767\n",
      "train loss:1.003767251417263\n",
      "train loss:1.2160766581275002\n",
      "train loss:1.0682147526121113\n",
      "train loss:1.0631649770264222\n",
      "train loss:0.9968165064941715\n",
      "train loss:1.1248742444696231\n",
      "train loss:0.9963934714723883\n",
      "train loss:1.0664406695625472\n",
      "train loss:1.3748240476408358\n",
      "train loss:1.1424478256187165\n",
      "train loss:1.0389525574229437\n",
      "train loss:1.0913675273446044\n",
      "train loss:1.324200618671823\n",
      "train loss:1.2192178097068445\n",
      "train loss:1.091515224115502\n",
      "train loss:1.1541455657891153\n",
      "train loss:1.323645389572543\n",
      "train loss:1.0601619924662022\n",
      "train loss:1.1301409983760216\n",
      "train loss:1.1947785779254159\n",
      "train loss:1.1814506470314579\n",
      "train loss:1.172034892836313\n",
      "train loss:1.2145186810307609\n",
      "train loss:1.1557346339177013\n",
      "train loss:1.0665876020986642\n",
      "train loss:1.3303622847501873\n",
      "train loss:1.0259590034938142\n",
      "train loss:1.1365938220640814\n",
      "train loss:1.2087829607318952\n",
      "train loss:1.0735384364914609\n",
      "train loss:1.0803708821538027\n",
      "train loss:1.0345748073579155\n",
      "train loss:1.1859538520131425\n",
      "train loss:1.2098593564367712\n",
      "train loss:1.125998614770558\n",
      "train loss:1.0070445618027137\n",
      "train loss:0.9822872356070361\n",
      "train loss:1.1030006762654803\n",
      "train loss:1.2467950296056989\n",
      "train loss:1.1942412860370393\n",
      "train loss:1.1699103936468156\n",
      "train loss:1.30804731239755\n",
      "train loss:1.2025607435977503\n",
      "train loss:1.1823565257986874\n",
      "train loss:1.1929479635092048\n",
      "train loss:1.1624390994420994\n",
      "train loss:1.1728127089170703\n",
      "train loss:1.1419465162397169\n",
      "train loss:0.9421828461182143\n",
      "train loss:1.0682718640420907\n",
      "train loss:1.1418573304670543\n",
      "train loss:1.0441887211195808\n",
      "train loss:1.20350755541135\n",
      "train loss:1.2380160598752852\n",
      "train loss:0.8892807570511679\n",
      "train loss:1.0950028510896308\n",
      "train loss:1.1991820582462713\n",
      "train loss:1.0188353096717158\n",
      "train loss:1.075712505767558\n",
      "train loss:1.355609687581092\n",
      "train loss:1.2101554193519994\n",
      "train loss:0.9994755094771025\n",
      "train loss:1.1229955131507174\n",
      "train loss:1.2587258524888052\n",
      "train loss:1.140515707347192\n",
      "train loss:1.247830610347831\n",
      "train loss:1.2681073008289012\n",
      "train loss:1.1146749428300466\n",
      "train loss:1.1917890866199992\n",
      "train loss:1.1208935344511255\n",
      "train loss:1.096425251096286\n",
      "train loss:1.091124802101792\n",
      "train loss:1.0000501120993157\n",
      "train loss:1.193760719142521\n",
      "train loss:1.2462236411285808\n",
      "train loss:1.1011771824534677\n",
      "train loss:1.1919316486890157\n",
      "train loss:1.2335407785328414\n",
      "train loss:1.2302067626375937\n",
      "train loss:1.1541735898362273\n",
      "train loss:1.3559210595957294\n",
      "train loss:0.9738955616481406\n",
      "train loss:1.338986689764133\n",
      "train loss:0.9936664393557619\n",
      "train loss:1.1294575634909472\n",
      "train loss:0.9935339483395722\n",
      "train loss:1.3413248677222438\n",
      "train loss:0.8668272385985888\n",
      "train loss:1.088083361580678\n",
      "train loss:1.0922990888305772\n",
      "train loss:1.081495658039307\n",
      "train loss:1.3182649494351393\n",
      "train loss:1.1113136498654719\n",
      "train loss:1.0119175855428377\n",
      "train loss:1.1627859459151453\n",
      "train loss:0.9514799168516018\n",
      "train loss:1.087108393430274\n",
      "train loss:1.1788560085805218\n",
      "train loss:1.2642979597494803\n",
      "train loss:1.289644187507588\n",
      "train loss:1.0939079652204995\n",
      "train loss:1.140508925842188\n",
      "train loss:1.064018362938204\n",
      "train loss:1.2628428969699461\n",
      "train loss:1.249019323881066\n",
      "train loss:0.9499249832674007\n",
      "train loss:1.2407557720538773\n",
      "train loss:1.0278026158477294\n",
      "train loss:1.1091891143404295\n",
      "train loss:0.9355512592230134\n",
      "train loss:1.0864366916612767\n",
      "train loss:1.1610190609388256\n",
      "train loss:1.1786993055833062\n",
      "train loss:1.0643865532873058\n",
      "train loss:1.2190889495947985\n",
      "train loss:1.0226821957742056\n",
      "train loss:0.9549092907436684\n",
      "train loss:1.1397002254370054\n",
      "train loss:1.2032951157340082\n",
      "train loss:1.2103654963701358\n",
      "train loss:1.0766852144483243\n",
      "train loss:0.9488572297824315\n",
      "train loss:1.2696529866621054\n",
      "train loss:1.0271525831479251\n",
      "train loss:1.2262882930837127\n",
      "train loss:1.1413587005972772\n",
      "train loss:1.1660445639833514\n",
      "train loss:1.0801827921262115\n",
      "train loss:1.0886045977483318\n",
      "train loss:1.255713958973099\n",
      "train loss:1.0333446917079432\n",
      "train loss:1.0038684839757122\n",
      "train loss:1.1236573980935833\n",
      "train loss:1.0339362523906044\n",
      "train loss:1.2513022809963485\n",
      "train loss:1.0212823039929808\n",
      "train loss:1.1640941496911956\n",
      "train loss:1.1934844597166765\n",
      "train loss:1.1388621650473651\n",
      "train loss:1.0480294979551075\n",
      "train loss:1.185622791700091\n",
      "train loss:1.1665122514020463\n",
      "train loss:1.0771104660240538\n",
      "train loss:0.9589609217771597\n",
      "train loss:1.0552680583810226\n",
      "train loss:1.326644698313786\n",
      "train loss:1.0597707008180848\n",
      "train loss:1.0440974342761544\n",
      "train loss:1.0180484943514205\n",
      "train loss:1.3624125080805374\n",
      "train loss:1.1226422141380081\n",
      "train loss:1.0671087462971331\n",
      "train loss:1.1095213473776107\n",
      "train loss:0.9766331730775001\n",
      "train loss:1.0621846899866063\n",
      "train loss:0.8953906720369653\n",
      "train loss:1.0308460069014194\n",
      "train loss:1.2297047913160406\n",
      "train loss:1.0260889914666482\n",
      "train loss:1.0102994756485033\n",
      "train loss:1.1497267333415828\n",
      "train loss:1.0275098609034972\n",
      "train loss:1.1410629049944547\n",
      "train loss:1.2392488319368318\n",
      "train loss:1.1266551518511947\n",
      "train loss:1.1748662831275782\n",
      "train loss:1.1328081605003477\n",
      "train loss:1.2405037945020874\n",
      "train loss:1.2490247560577592\n",
      "train loss:1.302324899178169\n",
      "train loss:1.3553231554209972\n",
      "train loss:1.052207395953049\n",
      "train loss:1.22608990630097\n",
      "train loss:1.0641848675237795\n",
      "train loss:0.9649430685042978\n",
      "train loss:1.129146284085492\n",
      "train loss:1.0713440760437303\n",
      "train loss:1.0891953846345581\n",
      "train loss:1.1020949908381612\n",
      "train loss:1.1162740008536898\n",
      "train loss:1.161024228317026\n",
      "train loss:1.1773744029173474\n",
      "train loss:1.1104508542650091\n",
      "train loss:1.2605232774431852\n",
      "train loss:1.076126874763231\n",
      "train loss:1.1477271167504628\n",
      "train loss:1.2245266671432724\n",
      "train loss:1.3862446056115934\n",
      "train loss:1.199225551509888\n",
      "train loss:1.1038380025484362\n",
      "train loss:1.0647688905903263\n",
      "train loss:1.2156113473739667\n",
      "train loss:0.9876697837513659\n",
      "train loss:1.0774450646126765\n",
      "train loss:1.1446723105165082\n",
      "train loss:1.0440388547966257\n",
      "train loss:1.1144077597396924\n",
      "train loss:1.2243561140875308\n",
      "train loss:1.1002025026507616\n",
      "train loss:1.1391925892940014\n",
      "train loss:1.0100283115304844\n",
      "train loss:1.1499203352794856\n",
      "=== epoch:7, train acc:0.616, test acc:0.549 ===\n",
      "train loss:1.1208741488923173\n",
      "train loss:1.2194405522202443\n",
      "train loss:1.0333233574161966\n",
      "train loss:1.2693250183783504\n",
      "train loss:1.1649103645758045\n",
      "train loss:1.1021857291450878\n",
      "train loss:0.9934765315624651\n",
      "train loss:1.0706200866241855\n",
      "train loss:1.0624459598010414\n",
      "train loss:1.1749616313676599\n",
      "train loss:1.0919772284211122\n",
      "train loss:1.1308542066146479\n",
      "train loss:1.053098906920601\n",
      "train loss:1.1985690703893952\n",
      "train loss:1.1507757439089723\n",
      "train loss:1.0672085920236485\n",
      "train loss:1.0697626064083121\n",
      "train loss:1.1540198682702287\n",
      "train loss:1.3406548005059913\n",
      "train loss:1.1364938020101516\n",
      "train loss:1.037947082944891\n",
      "train loss:1.071390968092369\n",
      "train loss:1.0668694232066327\n",
      "train loss:1.1768184685022285\n",
      "train loss:1.231635155475606\n",
      "train loss:1.1202366512244277\n",
      "train loss:1.1300994820234624\n",
      "train loss:1.3226585843080543\n",
      "train loss:1.205193690175482\n",
      "train loss:1.1589792766810654\n",
      "train loss:0.9768043535230378\n",
      "train loss:0.9141106314195967\n",
      "train loss:1.2479088390292246\n",
      "train loss:1.003811954509306\n",
      "train loss:0.9801118888138157\n",
      "train loss:1.2181634870929419\n",
      "train loss:1.0658257539351854\n",
      "train loss:1.214370713668431\n",
      "train loss:1.0921760383958417\n",
      "train loss:0.9722424218030316\n",
      "train loss:1.0415712727709907\n",
      "train loss:1.2402699339613255\n",
      "train loss:1.3523191472127627\n",
      "train loss:1.014486309504636\n",
      "train loss:1.0989075162574422\n",
      "train loss:1.0928379032748163\n",
      "train loss:0.99432076469848\n",
      "train loss:1.0922360731546565\n",
      "train loss:1.1978806108054563\n",
      "train loss:1.1707665799670748\n",
      "train loss:0.9043985109645029\n",
      "train loss:1.1038668253921822\n",
      "train loss:1.1621346769575862\n",
      "train loss:1.1054543886439019\n",
      "train loss:1.175416347125703\n",
      "train loss:0.9884550443374615\n",
      "train loss:1.1357357651455213\n",
      "train loss:1.1245693583959104\n",
      "train loss:1.0607458730511403\n",
      "train loss:1.0963946002470601\n",
      "train loss:1.0670229194663188\n",
      "train loss:1.0988338390491235\n",
      "train loss:0.9511454506056087\n",
      "train loss:1.1808657903092747\n",
      "train loss:1.2066563291433707\n",
      "train loss:1.3042626738413705\n",
      "train loss:1.0543140486254619\n",
      "train loss:0.99055780299475\n",
      "train loss:1.0252133613835073\n",
      "train loss:1.3169604782831694\n",
      "train loss:1.3633464062543974\n",
      "train loss:0.9927015134329131\n",
      "train loss:1.2561327744154391\n",
      "train loss:1.1089034522069818\n",
      "train loss:1.1051346915964906\n",
      "train loss:1.2355751087938471\n",
      "train loss:1.0266333790160436\n",
      "train loss:1.1772000765007846\n",
      "train loss:1.3039980070548378\n",
      "train loss:1.1582114436637183\n",
      "train loss:1.0312110431428354\n",
      "train loss:1.0793586424394175\n",
      "train loss:1.058526874929773\n",
      "train loss:1.0110586330515445\n",
      "train loss:1.216074718668156\n",
      "train loss:1.076723182931517\n",
      "train loss:1.2868640679867318\n",
      "train loss:1.1400194438696085\n",
      "train loss:1.2915418030454828\n",
      "train loss:1.286008806345724\n",
      "train loss:1.0567837356989616\n",
      "train loss:0.9314625544213954\n",
      "train loss:1.1328224601131418\n",
      "train loss:1.0147215120572575\n",
      "train loss:1.128653686848917\n",
      "train loss:1.0337457383081343\n",
      "train loss:1.0669341785154633\n",
      "train loss:1.1297861741354174\n",
      "train loss:1.0630356348530212\n",
      "train loss:1.2529204260882874\n",
      "train loss:1.245406261712526\n",
      "train loss:0.9657060022552875\n",
      "train loss:1.0104025010515318\n",
      "train loss:1.0183508897530202\n",
      "train loss:1.2095325105542196\n",
      "train loss:1.0479826015480023\n",
      "train loss:1.1719034273304454\n",
      "train loss:1.039736862274584\n",
      "train loss:1.2005946123187883\n",
      "train loss:1.1640976399731773\n",
      "train loss:1.2664794650768956\n",
      "train loss:1.1289112132406023\n",
      "train loss:1.02607009943726\n",
      "train loss:1.0666973556307484\n",
      "train loss:1.1644881697151792\n",
      "train loss:1.1876278091710153\n",
      "train loss:1.2836747531710475\n",
      "train loss:1.2073819130681556\n",
      "train loss:1.214309134848467\n",
      "train loss:1.1657201055247246\n",
      "train loss:0.9805397944595515\n",
      "train loss:1.1333892313512097\n",
      "train loss:1.277074517236325\n",
      "train loss:1.2464870744087149\n",
      "train loss:1.2107371095745996\n",
      "train loss:1.3347003739122918\n",
      "train loss:1.3619013597069247\n",
      "train loss:1.2746411766808334\n",
      "train loss:1.1953785814067723\n",
      "train loss:0.9442172480430595\n",
      "train loss:0.9218023520412529\n",
      "train loss:1.1395272137053496\n",
      "train loss:0.9858812369950317\n",
      "train loss:1.2179810604933703\n",
      "train loss:1.0984855001489535\n",
      "train loss:1.0596959492174787\n",
      "train loss:1.1501115970184617\n",
      "train loss:1.094447250156201\n",
      "train loss:1.0447201674453575\n",
      "train loss:1.1234647192152516\n",
      "train loss:1.0574081801092012\n",
      "train loss:1.0502965207174522\n",
      "train loss:1.0123125517310545\n",
      "train loss:1.2467752458500037\n",
      "train loss:1.2955455374513796\n",
      "train loss:1.2719676604441554\n",
      "train loss:1.264315712653123\n",
      "train loss:1.086973463726955\n",
      "train loss:1.2674113167202545\n",
      "train loss:1.1277922604961719\n",
      "train loss:1.1425009680317388\n",
      "train loss:1.184102676353559\n",
      "train loss:1.0458293205717117\n",
      "train loss:1.3410150547834112\n",
      "train loss:1.1545231652487855\n",
      "train loss:1.148363357079653\n",
      "train loss:1.1099093569601322\n",
      "train loss:1.1371907932679368\n",
      "train loss:1.0914534313599744\n",
      "train loss:1.0598910089513374\n",
      "train loss:1.1704155182106295\n",
      "train loss:1.0982728632274499\n",
      "train loss:1.1355687067532998\n",
      "train loss:1.1396663970334526\n",
      "train loss:0.9532424453502654\n",
      "train loss:1.0372347608714818\n",
      "train loss:1.148780750232571\n",
      "train loss:1.0676371276085828\n",
      "train loss:1.1688802496469455\n",
      "train loss:1.0887404513070167\n",
      "train loss:1.0939883325364956\n",
      "train loss:1.1437092905443667\n",
      "train loss:1.0942703117379327\n",
      "train loss:1.163737870291228\n",
      "train loss:1.3349680622715676\n",
      "train loss:0.8977131367453708\n",
      "train loss:0.8635841928901273\n",
      "train loss:1.1243132743130888\n",
      "train loss:1.1262411160276842\n",
      "train loss:1.2182881845374818\n",
      "train loss:1.030172722482394\n",
      "train loss:1.2178146163033001\n",
      "train loss:1.1819933229721085\n",
      "train loss:1.1836202146269743\n",
      "train loss:1.1619280192508663\n",
      "train loss:0.9661963526313906\n",
      "train loss:1.0839880575278276\n",
      "train loss:1.166125956937642\n",
      "train loss:1.1400064311932714\n",
      "train loss:1.0999896166918304\n",
      "train loss:1.1432883913107685\n",
      "train loss:1.2146380918267206\n",
      "train loss:1.1027275868792714\n",
      "train loss:1.099402781266708\n",
      "train loss:1.0645988806039939\n",
      "train loss:1.162520693709018\n",
      "train loss:1.2309710759289538\n",
      "train loss:1.1846184559096817\n",
      "train loss:1.2063117579158562\n",
      "train loss:0.8792161105818006\n",
      "train loss:1.0167151941823034\n",
      "train loss:0.9225956642700289\n",
      "train loss:1.1218638651719326\n",
      "train loss:0.9782407811119065\n",
      "train loss:0.9616447877428617\n",
      "train loss:1.119116800354695\n",
      "train loss:1.2266811441168322\n",
      "train loss:1.0144003512695263\n",
      "train loss:1.084536563675598\n",
      "train loss:0.9968561532297607\n",
      "train loss:1.1728668552082562\n",
      "train loss:0.9700269346094025\n",
      "train loss:1.0340881536296702\n",
      "train loss:1.33193644306064\n",
      "train loss:1.0464118569585956\n",
      "train loss:1.0170359161726572\n",
      "train loss:1.2245352571674035\n",
      "train loss:1.2738478546956267\n",
      "train loss:1.1609333570886315\n",
      "train loss:1.171500270119957\n",
      "train loss:1.1651362677252726\n",
      "train loss:1.119901677786909\n",
      "train loss:1.185888133676115\n",
      "train loss:1.0854460605549885\n",
      "train loss:1.0974107386089618\n",
      "train loss:1.203637678858498\n",
      "train loss:1.0394456369994531\n",
      "train loss:1.0410295324597698\n",
      "train loss:1.1541704903154024\n",
      "train loss:0.8934045485786952\n",
      "train loss:1.138464864154337\n",
      "train loss:1.0808651346901121\n",
      "train loss:1.3265184024365555\n",
      "train loss:0.974128115335784\n",
      "train loss:1.1532613021645062\n",
      "train loss:1.126048611630813\n",
      "train loss:1.0566941000069239\n",
      "train loss:1.166143687550078\n",
      "train loss:0.9032442446550007\n",
      "train loss:1.2051258535609821\n",
      "train loss:1.0140783694833284\n",
      "train loss:1.0450664022706508\n",
      "train loss:1.2632547930200964\n",
      "train loss:1.229494205911228\n",
      "train loss:1.1174008633016395\n",
      "train loss:1.0992646483292008\n",
      "train loss:1.1717729421566534\n",
      "train loss:1.247956025662072\n",
      "train loss:1.1038191376522664\n",
      "train loss:1.2292628950808278\n",
      "train loss:1.0440293472158064\n",
      "train loss:0.9719428430148944\n",
      "train loss:1.1408797096515908\n",
      "train loss:1.194171452357452\n",
      "train loss:1.0887172170900277\n",
      "train loss:1.1168887442921933\n",
      "train loss:0.9597338383606082\n",
      "train loss:1.2073321429620627\n",
      "train loss:1.1385883736514197\n",
      "train loss:1.0211417803123686\n",
      "train loss:1.076154295116304\n",
      "train loss:1.0350324685959107\n",
      "train loss:1.1293631779684297\n",
      "train loss:1.210218476667322\n",
      "train loss:1.0457797465842085\n",
      "train loss:0.9331227681940983\n",
      "train loss:1.1613529368809057\n",
      "train loss:1.1741470556826004\n",
      "train loss:1.2329259904510856\n",
      "train loss:1.101715128541226\n",
      "train loss:1.0155671787803724\n",
      "train loss:1.0290594401081463\n",
      "train loss:1.1556576179368416\n",
      "train loss:1.2201743255187303\n",
      "train loss:1.0888331331840992\n",
      "train loss:1.1845488944114735\n",
      "train loss:1.0197989847425346\n",
      "train loss:1.0446795474110295\n",
      "train loss:1.295840134121677\n",
      "train loss:0.9663417710766918\n",
      "train loss:1.0787342807373694\n",
      "train loss:1.0635352699673706\n",
      "train loss:1.1931546129250088\n",
      "train loss:0.9891827153611618\n",
      "train loss:1.026758294187762\n",
      "train loss:1.1144028643649704\n",
      "train loss:0.991463601749826\n",
      "train loss:1.0614215175370263\n",
      "train loss:1.2551871167014386\n",
      "train loss:1.0315257837749763\n",
      "train loss:1.2320276403357544\n",
      "train loss:1.138404925046909\n",
      "train loss:1.0409989868365555\n",
      "train loss:1.3336947723352133\n",
      "train loss:1.0248510140115632\n",
      "train loss:1.1931709590175792\n",
      "train loss:1.1782040691987208\n",
      "train loss:0.9773233446393971\n",
      "train loss:1.0344654857875002\n",
      "train loss:1.2363301749371411\n",
      "train loss:1.1641000507673451\n",
      "train loss:1.067476782302767\n",
      "train loss:1.1287642166244334\n",
      "train loss:1.2761076727225293\n",
      "train loss:1.1845174928807831\n",
      "train loss:1.076013609589783\n",
      "train loss:1.2565710069252485\n",
      "train loss:1.1865041252721675\n",
      "train loss:1.171246707014561\n",
      "train loss:1.2788837140526474\n",
      "train loss:1.0933489537944103\n",
      "train loss:1.159805930921495\n",
      "train loss:1.12308618179761\n",
      "train loss:1.216958375579692\n",
      "train loss:1.153462827718381\n",
      "train loss:1.0936669375689863\n",
      "train loss:1.079335864313637\n",
      "train loss:1.2943945496181248\n",
      "train loss:1.0615472923123535\n",
      "train loss:1.3541494206567848\n",
      "train loss:1.06158611212553\n",
      "train loss:1.131741861162319\n",
      "train loss:1.0593591916596161\n",
      "train loss:1.131569873229645\n",
      "train loss:1.1090700055527163\n",
      "train loss:1.2696803930536382\n",
      "train loss:0.9364603893214032\n",
      "train loss:1.3057788604652594\n",
      "train loss:1.0666495761954595\n",
      "train loss:1.1688812669999127\n",
      "train loss:1.1158445407416722\n",
      "train loss:1.180928310429933\n",
      "train loss:1.193943216953602\n",
      "train loss:1.234983220260321\n",
      "train loss:1.2165985650200901\n",
      "train loss:1.2296578196756014\n",
      "train loss:1.0765648609360772\n",
      "train loss:1.1585270697349876\n",
      "train loss:1.5001033788043265\n",
      "train loss:1.1470089201116787\n",
      "train loss:1.3232528626715623\n",
      "train loss:1.0217693119416105\n",
      "train loss:1.1012311847503786\n",
      "train loss:0.9370836365172326\n",
      "train loss:1.2137432348782478\n",
      "train loss:1.0497358140198765\n",
      "train loss:1.0539082652588894\n",
      "train loss:1.2780917040446693\n",
      "train loss:1.120672119778893\n",
      "train loss:1.0016621953137967\n",
      "train loss:1.0536736533748368\n",
      "train loss:1.1570629790355051\n",
      "train loss:1.0745191460650154\n",
      "train loss:0.943242242987849\n",
      "train loss:0.9629488141948517\n",
      "train loss:1.1730242442348726\n",
      "train loss:0.9061523391542501\n",
      "train loss:0.9979927963232552\n",
      "train loss:0.9488785611993842\n",
      "train loss:1.1217324562850626\n",
      "train loss:1.1283522149261052\n",
      "train loss:1.1057354029381883\n",
      "train loss:1.0944727752973444\n",
      "train loss:1.115597672677478\n",
      "train loss:0.9352803146282079\n",
      "train loss:1.18994748876831\n",
      "train loss:1.058317636762548\n",
      "train loss:0.9494214105811671\n",
      "train loss:1.2691716492347076\n",
      "train loss:1.3487349744653079\n",
      "train loss:1.2044074723071518\n",
      "train loss:1.122408241734037\n",
      "train loss:1.0509227768899911\n",
      "train loss:0.8996814469829544\n",
      "train loss:1.0781876026914146\n",
      "train loss:1.1401476073672907\n",
      "train loss:1.0894826891574436\n",
      "train loss:1.038743895095226\n",
      "train loss:1.0428375768089164\n",
      "train loss:1.0031162073326672\n",
      "train loss:0.9970902531939362\n",
      "train loss:1.215882834208668\n",
      "train loss:1.0712941004887808\n",
      "train loss:1.285402651495281\n",
      "train loss:1.0761365135701362\n",
      "train loss:1.1292461540707215\n",
      "train loss:1.2344153001136942\n",
      "train loss:1.0156959933907421\n",
      "train loss:1.1818245847333961\n",
      "train loss:0.9723820705581191\n",
      "train loss:1.035677450456684\n",
      "train loss:1.056639974625829\n",
      "train loss:1.0295100955586178\n",
      "train loss:1.1123422655797395\n",
      "train loss:1.2839883647247015\n",
      "train loss:0.9870684376639521\n",
      "train loss:1.0664069202562958\n",
      "train loss:1.0709400043367716\n",
      "train loss:1.09026536497153\n",
      "train loss:1.2071564211242019\n",
      "=== epoch:8, train acc:0.642, test acc:0.56 ===\n",
      "train loss:1.0047240390109422\n",
      "train loss:1.0435673182418919\n",
      "train loss:1.174150673111352\n",
      "train loss:1.0092453692069538\n",
      "train loss:1.0054243077526437\n",
      "train loss:0.8652884065053738\n",
      "train loss:1.0433876904434336\n",
      "train loss:1.0300676400545323\n",
      "train loss:1.0789135290686844\n",
      "train loss:1.0605748531235684\n",
      "train loss:1.0855042628728762\n",
      "train loss:1.049945586646839\n",
      "train loss:1.1173333080792194\n",
      "train loss:1.1305233830639423\n",
      "train loss:1.1803358148927259\n",
      "train loss:1.0660968241665982\n",
      "train loss:1.2038531016577576\n",
      "train loss:1.2154678696588332\n",
      "train loss:0.9525441646646731\n",
      "train loss:1.1209090520371416\n",
      "train loss:1.0421288860852862\n",
      "train loss:0.950464632181324\n",
      "train loss:1.0868140968122415\n",
      "train loss:1.061065857168426\n",
      "train loss:1.214016536396266\n",
      "train loss:1.1839277601350953\n",
      "train loss:1.123175039918677\n",
      "train loss:1.1339339657123668\n",
      "train loss:1.0120866568246405\n",
      "train loss:1.1583537557564738\n",
      "train loss:1.0654384639387877\n",
      "train loss:1.2099172157531672\n",
      "train loss:1.0432462372639701\n",
      "train loss:1.1492997796291782\n",
      "train loss:1.1169273704364588\n",
      "train loss:1.0503711281796762\n",
      "train loss:1.0264268775904923\n",
      "train loss:1.1622897117809798\n",
      "train loss:0.8995630766613522\n",
      "train loss:1.1016930412258217\n",
      "train loss:1.213140021365744\n",
      "train loss:1.0015865014767025\n",
      "train loss:1.013269997553943\n",
      "train loss:1.2160956302247945\n",
      "train loss:0.9739817334426988\n",
      "train loss:1.0333363153967363\n",
      "train loss:1.1791031992093912\n",
      "train loss:1.1128201704082246\n",
      "train loss:1.0982053105119498\n",
      "train loss:1.2553567686419735\n",
      "train loss:1.17291149742202\n",
      "train loss:0.9438414362775528\n",
      "train loss:0.971703486869599\n",
      "train loss:1.0874657217240566\n",
      "train loss:1.4095080575922712\n",
      "train loss:1.1600391950078859\n",
      "train loss:1.0829779507755892\n",
      "train loss:0.9407298755956464\n",
      "train loss:1.0608562878680137\n",
      "train loss:1.050377655179697\n",
      "train loss:1.1668377872714024\n",
      "train loss:1.039256612479322\n",
      "train loss:1.1139317524185088\n",
      "train loss:1.2254778585792057\n",
      "train loss:1.1189419326431898\n",
      "train loss:0.9216587032380401\n",
      "train loss:1.0867881696963504\n",
      "train loss:1.1191010327553528\n",
      "train loss:1.0203919921747855\n",
      "train loss:1.2354105282173047\n",
      "train loss:1.111592721261213\n",
      "train loss:1.2040219142629625\n",
      "train loss:1.0277997938650223\n",
      "train loss:1.0232827501550357\n",
      "train loss:1.2842564576689273\n",
      "train loss:1.151164332430019\n",
      "train loss:0.9606518398315557\n",
      "train loss:1.2847975716328606\n",
      "train loss:0.8859699772590475\n",
      "train loss:1.0659812725493554\n",
      "train loss:1.2299056163773852\n",
      "train loss:1.158908782365225\n",
      "train loss:1.2295958177200474\n",
      "train loss:1.1880301183498367\n",
      "train loss:1.220925981680683\n",
      "train loss:0.9299040446571639\n",
      "train loss:1.206237528119494\n",
      "train loss:1.1725796848734618\n",
      "train loss:1.1162113620075254\n",
      "train loss:1.0294136750523426\n",
      "train loss:1.1590504086992268\n",
      "train loss:1.1749123890704352\n",
      "train loss:1.0093775225954773\n",
      "train loss:1.1210281615966695\n",
      "train loss:1.0975186408334414\n",
      "train loss:1.0134961064883665\n",
      "train loss:1.0088088344757475\n",
      "train loss:0.9855783403668168\n",
      "train loss:1.1736649073597305\n",
      "train loss:0.992224754010681\n",
      "train loss:1.0846957222050961\n",
      "train loss:1.0535374569671183\n",
      "train loss:1.009405069999065\n",
      "train loss:1.2364847372243442\n",
      "train loss:1.031941093315441\n",
      "train loss:1.159178175743364\n",
      "train loss:1.1406663720733752\n",
      "train loss:1.0318098844235424\n",
      "train loss:1.2023737988660839\n",
      "train loss:1.0138588652202103\n",
      "train loss:1.2247096939604818\n",
      "train loss:1.147431071423753\n",
      "train loss:1.0926981423936\n",
      "train loss:1.167575632673074\n",
      "train loss:1.0968726470517491\n",
      "train loss:1.0999353585061329\n",
      "train loss:0.9618630318575748\n",
      "train loss:1.1824857543836662\n",
      "train loss:1.104179066663964\n",
      "train loss:1.0945382539073458\n",
      "train loss:1.0458098405279908\n",
      "train loss:0.9315075566482608\n",
      "train loss:1.1950641487663742\n",
      "train loss:1.0700132866595322\n",
      "train loss:1.0159998992106096\n",
      "train loss:1.1540742674301703\n",
      "train loss:1.1925661535308099\n",
      "train loss:1.152757396485906\n",
      "train loss:1.0262352068468459\n",
      "train loss:1.20524644444486\n",
      "train loss:1.0502533279727009\n",
      "train loss:1.1216054941059148\n",
      "train loss:0.9794160988316374\n",
      "train loss:1.0949298297710375\n",
      "train loss:0.9227569199409299\n",
      "train loss:1.0931990930926272\n",
      "train loss:0.9722693164932664\n",
      "train loss:1.0584905040813524\n",
      "train loss:0.9913781466142078\n",
      "train loss:1.1280265190129\n",
      "train loss:1.0059515496162135\n",
      "train loss:1.0245301972226206\n",
      "train loss:1.075425731443732\n",
      "train loss:1.0809486114005118\n",
      "train loss:1.0414640321275668\n",
      "train loss:0.8959857554363418\n",
      "train loss:0.9365018739420014\n",
      "train loss:1.0649064291340078\n",
      "train loss:0.9666612531948625\n",
      "train loss:1.1694415672271083\n",
      "train loss:1.0674596503612093\n",
      "train loss:0.9811666278403649\n",
      "train loss:1.258529327886784\n",
      "train loss:0.8446522596210078\n",
      "train loss:1.1094882496295888\n",
      "train loss:1.1350143322741837\n",
      "train loss:1.2250595432828744\n",
      "train loss:1.0629321984669275\n",
      "train loss:1.141431000146548\n",
      "train loss:1.2468279008834247\n",
      "train loss:0.9741046678714433\n",
      "train loss:0.9050352487954895\n",
      "train loss:1.0708320848760742\n",
      "train loss:1.2494948841497084\n",
      "train loss:0.8879595126813739\n",
      "train loss:1.153148200214777\n",
      "train loss:1.0296395879231732\n",
      "train loss:0.9685000795965938\n",
      "train loss:0.9887833583416924\n",
      "train loss:1.0403857529591942\n",
      "train loss:1.0470035627327077\n",
      "train loss:1.0017324041601008\n",
      "train loss:1.0423854607542637\n",
      "train loss:0.9490363778545887\n",
      "train loss:1.187001151725721\n",
      "train loss:1.1650806447404904\n",
      "train loss:1.1511021358062254\n",
      "train loss:1.2525452682189775\n",
      "train loss:1.0591946415215707\n",
      "train loss:1.0279657820338792\n",
      "train loss:1.0646410312567034\n",
      "train loss:1.098345716133753\n",
      "train loss:1.1730313724227048\n",
      "train loss:0.9783171795667198\n",
      "train loss:1.1058103574372293\n",
      "train loss:0.9274052206508395\n",
      "train loss:0.9913701988941864\n",
      "train loss:1.0896152569495006\n",
      "train loss:1.0677132054981116\n",
      "train loss:1.2110840832722234\n",
      "train loss:1.1895178624220444\n",
      "train loss:1.1115469379327225\n",
      "train loss:1.00966567469635\n",
      "train loss:0.9686138292292259\n",
      "train loss:1.1234939874841452\n",
      "train loss:1.0329561354592887\n",
      "train loss:1.2197521544466026\n",
      "train loss:0.9418487987048106\n",
      "train loss:1.134372016601533\n",
      "train loss:0.8642703047747906\n",
      "train loss:1.1966113375200065\n",
      "train loss:1.100388233867485\n",
      "train loss:1.1118692262561831\n",
      "train loss:1.0726018237693207\n",
      "train loss:0.9491202057155597\n",
      "train loss:1.2667422716964811\n",
      "train loss:1.159938734315122\n",
      "train loss:0.9943371799237251\n",
      "train loss:1.0594618916773\n",
      "train loss:1.0412771620013965\n",
      "train loss:0.8491283817338546\n",
      "train loss:1.0743100657992892\n",
      "train loss:1.1348679556410743\n",
      "train loss:1.1366750093278555\n",
      "train loss:0.9707231395406046\n",
      "train loss:1.0317470031538174\n",
      "train loss:0.9599444974486654\n",
      "train loss:1.1489718056533353\n",
      "train loss:1.1922244089987337\n",
      "train loss:1.191917672315682\n",
      "train loss:0.8075279730727799\n",
      "train loss:1.0544979429209063\n",
      "train loss:1.15124282879904\n",
      "train loss:1.1569020857736725\n",
      "train loss:1.0869353724468527\n",
      "train loss:1.0511310121940391\n",
      "train loss:1.268435556294941\n",
      "train loss:1.273721240707087\n",
      "train loss:1.0900180944270472\n",
      "train loss:1.0648704225590877\n",
      "train loss:1.063697583350209\n",
      "train loss:1.2916336860968547\n",
      "train loss:0.9984377431606023\n",
      "train loss:1.1289590187650294\n",
      "train loss:1.108254809674177\n",
      "train loss:0.9747104145195159\n",
      "train loss:1.2228431581464712\n",
      "train loss:1.2908719870990497\n",
      "train loss:0.957776724593939\n",
      "train loss:1.0561474431103752\n",
      "train loss:1.0951952462084613\n",
      "train loss:1.0430237493037924\n",
      "train loss:1.037044334857649\n",
      "train loss:1.1485660222948546\n",
      "train loss:1.1067066359206008\n",
      "train loss:1.1499362254822707\n",
      "train loss:1.232266087090538\n",
      "train loss:1.2609495161933366\n",
      "train loss:0.8990853489801828\n",
      "train loss:1.0495406780189602\n",
      "train loss:1.0092073237378718\n",
      "train loss:1.0175031552689666\n",
      "train loss:1.1201601222802697\n",
      "train loss:1.0653202042982566\n",
      "train loss:0.9905899250885116\n",
      "train loss:1.1519711336308338\n",
      "train loss:1.2407626331090698\n",
      "train loss:1.0318394253233223\n",
      "train loss:1.1933648833708925\n",
      "train loss:1.1468980421056403\n",
      "train loss:1.0054716590408643\n",
      "train loss:0.9637085900405047\n",
      "train loss:1.1599386219020267\n",
      "train loss:1.0312886772282546\n",
      "train loss:1.071673102747777\n",
      "train loss:1.154134150242789\n",
      "train loss:1.0430041444474798\n",
      "train loss:1.0030957578927522\n",
      "train loss:0.8053618306450094\n",
      "train loss:0.8754627853314163\n",
      "train loss:1.0538680547355623\n",
      "train loss:0.9408746240388104\n",
      "train loss:1.036929187539869\n",
      "train loss:1.3022524987113473\n",
      "train loss:1.2702363345499268\n",
      "train loss:1.2851732315293511\n",
      "train loss:1.1086183961576088\n",
      "train loss:1.1208619744231638\n",
      "train loss:1.136955834745651\n",
      "train loss:1.0639036909546649\n",
      "train loss:1.0203740027140988\n",
      "train loss:0.9418441800019558\n",
      "train loss:1.2530104243791345\n",
      "train loss:0.8886940967138408\n",
      "train loss:1.1880359521567572\n",
      "train loss:0.9975368192547304\n",
      "train loss:1.014169268678208\n",
      "train loss:1.0746237165487118\n",
      "train loss:1.0752948172264924\n",
      "train loss:1.2427188541838472\n",
      "train loss:1.1204885477585627\n",
      "train loss:1.1952626992081796\n",
      "train loss:1.1358752283124567\n",
      "train loss:1.1886820943022418\n",
      "train loss:1.17912497781507\n",
      "train loss:0.9975290103973875\n",
      "train loss:0.8950686884687425\n",
      "train loss:0.9641627009000672\n",
      "train loss:1.1820651755927747\n",
      "train loss:0.9689656922256955\n",
      "train loss:0.969308663856242\n",
      "train loss:0.8896917284655168\n",
      "train loss:1.005391365392998\n",
      "train loss:1.1107227755885472\n",
      "train loss:1.1556310886472518\n",
      "train loss:1.0094337393643977\n",
      "train loss:1.0689124691963527\n",
      "train loss:1.0380249745782557\n",
      "train loss:0.9780676749721589\n",
      "train loss:1.072360235929662\n",
      "train loss:1.2057244358767572\n",
      "train loss:0.9927096946885015\n",
      "train loss:1.1345506152328342\n",
      "train loss:0.9935102323061092\n",
      "train loss:1.1950004579119053\n",
      "train loss:1.0278049546522192\n",
      "train loss:0.9580869963654685\n",
      "train loss:1.1206703539299157\n",
      "train loss:0.9194071417476337\n",
      "train loss:0.9803026896368504\n",
      "train loss:1.0848047150962814\n",
      "train loss:0.9425701347362612\n",
      "train loss:1.1480822355176732\n",
      "train loss:1.0188920595250925\n",
      "train loss:1.0558185098336805\n",
      "train loss:1.1416464207668224\n",
      "train loss:1.08408104727133\n",
      "train loss:1.1446283173736098\n",
      "train loss:1.0643269874327874\n",
      "train loss:1.1609061762937567\n",
      "train loss:0.9544727844609934\n",
      "train loss:1.0478071241015827\n",
      "train loss:1.221458792597684\n",
      "train loss:1.214029979081839\n",
      "train loss:1.0842502431269505\n",
      "train loss:1.224128548545081\n",
      "train loss:0.9564599082667801\n",
      "train loss:1.0468306977372581\n",
      "train loss:0.9782525663313648\n",
      "train loss:1.1495371879181113\n",
      "train loss:1.01471016318959\n",
      "train loss:1.080981717882525\n",
      "train loss:1.059985978269213\n",
      "train loss:1.2797915585384556\n",
      "train loss:1.178763852982328\n",
      "train loss:1.0593980618826122\n",
      "train loss:0.9090857302508142\n",
      "train loss:1.0301354232879811\n",
      "train loss:1.132928117903908\n",
      "train loss:0.8738441380135584\n",
      "train loss:0.9801509757655381\n",
      "train loss:1.1522292943812709\n",
      "train loss:1.0570165081303977\n",
      "train loss:1.1468997215910428\n",
      "train loss:1.2093826237469032\n",
      "train loss:1.1698003237672177\n",
      "train loss:1.0914430947008373\n",
      "train loss:1.1379251516131952\n",
      "train loss:0.8863853816728795\n",
      "train loss:0.9357124698492946\n",
      "train loss:1.0830353257220136\n",
      "train loss:1.0074158218152425\n",
      "train loss:0.9621718129273941\n",
      "train loss:1.1660977824932406\n",
      "train loss:0.9677288618943533\n",
      "train loss:0.8961083259551635\n",
      "train loss:0.9206712722767137\n",
      "train loss:1.0056900274407208\n",
      "train loss:1.1506268893776102\n",
      "train loss:1.0712780499152483\n",
      "train loss:1.0646245640420384\n",
      "train loss:1.0661770187302555\n",
      "train loss:1.061551804607153\n",
      "train loss:1.2160041368376726\n",
      "train loss:0.9004739992905592\n",
      "train loss:1.1852963052765035\n",
      "train loss:1.0365287626582722\n",
      "train loss:0.8457574534886426\n",
      "train loss:0.907533757494747\n",
      "train loss:1.2852996246135726\n",
      "train loss:1.1464586953777276\n",
      "train loss:1.0799011754058006\n",
      "train loss:1.1101248983956749\n",
      "train loss:1.2205084712478673\n",
      "train loss:1.1809602636046312\n",
      "train loss:0.9057090478503187\n",
      "train loss:0.9987067750069843\n",
      "train loss:1.0282276133539485\n",
      "train loss:1.077590417660901\n",
      "train loss:1.0726416025651004\n",
      "train loss:1.0594353681791\n",
      "train loss:0.9772241612104581\n",
      "train loss:1.1400871241885413\n",
      "train loss:1.052829392393359\n",
      "train loss:0.9588845739845339\n",
      "train loss:1.1787609036293143\n",
      "train loss:1.20740178008484\n",
      "train loss:0.9526631218972006\n",
      "train loss:1.1290590457079839\n",
      "train loss:0.8761464851983054\n",
      "=== epoch:9, train acc:0.636, test acc:0.553 ===\n",
      "train loss:0.9831070343060988\n",
      "train loss:1.1002545801168824\n",
      "train loss:1.0718104640507313\n",
      "train loss:1.1300454029619862\n",
      "train loss:1.0758320298393613\n",
      "train loss:1.1566031175595446\n",
      "train loss:0.9845956330641955\n",
      "train loss:1.0628662738081807\n",
      "train loss:0.9458170563373755\n",
      "train loss:1.1627497002697667\n",
      "train loss:0.8934324022942219\n",
      "train loss:0.9553290258826843\n",
      "train loss:1.0599430588492573\n",
      "train loss:1.3629686779707557\n",
      "train loss:0.8784175095867229\n",
      "train loss:0.9730877858630579\n",
      "train loss:1.090724463475103\n",
      "train loss:1.1084770632716967\n",
      "train loss:1.032168214901953\n",
      "train loss:0.8849961784791625\n",
      "train loss:1.03435604793953\n",
      "train loss:1.1109057059305831\n",
      "train loss:0.9011503796066642\n",
      "train loss:1.0288997122098136\n",
      "train loss:1.0377762624692946\n",
      "train loss:0.9282469055847387\n",
      "train loss:1.2307127120605625\n",
      "train loss:1.1993682793734068\n",
      "train loss:0.8424292482863178\n",
      "train loss:1.2492647437713902\n",
      "train loss:1.0395148142139141\n",
      "train loss:1.0016498433062775\n",
      "train loss:1.1415497962748544\n",
      "train loss:1.007914981049882\n",
      "train loss:0.9743336410323059\n",
      "train loss:0.9996144280225152\n",
      "train loss:1.0757619292864453\n",
      "train loss:1.0240340311926643\n",
      "train loss:0.9222629792459129\n",
      "train loss:1.1624584257130548\n",
      "train loss:0.9140648124415997\n",
      "train loss:1.0582835985615369\n",
      "train loss:1.0687010017418714\n",
      "train loss:0.9518393113328157\n",
      "train loss:1.0144579442519588\n",
      "train loss:1.0021883951717612\n",
      "train loss:1.0041245394910914\n",
      "train loss:1.1094918379961116\n",
      "train loss:1.0606333992870436\n",
      "train loss:0.9215671182254074\n",
      "train loss:0.8889717562987255\n",
      "train loss:1.135600779896707\n",
      "train loss:1.0075394777101208\n",
      "train loss:0.9328131020045024\n",
      "train loss:1.1190814869947407\n",
      "train loss:1.2380763560698793\n",
      "train loss:1.0484674786210724\n",
      "train loss:1.1531592039683176\n",
      "train loss:1.1275582209647157\n",
      "train loss:0.9141992816275233\n",
      "train loss:1.040167827961171\n",
      "train loss:1.092185213298318\n",
      "train loss:1.1007851912855546\n",
      "train loss:0.9526301706335544\n",
      "train loss:1.0340905454400597\n",
      "train loss:0.91315078959268\n",
      "train loss:1.3700014852870124\n",
      "train loss:1.2262991512828911\n",
      "train loss:1.0696515625396814\n",
      "train loss:0.9423205313985679\n",
      "train loss:1.1073471503092673\n",
      "train loss:1.2284617003505438\n",
      "train loss:1.127987114562118\n",
      "train loss:0.8927119751795703\n",
      "train loss:1.2225881026650849\n",
      "train loss:0.938018858052274\n",
      "train loss:0.936203089629898\n",
      "train loss:0.9523101559141385\n",
      "train loss:1.1984847128808969\n",
      "train loss:1.1453382942835117\n",
      "train loss:1.011928060273091\n",
      "train loss:1.2262480105760696\n",
      "train loss:1.0859311118390762\n",
      "train loss:1.246940603825661\n",
      "train loss:1.0519122487583645\n",
      "train loss:1.00001975562263\n",
      "train loss:0.991907400574929\n",
      "train loss:1.1392294268166765\n",
      "train loss:1.0095934759614738\n",
      "train loss:1.1098983352352563\n",
      "train loss:1.0029006828698463\n",
      "train loss:1.0805264493028204\n",
      "train loss:1.0398915457948275\n",
      "train loss:0.9459556946691688\n",
      "train loss:1.1099704155483967\n",
      "train loss:1.1252542835084056\n",
      "train loss:0.9950381117587649\n",
      "train loss:1.094327464438039\n",
      "train loss:0.8431711143010265\n",
      "train loss:1.017671757582669\n",
      "train loss:0.914415869372392\n",
      "train loss:1.0116378019026064\n",
      "train loss:1.0988704647599232\n",
      "train loss:1.140019019163234\n",
      "train loss:0.9760822149230787\n",
      "train loss:1.0190516040339919\n",
      "train loss:1.0339636243807526\n",
      "train loss:1.0154827475987696\n",
      "train loss:0.9782771838904246\n",
      "train loss:1.000732736099117\n",
      "train loss:1.078311985358892\n",
      "train loss:0.950547962398482\n",
      "train loss:1.1451065391556292\n",
      "train loss:1.0656428579073203\n",
      "train loss:0.8623598271085932\n",
      "train loss:0.9651552280122044\n",
      "train loss:0.9160974580288734\n",
      "train loss:1.2200853043094488\n",
      "train loss:1.124388342604895\n",
      "train loss:0.9557182988272044\n",
      "train loss:0.8510043619882219\n",
      "train loss:1.0685539287695436\n",
      "train loss:1.0565335537649339\n",
      "train loss:1.1999404772280582\n",
      "train loss:1.0043102747018333\n",
      "train loss:1.0689022175482217\n",
      "train loss:0.9798168015568082\n",
      "train loss:0.9538713761994785\n",
      "train loss:0.8779636612811469\n",
      "train loss:1.1119125889032602\n",
      "train loss:1.1609578991388942\n",
      "train loss:0.9034900986055926\n",
      "train loss:1.0760670518662885\n",
      "train loss:1.0281524816384102\n",
      "train loss:0.9995716158924239\n",
      "train loss:0.9705854179658716\n",
      "train loss:1.0706365516646528\n",
      "train loss:1.186599594842594\n",
      "train loss:1.0754146665539097\n",
      "train loss:1.0676491756889086\n",
      "train loss:0.987849225780528\n",
      "train loss:1.1655024431791576\n",
      "train loss:1.0046077894987702\n",
      "train loss:1.126358578631966\n",
      "train loss:0.9220544396997994\n",
      "train loss:1.1797745026465147\n",
      "train loss:1.006833181930416\n",
      "train loss:0.9601043749167495\n",
      "train loss:0.9448279741213745\n",
      "train loss:1.0774351234379995\n",
      "train loss:0.9164165915690594\n",
      "train loss:1.0083989893348133\n",
      "train loss:1.3221998202481142\n",
      "train loss:1.0653803643641206\n",
      "train loss:1.0455736213731983\n",
      "train loss:0.9642332115506688\n",
      "train loss:0.9549637345999389\n",
      "train loss:1.058419716355553\n",
      "train loss:1.0051232875682898\n",
      "train loss:1.0316714694520028\n",
      "train loss:0.9794680271045766\n",
      "train loss:0.9575971743593983\n",
      "train loss:0.8869231192881684\n",
      "train loss:1.0071408111103262\n",
      "train loss:0.8771407908685127\n",
      "train loss:0.9991051113571278\n",
      "train loss:1.1078655769598176\n",
      "train loss:1.1572318247763738\n",
      "train loss:0.9653657846822314\n",
      "train loss:1.0549956204223603\n",
      "train loss:1.1700479780339315\n",
      "train loss:1.1721229451488875\n",
      "train loss:1.0821615076037547\n",
      "train loss:1.1579170242422843\n",
      "train loss:0.9393094343995181\n",
      "train loss:0.9622823268501989\n",
      "train loss:0.946135683514725\n",
      "train loss:0.9895077653531169\n",
      "train loss:0.9075478304974568\n",
      "train loss:0.952393552241929\n",
      "train loss:1.0132810128149445\n",
      "train loss:1.0695727905374506\n",
      "train loss:1.1507481452768722\n",
      "train loss:0.9869998310744773\n",
      "train loss:0.941984439364105\n",
      "train loss:1.007552774000484\n",
      "train loss:0.9195672675401593\n",
      "train loss:0.9442799784909632\n",
      "train loss:0.9618345609486396\n",
      "train loss:1.2476539349299447\n",
      "train loss:1.0946403109657634\n",
      "train loss:1.2275597322466079\n",
      "train loss:0.9825246305295553\n",
      "train loss:0.9941654976931744\n",
      "train loss:1.0525053228359704\n",
      "train loss:1.053022236707957\n",
      "train loss:0.995765846804171\n",
      "train loss:0.9061270147972923\n",
      "train loss:0.9991551895808662\n",
      "train loss:1.109754297052081\n",
      "train loss:1.0967297197462087\n",
      "train loss:1.1411042630075545\n",
      "train loss:1.0720649136612899\n",
      "train loss:1.164238757405976\n",
      "train loss:0.9848786921540968\n",
      "train loss:0.9856804456493796\n",
      "train loss:0.8317473302119928\n",
      "train loss:1.0338298955547116\n",
      "train loss:1.026392945639916\n",
      "train loss:1.0876649680580328\n",
      "train loss:0.8947496973284178\n",
      "train loss:0.8311317227316317\n",
      "train loss:1.0239867420756465\n",
      "train loss:1.1180549660016252\n",
      "train loss:0.9499108961538617\n",
      "train loss:1.257949717393779\n",
      "train loss:1.0850144640562198\n",
      "train loss:0.8814759885103985\n",
      "train loss:1.1726171796837501\n",
      "train loss:0.9728542000202228\n",
      "train loss:0.8734315807999679\n",
      "train loss:1.0255869943238705\n",
      "train loss:0.9891074995064809\n",
      "train loss:0.9272144694018845\n",
      "train loss:1.0025474686800773\n",
      "train loss:1.1723618778468516\n",
      "train loss:0.9568322058701996\n",
      "train loss:1.1919321575785256\n",
      "train loss:1.010467112274747\n",
      "train loss:1.1987524270782794\n",
      "train loss:1.002764165575138\n",
      "train loss:0.8747066176878789\n",
      "train loss:0.9854467871833903\n",
      "train loss:1.1040099189500894\n",
      "train loss:1.072833319513206\n",
      "train loss:1.0490426115053386\n",
      "train loss:0.9541815413634496\n",
      "train loss:1.0645822439513146\n",
      "train loss:0.9456155352671978\n",
      "train loss:0.8768937535448944\n",
      "train loss:1.229041915187361\n",
      "train loss:0.931528947906487\n",
      "train loss:1.1617831478141891\n",
      "train loss:0.8598881193922828\n",
      "train loss:0.8454652592460405\n",
      "train loss:0.8394637913661043\n",
      "train loss:1.0190690782695049\n",
      "train loss:1.0253961988390563\n",
      "train loss:1.0656872921112335\n",
      "train loss:1.16944891024359\n",
      "train loss:0.9999549037859488\n",
      "train loss:1.0869491973429324\n",
      "train loss:1.0474756132897758\n",
      "train loss:0.9798487164994027\n",
      "train loss:0.8619971270206256\n",
      "train loss:0.9542769059847656\n",
      "train loss:0.909217814658901\n",
      "train loss:0.9079414730551167\n",
      "train loss:0.927353496280875\n",
      "train loss:0.9285250039118715\n",
      "train loss:0.9652254775967297\n",
      "train loss:0.8365957050955555\n",
      "train loss:0.975119799670589\n",
      "train loss:1.2424935170177782\n",
      "train loss:1.0943491335341353\n",
      "train loss:1.2777971244312991\n",
      "train loss:1.0982722349915528\n",
      "train loss:1.1246263374738317\n",
      "train loss:1.190343703438729\n",
      "train loss:0.9900401183884739\n",
      "train loss:1.0336765815387945\n",
      "train loss:1.072875570893891\n",
      "train loss:0.9599541153802577\n",
      "train loss:0.93007612838835\n",
      "train loss:1.0352535528339737\n",
      "train loss:1.062721730049125\n",
      "train loss:1.008068759607045\n",
      "train loss:1.0618297189149395\n",
      "train loss:1.0103854627698696\n",
      "train loss:0.9290327417040884\n",
      "train loss:1.0405120878638794\n",
      "train loss:0.965585287333236\n",
      "train loss:1.0750174231574263\n",
      "train loss:0.9125586230213532\n",
      "train loss:1.2831665931489908\n",
      "train loss:1.0452560926956997\n",
      "train loss:1.1222401524228756\n",
      "train loss:0.9790022100372013\n",
      "train loss:1.0159742806556518\n",
      "train loss:0.9162976122940626\n",
      "train loss:0.9174543878950542\n",
      "train loss:1.1653431577214264\n",
      "train loss:0.9861337168689898\n",
      "train loss:1.1155040124159408\n",
      "train loss:0.9940753619692404\n",
      "train loss:1.0233051726895142\n",
      "train loss:0.961832962994915\n",
      "train loss:1.2292723466055682\n",
      "train loss:1.2643864117396633\n",
      "train loss:0.9659691642277519\n",
      "train loss:1.0729246174702054\n",
      "train loss:1.0782649778710933\n",
      "train loss:1.043688683261035\n",
      "train loss:0.8266448269938329\n",
      "train loss:1.0256315757968322\n",
      "train loss:0.9052520443765072\n",
      "train loss:1.0780481530923935\n",
      "train loss:0.9937932790334159\n",
      "train loss:1.0075999046630089\n",
      "train loss:1.1629817800466682\n",
      "train loss:1.136495300847415\n",
      "train loss:1.0384619923189795\n",
      "train loss:1.107153214550482\n",
      "train loss:0.9359805772283238\n",
      "train loss:1.0749490525762326\n",
      "train loss:1.015636041487661\n",
      "train loss:1.0522387502573936\n",
      "train loss:1.0487729519352107\n",
      "train loss:1.0089369300007611\n",
      "train loss:0.9721992591672142\n",
      "train loss:1.0423341865893117\n",
      "train loss:1.10270333636064\n",
      "train loss:1.1162183191960822\n",
      "train loss:1.000320500842255\n",
      "train loss:1.0489909457331306\n",
      "train loss:1.1194419932235546\n",
      "train loss:1.118016480722531\n",
      "train loss:1.1292896632774936\n",
      "train loss:1.0890488099088331\n",
      "train loss:0.9730327136272982\n",
      "train loss:1.121853631918783\n",
      "train loss:1.0095932929583737\n",
      "train loss:0.9869155137255189\n",
      "train loss:1.0454040414369112\n",
      "train loss:1.0742651299697383\n",
      "train loss:0.9899668488579862\n",
      "train loss:1.0111545019534827\n",
      "train loss:0.9849827109115951\n",
      "train loss:1.0060754241109697\n",
      "train loss:1.0958526907922561\n",
      "train loss:1.123466977653324\n",
      "train loss:1.0602208819432049\n",
      "train loss:0.998602303393807\n",
      "train loss:1.1695523766304385\n",
      "train loss:1.095932177814131\n",
      "train loss:1.1337817704818431\n",
      "train loss:0.9167041839217126\n",
      "train loss:1.0533527630535635\n",
      "train loss:0.9687398778972668\n",
      "train loss:0.9711865031852127\n",
      "train loss:1.1184419106425083\n",
      "train loss:1.1640259213187187\n",
      "train loss:1.1105037169617489\n",
      "train loss:1.170899559040381\n",
      "train loss:0.9973688545688959\n",
      "train loss:0.8924488115847474\n",
      "train loss:0.8567335416603302\n",
      "train loss:1.1584973385060742\n",
      "train loss:1.020426546785607\n",
      "train loss:0.96123619416807\n",
      "train loss:1.2017118274181235\n",
      "train loss:0.957934643531256\n",
      "train loss:1.0276938680793395\n",
      "train loss:1.0153725339384734\n",
      "train loss:1.2363530525329403\n",
      "train loss:1.0197673015993924\n",
      "train loss:0.9756812776082421\n",
      "train loss:0.9944958462876717\n",
      "train loss:0.8386242094286703\n",
      "train loss:0.9362403160153498\n",
      "train loss:1.097673610167923\n",
      "train loss:1.155207360542379\n",
      "train loss:1.006230390464395\n",
      "train loss:0.9706680192983039\n",
      "train loss:0.9330440609181894\n",
      "train loss:0.8457136676152114\n",
      "train loss:1.0230436874992683\n",
      "train loss:0.9022120046491071\n",
      "train loss:1.0798434903364416\n",
      "train loss:1.1563776195032043\n",
      "train loss:0.9072728181207229\n",
      "train loss:1.0802249430290325\n",
      "train loss:1.113731741533179\n",
      "train loss:1.1922248279950494\n",
      "train loss:1.0303800363968758\n",
      "train loss:1.1955411146318555\n",
      "train loss:1.1362615580981659\n",
      "train loss:1.0344718806420528\n",
      "train loss:1.1844546691348774\n",
      "train loss:1.057115169162593\n",
      "train loss:0.9854585856668442\n",
      "train loss:0.9926750971703412\n",
      "train loss:0.913799294336552\n",
      "train loss:0.9174247782010586\n",
      "train loss:1.073271429568355\n",
      "train loss:1.0097377530433598\n",
      "train loss:0.9971564761539409\n",
      "train loss:1.0297620461974837\n",
      "train loss:0.8164065400712741\n",
      "train loss:0.9302052695713844\n",
      "=== epoch:10, train acc:0.683, test acc:0.574 ===\n",
      "train loss:0.9154931972185071\n",
      "train loss:0.9996320163758822\n",
      "train loss:0.8851949877847285\n",
      "train loss:1.1895409156467764\n",
      "train loss:1.0327803406928966\n",
      "train loss:0.9418020889824633\n",
      "train loss:0.968745480538488\n",
      "train loss:0.9869592880353416\n",
      "train loss:1.0865029591343351\n",
      "train loss:0.8934997664286572\n",
      "train loss:0.8307062267063707\n",
      "train loss:1.045496589871138\n",
      "train loss:0.9178463308894186\n",
      "train loss:0.9921179859869865\n",
      "train loss:1.0394356613516438\n",
      "train loss:1.1246461623403423\n",
      "train loss:1.2378549630189868\n",
      "train loss:1.2111831763138516\n",
      "train loss:0.960235111010531\n",
      "train loss:0.8431120647600391\n",
      "train loss:1.1295391064190055\n",
      "train loss:1.1216389520992542\n",
      "train loss:1.0318572176375767\n",
      "train loss:1.0039068559137512\n",
      "train loss:0.8508523888894021\n",
      "train loss:1.1564126759262918\n",
      "train loss:0.9987533309808565\n",
      "train loss:0.9420366671671038\n",
      "train loss:0.8333115047927461\n",
      "train loss:0.9516997301041954\n",
      "train loss:0.9485364662051657\n",
      "train loss:1.126419022095118\n",
      "train loss:0.9126150345078817\n",
      "train loss:1.1167661311383115\n",
      "train loss:1.1621709613267903\n",
      "train loss:1.1184405265538069\n",
      "train loss:1.0579977709864412\n",
      "train loss:1.1443957559358315\n",
      "train loss:1.0856413220567258\n",
      "train loss:0.9772420001600082\n",
      "train loss:1.0823403374383032\n",
      "train loss:1.089738391321722\n",
      "train loss:0.8784205424311246\n",
      "train loss:1.0166061984205457\n",
      "train loss:0.9581671405644678\n",
      "train loss:0.8909593395328982\n",
      "train loss:0.9900424486646952\n",
      "train loss:0.9858761562301034\n",
      "train loss:0.984137786254138\n",
      "train loss:1.0191697232968366\n",
      "train loss:1.0401645878370192\n",
      "train loss:1.0328472801455795\n",
      "train loss:1.1484142765230805\n",
      "train loss:1.2318181013896663\n",
      "train loss:1.1499714072127845\n",
      "train loss:1.0268599463686736\n",
      "train loss:1.1324751282189123\n",
      "train loss:1.0299588655991152\n",
      "train loss:1.0524175888432858\n",
      "train loss:0.9199567636247683\n",
      "train loss:0.9451479867573318\n",
      "train loss:1.0321783292733897\n",
      "train loss:0.8638175742006928\n",
      "train loss:0.8409833091210165\n",
      "train loss:1.089925907800495\n",
      "train loss:1.0810057190706683\n",
      "train loss:1.0520417795870687\n",
      "train loss:0.9449823764330374\n",
      "train loss:1.1568236641307914\n",
      "train loss:1.2229801324136447\n",
      "train loss:0.9826634961372348\n",
      "train loss:0.9801840710348186\n",
      "train loss:0.9042521594962146\n",
      "train loss:1.0168656498028192\n",
      "train loss:1.0295010235386928\n",
      "train loss:0.9464005151913291\n",
      "train loss:1.0705393324742989\n",
      "train loss:1.0377357054996914\n",
      "train loss:1.0154620809499715\n",
      "train loss:0.945255550674556\n",
      "train loss:0.9910468327863622\n",
      "train loss:1.006951452378346\n",
      "train loss:1.0350786982051574\n",
      "train loss:0.9923886540817938\n",
      "train loss:0.9359241914595267\n",
      "train loss:0.869132857344955\n",
      "train loss:1.0524279864132615\n",
      "train loss:1.0293016787537015\n",
      "train loss:0.9967467371275458\n",
      "train loss:0.9081939851642654\n",
      "train loss:1.0818625903982138\n",
      "train loss:0.8960038054677812\n",
      "train loss:1.011037577876\n",
      "train loss:0.9835708775300338\n",
      "train loss:1.1022624385414006\n",
      "train loss:0.7810551331077298\n",
      "train loss:1.1902611433081869\n",
      "train loss:1.1986230236629474\n",
      "train loss:1.0608982836435812\n",
      "train loss:1.0111355704224136\n",
      "train loss:1.0923000478956304\n",
      "train loss:0.962473066007839\n",
      "train loss:0.9622441842571773\n",
      "train loss:1.1808737249676116\n",
      "train loss:1.019923918553998\n",
      "train loss:0.9823594853986346\n",
      "train loss:0.8334713535130948\n",
      "train loss:0.8944453458651226\n",
      "train loss:1.0685519808945536\n",
      "train loss:0.9922720966066487\n",
      "train loss:0.9744231767774556\n",
      "train loss:0.9386351694977728\n",
      "train loss:1.1897059757085424\n",
      "train loss:1.0182441309576082\n",
      "train loss:0.979153737177778\n",
      "train loss:1.0205408256923176\n",
      "train loss:1.0680218268635402\n",
      "train loss:1.0677074574763301\n",
      "train loss:0.9309039892138248\n",
      "train loss:0.9792224042678922\n",
      "train loss:1.0806050660575188\n",
      "train loss:0.9552889041836976\n",
      "train loss:0.9919689750692565\n",
      "train loss:0.9205068536929142\n",
      "train loss:1.0450523981289281\n",
      "train loss:0.7970030476836597\n",
      "train loss:0.9247512030435339\n",
      "train loss:1.0940707431050594\n",
      "train loss:0.7633747630847253\n",
      "train loss:0.8432487101256227\n",
      "train loss:1.0022058256359339\n",
      "train loss:0.9651956025083166\n",
      "train loss:1.0164649318611914\n",
      "train loss:0.959843139892283\n",
      "train loss:0.8140175265861727\n",
      "train loss:1.1751142668950825\n",
      "train loss:1.0961501203781827\n",
      "train loss:0.8832560346583381\n",
      "train loss:0.8683673703843872\n",
      "train loss:0.874197594747676\n",
      "train loss:0.8926833583565813\n",
      "train loss:0.8827017422725681\n",
      "train loss:1.1787718151574722\n",
      "train loss:1.070238609282041\n",
      "train loss:0.7628810959180474\n",
      "train loss:1.0676288814050294\n",
      "train loss:1.04179628951817\n",
      "train loss:0.886886645704433\n",
      "train loss:0.8435848990424359\n",
      "train loss:1.033693370131392\n",
      "train loss:0.9896709627216501\n",
      "train loss:1.1234832840210272\n",
      "train loss:1.0233843645821117\n",
      "train loss:1.0582661047285102\n",
      "train loss:1.1339790095544708\n",
      "train loss:1.0170956112164249\n",
      "train loss:1.012329629400779\n",
      "train loss:0.948936240213949\n",
      "train loss:1.0747685823178208\n",
      "train loss:0.950506950067235\n",
      "train loss:0.9764258854802594\n",
      "train loss:1.135834704375853\n",
      "train loss:1.0191160901599683\n",
      "train loss:1.0834287669877323\n",
      "train loss:0.9294595677336709\n",
      "train loss:0.8917759666392961\n",
      "train loss:1.0854852443741212\n",
      "train loss:1.0728826895648311\n",
      "train loss:0.9926958375888829\n",
      "train loss:0.8486067107745952\n",
      "train loss:0.9448169706470718\n",
      "train loss:0.9072763298981893\n",
      "train loss:0.8927459746028426\n",
      "train loss:0.9581773522543052\n",
      "train loss:1.0671881877238856\n",
      "train loss:1.0717218586488735\n",
      "train loss:0.9373297433299648\n",
      "train loss:1.0812593181190298\n",
      "train loss:1.0850660702507606\n",
      "train loss:0.840632165908008\n",
      "train loss:0.9862453844639737\n",
      "train loss:1.0025403313938264\n",
      "train loss:1.1224804965542106\n",
      "train loss:0.9310326057140518\n",
      "train loss:0.9079907673628695\n",
      "train loss:0.9066580744937057\n",
      "train loss:0.9423846224933189\n",
      "train loss:1.1034699127771967\n",
      "train loss:1.0331709181943607\n",
      "train loss:0.9983729540621993\n",
      "train loss:1.053525926497179\n",
      "train loss:0.8725509682241137\n",
      "train loss:0.8753618096574375\n",
      "train loss:1.10249028135848\n",
      "train loss:0.7669583836682154\n",
      "train loss:1.0686880523424547\n",
      "train loss:0.916242451034598\n",
      "train loss:1.0144748147467293\n",
      "train loss:1.01001001768213\n",
      "train loss:1.0322607845315726\n",
      "train loss:1.0607178751571436\n",
      "train loss:1.0894688324998176\n",
      "train loss:1.125054912986453\n",
      "train loss:0.8396601219004157\n",
      "train loss:1.1793403384507846\n",
      "train loss:0.9144677195598213\n",
      "train loss:0.8560293344885506\n",
      "train loss:1.0075883673060426\n",
      "train loss:0.989655266581134\n",
      "train loss:1.010825621812307\n",
      "train loss:0.939541128274033\n",
      "train loss:1.1194710992202452\n",
      "train loss:0.9469398904088614\n",
      "train loss:0.7842799987953213\n",
      "train loss:1.0942111729110793\n",
      "train loss:1.0222749349766305\n",
      "train loss:0.9862161625881711\n",
      "train loss:1.108905359728828\n",
      "train loss:1.0807963648001764\n",
      "train loss:0.9692457554222128\n",
      "train loss:0.864387865111701\n",
      "train loss:0.9280299391817907\n",
      "train loss:0.9427948996619595\n",
      "train loss:1.1270386692572278\n",
      "train loss:1.1712736405203676\n",
      "train loss:0.8791566778670722\n",
      "train loss:1.1217281012542089\n",
      "train loss:1.0175055945534914\n",
      "train loss:1.022716270980858\n",
      "train loss:1.003327095602017\n",
      "train loss:1.0113961694636189\n",
      "train loss:1.04014107196118\n",
      "train loss:0.8776762821333493\n",
      "train loss:1.0361153685761657\n",
      "train loss:1.113672442623448\n",
      "train loss:0.9406246044132267\n",
      "train loss:0.9108543010492385\n",
      "train loss:0.8360931120064012\n",
      "train loss:0.9885510290622669\n",
      "train loss:0.831499813179666\n",
      "train loss:1.012534862954678\n",
      "train loss:1.0960415190520043\n",
      "train loss:0.9830194950864967\n",
      "train loss:0.7400088323580767\n",
      "train loss:1.0241105903492618\n",
      "train loss:1.2813728092926417\n",
      "train loss:0.9529864218068751\n",
      "train loss:0.8487939968808711\n",
      "train loss:0.9849806091148909\n",
      "train loss:1.0215969971469105\n",
      "train loss:1.0229385611140285\n",
      "train loss:0.9387471499506753\n",
      "train loss:1.0637137300462012\n",
      "train loss:1.0950612415217151\n",
      "train loss:0.9698148322459992\n",
      "train loss:0.8284213642743429\n",
      "train loss:1.0422175046969238\n",
      "train loss:1.1133369804730295\n",
      "train loss:1.1231558999537068\n",
      "train loss:0.9695048505914236\n",
      "train loss:0.9645220584250073\n",
      "train loss:0.9694057168773996\n",
      "train loss:1.1233593410177005\n",
      "train loss:0.9993860003106234\n",
      "train loss:0.8603784251870824\n",
      "train loss:0.8741920637174886\n",
      "train loss:1.0040191012304758\n",
      "train loss:0.9900237618983226\n",
      "train loss:0.9287779267323159\n",
      "train loss:1.0826472314638398\n",
      "train loss:1.0210891795857648\n",
      "train loss:1.0662534974871927\n",
      "train loss:1.0101743416846536\n",
      "train loss:1.2370348477893713\n",
      "train loss:1.0096631693917812\n",
      "train loss:0.863594588462966\n",
      "train loss:1.0200022496854393\n",
      "train loss:1.082500940688022\n",
      "train loss:0.9459637622903814\n",
      "train loss:1.055392834024277\n",
      "train loss:1.0122122744743305\n",
      "train loss:0.9553147214790622\n",
      "train loss:0.9397403905921091\n",
      "train loss:0.9276154784952136\n",
      "train loss:0.884983939837366\n",
      "train loss:1.1962272584559563\n",
      "train loss:1.0387149343679234\n",
      "train loss:1.0237382210751615\n",
      "train loss:0.7901988427199855\n",
      "train loss:1.0707373928132895\n",
      "train loss:1.0607949838783892\n",
      "train loss:0.9858777896785448\n",
      "train loss:0.9473477767076548\n",
      "train loss:0.8622936353457891\n",
      "train loss:1.0360535661174337\n",
      "train loss:1.1123756544468786\n",
      "train loss:1.1795501553767291\n",
      "train loss:0.8182609441022913\n",
      "train loss:1.0319092280078106\n",
      "train loss:0.8878783222164062\n",
      "train loss:0.988495952893891\n",
      "train loss:0.9231106534550527\n",
      "train loss:0.8473902385962013\n",
      "train loss:1.0462962654975336\n",
      "train loss:0.9531536589744287\n",
      "train loss:1.0834912684453242\n",
      "train loss:0.9382171159245342\n",
      "train loss:0.9950471114077911\n",
      "train loss:1.0874616899283158\n",
      "train loss:0.9531670825054986\n",
      "train loss:1.1769359648288367\n",
      "train loss:1.022396410701127\n",
      "train loss:0.968322404683567\n",
      "train loss:0.8955596272938671\n",
      "train loss:0.9336082673277154\n",
      "train loss:0.9590640606540132\n",
      "train loss:1.0900193548428339\n",
      "train loss:1.0978166165235679\n",
      "train loss:0.9199525926651484\n",
      "train loss:0.8877421175049384\n",
      "train loss:1.0074562681496673\n",
      "train loss:0.874002928591476\n",
      "train loss:0.9303776749761787\n",
      "train loss:1.0788675839169874\n",
      "train loss:0.9463476868081802\n",
      "train loss:1.2726413905585883\n",
      "train loss:1.0952407855477329\n",
      "train loss:0.9375416554329086\n",
      "train loss:1.0296890935394976\n",
      "train loss:1.0202650465163137\n",
      "train loss:0.8497604418251251\n",
      "train loss:0.8935701112662173\n",
      "train loss:1.1085531647270606\n",
      "train loss:0.7435242532640678\n",
      "train loss:0.9975092850702548\n",
      "train loss:0.8531954037988498\n",
      "train loss:0.9145933967991857\n",
      "train loss:0.9435451307576652\n",
      "train loss:0.8839842628165541\n",
      "train loss:1.1596414144128881\n",
      "train loss:1.031729427361575\n",
      "train loss:0.9037836871720912\n",
      "train loss:1.0548654724089226\n",
      "train loss:0.9249948450423129\n",
      "train loss:0.9958342218957098\n",
      "train loss:0.8524120722052914\n",
      "train loss:0.8981733254318371\n",
      "train loss:0.7741863643026708\n",
      "train loss:0.7167356025781736\n",
      "train loss:0.8169056231414537\n",
      "train loss:0.9016078314018355\n",
      "train loss:1.0380656065675569\n",
      "train loss:0.9357083174916574\n",
      "train loss:0.9960637722863729\n",
      "train loss:1.3032280555767537\n",
      "train loss:0.8478832256645668\n",
      "train loss:0.9249345572226217\n",
      "train loss:1.0391387143821076\n",
      "train loss:1.147764373772278\n",
      "train loss:1.0340753039600716\n",
      "train loss:0.9243224483669763\n",
      "train loss:1.1168795204265427\n",
      "train loss:1.0044843329020683\n",
      "train loss:1.070804792890308\n",
      "train loss:1.105322102660467\n",
      "train loss:0.9431986919276318\n",
      "train loss:1.2532280830223663\n",
      "train loss:1.020049841629878\n",
      "train loss:0.9609720841031725\n",
      "train loss:1.0475283688787613\n",
      "train loss:1.009430545124079\n",
      "train loss:1.0883813554989827\n",
      "train loss:1.0599573953955426\n",
      "train loss:0.8182538142843504\n",
      "train loss:1.0328696365008703\n",
      "train loss:0.9602427567509594\n",
      "train loss:1.0412949157691278\n",
      "train loss:1.0774031264773143\n",
      "train loss:0.8490712807351586\n",
      "train loss:0.978874003616495\n",
      "train loss:1.0370660027120284\n",
      "train loss:0.8302927376845075\n",
      "train loss:0.9467158275044347\n",
      "train loss:1.0380549758399271\n",
      "train loss:1.0748958167970022\n",
      "train loss:1.0622826059734658\n",
      "train loss:0.9136298375768473\n",
      "train loss:0.8326113736289829\n",
      "train loss:1.0009893940960155\n",
      "train loss:0.9463426189372354\n",
      "train loss:0.9272094238793558\n",
      "train loss:0.9335908260996787\n",
      "train loss:0.8142826742444029\n",
      "train loss:0.9500251461797251\n",
      "train loss:1.104235752963074\n",
      "train loss:0.7855024443351648\n",
      "train loss:1.0750808664729867\n",
      "train loss:1.0283801895459264\n",
      "train loss:1.0460354329698682\n",
      "train loss:1.0102202166375813\n",
      "=== epoch:11, train acc:0.679, test acc:0.568 ===\n",
      "train loss:1.0112614224105108\n",
      "train loss:1.1576173484507597\n",
      "train loss:0.8227662595478503\n",
      "train loss:1.006581272369815\n",
      "train loss:0.7724215209291847\n",
      "train loss:1.0656048256294055\n",
      "train loss:1.1922023221712756\n",
      "train loss:1.1289478335686036\n",
      "train loss:1.037991969103169\n",
      "train loss:1.0952715151582633\n",
      "train loss:0.86164187156054\n",
      "train loss:0.9273660494231936\n",
      "train loss:1.1604950605523872\n",
      "train loss:1.3287751393936436\n",
      "train loss:1.067674593453364\n",
      "train loss:0.9782210666473325\n",
      "train loss:1.0025160292858175\n",
      "train loss:1.0339243397652726\n",
      "train loss:0.9417429068423243\n",
      "train loss:0.8254674694164349\n",
      "train loss:0.8340504039617207\n",
      "train loss:0.8814305516497895\n",
      "train loss:1.0038181453350665\n",
      "train loss:0.9895167059674947\n",
      "train loss:0.9317792517667088\n",
      "train loss:0.9299488763390553\n",
      "train loss:0.9758251731695446\n",
      "train loss:1.0523810567174405\n",
      "train loss:0.9585348805209073\n",
      "train loss:0.8546613177539167\n",
      "train loss:0.9227433667982646\n",
      "train loss:0.8709692223339982\n",
      "train loss:0.8832028542880305\n",
      "train loss:0.7633337192341031\n",
      "train loss:0.9164361921929427\n",
      "train loss:0.9210871828146254\n",
      "train loss:0.9406338044499152\n",
      "train loss:1.0277521157870955\n",
      "train loss:1.0443568561231091\n",
      "train loss:1.1468236800527567\n",
      "train loss:0.9825917853081662\n",
      "train loss:0.863052740530007\n",
      "train loss:0.9758594495694533\n",
      "train loss:1.0382179319096583\n",
      "train loss:0.9862893327658381\n",
      "train loss:0.8831823825085414\n",
      "train loss:0.9267643207894299\n",
      "train loss:0.9465666648562956\n",
      "train loss:0.972499439999511\n",
      "train loss:0.9081041366534509\n",
      "train loss:0.9383239295682287\n",
      "train loss:1.0532457994783828\n",
      "train loss:0.9526152896360601\n",
      "train loss:1.0986357523253778\n",
      "train loss:0.9442293390669718\n",
      "train loss:1.0178231490145884\n",
      "train loss:1.0260405781684587\n",
      "train loss:1.0173175474526819\n",
      "train loss:1.1077520152259421\n",
      "train loss:1.1045430236072935\n",
      "train loss:0.9137197119972942\n",
      "train loss:0.8748068844480794\n",
      "train loss:0.8936931714673894\n",
      "train loss:0.9684603536608966\n",
      "train loss:1.1148675241929598\n",
      "train loss:1.0671582055792093\n",
      "train loss:1.0152587526012133\n",
      "train loss:1.0292828405099004\n",
      "train loss:0.8883556389650014\n",
      "train loss:0.8357370986306145\n",
      "train loss:0.9826740964396883\n",
      "train loss:0.8885659606573045\n",
      "train loss:0.8887296131540191\n",
      "train loss:0.9548691922902917\n",
      "train loss:0.8952030282050957\n",
      "train loss:0.9559450459756959\n",
      "train loss:1.0244586119593244\n",
      "train loss:1.084547751309785\n",
      "train loss:0.9823318018626449\n",
      "train loss:1.075477636761263\n",
      "train loss:0.9491534647284464\n",
      "train loss:0.8177172908270167\n",
      "train loss:0.9035277397186884\n",
      "train loss:0.9418554265916907\n",
      "train loss:1.082187845052255\n",
      "train loss:0.9596014998604836\n",
      "train loss:1.1362686394341857\n",
      "train loss:0.9769694598732279\n",
      "train loss:1.180735267165123\n",
      "train loss:1.0200674419515152\n",
      "train loss:1.1248592603217558\n",
      "train loss:1.1288187989348317\n",
      "train loss:0.9822444146989133\n",
      "train loss:0.9937247468975812\n",
      "train loss:0.9669243365237888\n",
      "train loss:0.9658460815676021\n",
      "train loss:0.908411076229683\n",
      "train loss:0.9491489843084612\n",
      "train loss:0.964484139330539\n",
      "train loss:0.8180024055548135\n",
      "train loss:0.9600731144543531\n",
      "train loss:0.8759197957109899\n",
      "train loss:1.04642137953392\n",
      "train loss:0.8850576496437018\n",
      "train loss:0.9224692404440347\n",
      "train loss:0.9336614746553977\n",
      "train loss:1.017647621554729\n",
      "train loss:1.0845251123369521\n",
      "train loss:0.9694301773691854\n",
      "train loss:0.8722354903341938\n",
      "train loss:0.8645639655218216\n",
      "train loss:0.8484920521306449\n",
      "train loss:0.9878653470252913\n",
      "train loss:1.1119409817222883\n",
      "train loss:0.945823081434895\n",
      "train loss:0.8848964859908925\n",
      "train loss:1.0423264957447538\n",
      "train loss:1.0837178875759927\n",
      "train loss:1.0804829861154426\n",
      "train loss:1.020949885528594\n",
      "train loss:0.9631768491990671\n",
      "train loss:0.8944929702437037\n",
      "train loss:0.9963617014596743\n",
      "train loss:1.0197763516219545\n",
      "train loss:0.8454342715681418\n",
      "train loss:0.8995451227905857\n",
      "train loss:1.0662382337894796\n",
      "train loss:0.8914670697732379\n",
      "train loss:0.8918812033109036\n",
      "train loss:1.1788283835604412\n",
      "train loss:1.072049021169334\n",
      "train loss:0.9868900446591319\n",
      "train loss:1.1566099442737616\n",
      "train loss:0.8463112990908525\n",
      "train loss:0.948622743207264\n",
      "train loss:1.116916174128513\n",
      "train loss:0.8567182426214015\n",
      "train loss:0.7412337947618837\n",
      "train loss:0.9800064443408051\n",
      "train loss:0.9338937434352624\n",
      "train loss:1.0070243154782672\n",
      "train loss:0.8032728981213338\n",
      "train loss:0.9552843714819897\n",
      "train loss:0.9008034717128051\n",
      "train loss:0.9971794853514317\n",
      "train loss:0.8792621868610294\n",
      "train loss:0.9125214086135739\n",
      "train loss:0.7972668273764657\n",
      "train loss:1.028662640048101\n",
      "train loss:0.840660357274553\n",
      "train loss:1.0029180191114613\n",
      "train loss:0.9871340062147397\n",
      "train loss:0.9188465305629113\n",
      "train loss:0.9533259740199164\n",
      "train loss:0.9967158799421924\n",
      "train loss:0.8801567250914768\n",
      "train loss:0.8657023133856364\n",
      "train loss:0.965671243755111\n",
      "train loss:1.0043927801160841\n",
      "train loss:0.9474555516286162\n",
      "train loss:0.9501295497167054\n",
      "train loss:1.0269637617615748\n",
      "train loss:0.9117634940065057\n",
      "train loss:0.7791901019124938\n",
      "train loss:0.7641800472472352\n",
      "train loss:1.143432057441495\n",
      "train loss:0.826345787235271\n",
      "train loss:1.1510918586749503\n",
      "train loss:0.8927907176112488\n",
      "train loss:1.0081970846414505\n",
      "train loss:0.9386768737016287\n",
      "train loss:0.8353161893782339\n",
      "train loss:0.9245989520122824\n",
      "train loss:0.8222189829003578\n",
      "train loss:0.8519816526197512\n",
      "train loss:0.992102100822377\n",
      "train loss:0.9373375929664657\n",
      "train loss:1.0922096098514897\n",
      "train loss:1.102032385377214\n",
      "train loss:0.9095823903600317\n",
      "train loss:1.0417738177729956\n",
      "train loss:1.0769214523507318\n",
      "train loss:1.1287441358482158\n",
      "train loss:0.8996456984974405\n",
      "train loss:0.9238842082474608\n",
      "train loss:1.0634039989295727\n",
      "train loss:0.9906103497818383\n",
      "train loss:0.9489361795806299\n",
      "train loss:0.9567008884615283\n",
      "train loss:0.8687232364220123\n",
      "train loss:0.9575812749907171\n",
      "train loss:0.7585270727580015\n",
      "train loss:0.9532319348828758\n",
      "train loss:0.9295300214578739\n",
      "train loss:1.0313219001073206\n",
      "train loss:0.8931879029048827\n",
      "train loss:0.9972944735963202\n",
      "train loss:0.9291307167203151\n",
      "train loss:0.8824905032525453\n",
      "train loss:0.844812366396548\n",
      "train loss:0.9596946240818285\n",
      "train loss:0.8451333680409522\n",
      "train loss:1.098041960705677\n",
      "train loss:1.1420993730559754\n",
      "train loss:0.9872056584256224\n",
      "train loss:0.9814486491708803\n",
      "train loss:0.9805266403852648\n",
      "train loss:0.9800465013735992\n",
      "train loss:0.7567066983018259\n",
      "train loss:0.9505607184129271\n",
      "train loss:0.8344801554331169\n",
      "train loss:1.143657711267832\n",
      "train loss:0.8939272589480629\n",
      "train loss:0.8104711898422161\n",
      "train loss:0.9950280431983995\n",
      "train loss:0.9258116749289239\n",
      "train loss:0.9246501326306076\n",
      "train loss:0.8478279751526472\n",
      "train loss:0.857409493442174\n",
      "train loss:0.9041141961154042\n",
      "train loss:0.9410871474603069\n",
      "train loss:0.8575698793347708\n",
      "train loss:0.7947237258484188\n",
      "train loss:0.9232879104146032\n",
      "train loss:0.9550912539985548\n",
      "train loss:1.00456584862824\n",
      "train loss:1.0061342308519905\n",
      "train loss:0.9516090221944373\n",
      "train loss:1.1563625890979248\n",
      "train loss:0.8725640849614862\n",
      "train loss:0.9508547984492062\n",
      "train loss:1.1277362267020188\n",
      "train loss:0.8421101741418113\n",
      "train loss:0.9807768567505871\n",
      "train loss:1.0521269743923425\n",
      "train loss:1.0569765135742673\n",
      "train loss:0.9553038909003563\n",
      "train loss:1.054289754071717\n",
      "train loss:1.0153364761588033\n",
      "train loss:0.8488685925424454\n",
      "train loss:0.8167042336171931\n",
      "train loss:0.8674889291914457\n",
      "train loss:0.8728238880642821\n",
      "train loss:0.9554102584771862\n",
      "train loss:0.9806802794617557\n",
      "train loss:0.8214289747224923\n",
      "train loss:0.8477012850472601\n",
      "train loss:1.0358977239710685\n",
      "train loss:0.9364543021811813\n",
      "train loss:0.9608396416938728\n",
      "train loss:1.0232263054798003\n",
      "train loss:0.7490382066953682\n",
      "train loss:1.039010138731134\n",
      "train loss:1.1778226374815666\n",
      "train loss:0.8648978465857086\n",
      "train loss:0.8468098259531245\n",
      "train loss:0.9106675526014358\n",
      "train loss:1.1569031406725976\n",
      "train loss:0.9936896392072709\n",
      "train loss:0.8771783404455435\n",
      "train loss:0.9815613961517308\n",
      "train loss:1.0753534551115012\n",
      "train loss:1.027636091789832\n",
      "train loss:0.9880656236231219\n",
      "train loss:0.960939652128872\n",
      "train loss:1.0393730959579002\n",
      "train loss:1.1268810491384698\n",
      "train loss:1.0994060361185145\n",
      "train loss:0.8615649011905081\n",
      "train loss:0.9945813469388441\n",
      "train loss:0.957052977446095\n",
      "train loss:1.0803420727544457\n",
      "train loss:1.1252812435770851\n",
      "train loss:0.725562089348786\n",
      "train loss:1.1733383212196888\n",
      "train loss:1.0417281969712864\n",
      "train loss:0.9613479369725769\n",
      "train loss:1.1047717317611496\n",
      "train loss:0.9140638227638169\n",
      "train loss:1.0246022329444109\n",
      "train loss:0.9992650020378296\n",
      "train loss:0.951119830518212\n",
      "train loss:0.7912536887527406\n",
      "train loss:0.9424810099835426\n",
      "train loss:0.8978391787777027\n",
      "train loss:1.029126876337165\n",
      "train loss:0.8309061714373542\n",
      "train loss:0.8387669667102204\n",
      "train loss:0.8948580250975384\n",
      "train loss:0.9509067085951466\n",
      "train loss:0.948233852617967\n",
      "train loss:0.8499316596938659\n",
      "train loss:0.8460676676418122\n",
      "train loss:1.0116327243289942\n",
      "train loss:0.8388885235583647\n",
      "train loss:0.918793706178672\n",
      "train loss:0.8647464455648597\n",
      "train loss:0.9850571115406277\n",
      "train loss:0.8958947876130291\n",
      "train loss:0.8361119169052607\n",
      "train loss:1.0625474080029074\n",
      "train loss:0.7539874558331147\n",
      "train loss:0.9331304164837606\n",
      "train loss:1.0780838506999657\n",
      "train loss:0.9680312930628782\n",
      "train loss:0.8983925841628202\n",
      "train loss:0.8878803034968644\n",
      "train loss:0.8794162112370504\n",
      "train loss:0.9553402598380093\n",
      "train loss:0.9763764422053783\n",
      "train loss:0.8262203110827991\n",
      "train loss:1.0933291840932382\n",
      "train loss:1.041720192619702\n",
      "train loss:0.7470461537085811\n",
      "train loss:1.2842531848036258\n",
      "train loss:1.037508288867629\n",
      "train loss:0.8228808929774839\n",
      "train loss:0.9618470107322945\n",
      "train loss:0.8242991648598434\n",
      "train loss:0.912625002154064\n",
      "train loss:1.002507977790776\n",
      "train loss:1.0165874480985724\n",
      "train loss:0.8895778697374377\n",
      "train loss:0.9967417766866664\n",
      "train loss:1.0359012317867486\n",
      "train loss:0.9068437490070594\n",
      "train loss:1.001874120541122\n",
      "train loss:0.8649289499789725\n",
      "train loss:0.9981471559619994\n",
      "train loss:1.0286468066170402\n",
      "train loss:1.109014666983527\n",
      "train loss:0.9199006932427833\n",
      "train loss:1.0364788844594564\n",
      "train loss:0.7766892590721192\n",
      "train loss:0.8750946441861562\n",
      "train loss:0.9295984983050418\n",
      "train loss:1.0342605592200658\n",
      "train loss:1.0264442754657894\n",
      "train loss:1.0914722066452498\n",
      "train loss:0.8561455277412918\n",
      "train loss:1.032369583583043\n",
      "train loss:0.903687890026555\n",
      "train loss:0.8254012179005487\n",
      "train loss:1.178144762031678\n",
      "train loss:1.039207073040879\n",
      "train loss:0.9273962936362392\n",
      "train loss:1.0508314512916244\n",
      "train loss:1.002133020616501\n",
      "train loss:0.9498859245127274\n",
      "train loss:0.8878003944025076\n",
      "train loss:0.8539680500195829\n",
      "train loss:0.8270339267645427\n",
      "train loss:1.038116801534298\n",
      "train loss:1.0127513844905554\n",
      "train loss:1.108568012969102\n",
      "train loss:0.8746738088395495\n",
      "train loss:0.9857131889420502\n",
      "train loss:0.9580880913669435\n",
      "train loss:1.1612813878816084\n",
      "train loss:1.014392163769629\n",
      "train loss:1.055909336874922\n",
      "train loss:0.9415397335087254\n",
      "train loss:0.8681679221725984\n",
      "train loss:1.0241588799677894\n",
      "train loss:0.8917689738357294\n",
      "train loss:0.9385519184575716\n",
      "train loss:1.060298951198265\n",
      "train loss:0.8040247177159715\n",
      "train loss:0.827417360267004\n",
      "train loss:0.8510975593702509\n",
      "train loss:0.8751118671262765\n",
      "train loss:0.9092892601785451\n",
      "train loss:0.8747542314767052\n",
      "train loss:1.2398832769527903\n",
      "train loss:0.8248745418770288\n",
      "train loss:1.0087154006364007\n",
      "train loss:0.7641961409987023\n",
      "train loss:0.8301473695815195\n",
      "train loss:0.9552460188311698\n",
      "train loss:0.9085827036479343\n",
      "train loss:0.9963662036400975\n",
      "train loss:0.9558692542481653\n",
      "train loss:0.9499526205078347\n",
      "train loss:1.200207022918795\n",
      "train loss:0.8228601256898216\n",
      "train loss:0.8636273970158115\n",
      "train loss:0.8246293434444801\n",
      "train loss:1.0986652575563118\n",
      "train loss:1.0762786897153083\n",
      "train loss:0.6725869426853655\n",
      "train loss:0.9505078888765529\n",
      "train loss:0.9633686380019607\n",
      "train loss:0.9607989677992955\n",
      "train loss:0.9654524854660385\n",
      "train loss:1.0544570969124696\n",
      "train loss:0.9688972546122605\n",
      "train loss:0.9727333891632548\n",
      "train loss:0.9323408960298538\n",
      "train loss:0.8153243838930826\n",
      "train loss:0.9730714886580799\n",
      "=== epoch:12, train acc:0.684, test acc:0.569 ===\n",
      "train loss:0.8803189364479784\n",
      "train loss:1.0220359652926259\n",
      "train loss:0.9944927104022802\n",
      "train loss:0.8851721778006698\n",
      "train loss:0.798366481199528\n",
      "train loss:1.0305667356938848\n",
      "train loss:0.8097885927619669\n",
      "train loss:1.0326281830398407\n",
      "train loss:1.0643444248210074\n",
      "train loss:0.8916079869996768\n",
      "train loss:0.854391890849588\n",
      "train loss:0.8460087604385117\n",
      "train loss:1.0745897909924718\n",
      "train loss:0.9730977470684692\n",
      "train loss:0.9114725919209179\n",
      "train loss:0.921724833304693\n",
      "train loss:1.0731991224189863\n",
      "train loss:1.0793245073493967\n",
      "train loss:0.762509085227009\n",
      "train loss:0.7746196937224694\n",
      "train loss:0.8014478938459281\n",
      "train loss:0.8929745014275501\n",
      "train loss:1.1189285202824035\n",
      "train loss:0.9251578892828666\n",
      "train loss:0.9124952700390949\n",
      "train loss:1.0316522983078993\n",
      "train loss:1.0076696654285562\n",
      "train loss:1.0425393388203283\n",
      "train loss:0.9012001603667609\n",
      "train loss:0.8252386569769092\n",
      "train loss:0.9607537113439655\n",
      "train loss:1.1198556473498968\n",
      "train loss:1.1605089118969691\n",
      "train loss:0.9368977349836766\n",
      "train loss:1.1071926032655155\n",
      "train loss:1.0041883828376026\n",
      "train loss:0.8694336331379837\n",
      "train loss:0.7178897091544257\n",
      "train loss:1.0576951782560022\n",
      "train loss:0.8559173602632693\n",
      "train loss:1.0490332795757984\n",
      "train loss:0.8567165723675856\n",
      "train loss:1.0336090747736209\n",
      "train loss:0.9003458634697249\n",
      "train loss:0.6735022744140438\n",
      "train loss:0.9801035507185353\n",
      "train loss:0.9403330954325558\n",
      "train loss:0.9326386086244288\n",
      "train loss:0.932386586160823\n",
      "train loss:0.9400523227700296\n",
      "train loss:1.0226220941582767\n",
      "train loss:1.0277712026125\n",
      "train loss:1.0264419202790114\n",
      "train loss:0.8505786557971406\n",
      "train loss:1.0247969852337062\n",
      "train loss:0.8696499293111576\n",
      "train loss:0.9847356279802377\n",
      "train loss:0.9156127613531814\n",
      "train loss:1.1090559896611465\n",
      "train loss:0.933337842516982\n",
      "train loss:1.1266284187060918\n",
      "train loss:1.0758098622779466\n",
      "train loss:0.9618540781651623\n",
      "train loss:1.0344508250735034\n",
      "train loss:0.8393342191644376\n",
      "train loss:0.7657358017994703\n",
      "train loss:1.1289409356049704\n",
      "train loss:0.9712078257620972\n",
      "train loss:0.8848797104011503\n",
      "train loss:0.9519098091540308\n",
      "train loss:0.8075663922584827\n",
      "train loss:1.1539738856757638\n",
      "train loss:0.8737429474304257\n",
      "train loss:0.8806746203238552\n",
      "train loss:0.8735071119028196\n",
      "train loss:0.815594639593801\n",
      "train loss:0.9339729497672608\n",
      "train loss:0.9771763800664769\n",
      "train loss:0.8117040132670826\n",
      "train loss:0.6852624526546183\n",
      "train loss:1.027805584808808\n",
      "train loss:0.9283481908807425\n",
      "train loss:0.9520894139995619\n",
      "train loss:1.0286003763295002\n",
      "train loss:0.7783166049923357\n",
      "train loss:0.9243312138691091\n",
      "train loss:1.028730055170493\n",
      "train loss:0.8696850748106523\n",
      "train loss:0.9581346871058112\n",
      "train loss:1.0241362914966432\n",
      "train loss:0.8489368502623708\n",
      "train loss:1.1319907009201913\n",
      "train loss:0.9742763672594578\n",
      "train loss:1.0742147271892883\n",
      "train loss:0.9781429316097685\n",
      "train loss:0.8991171249139635\n",
      "train loss:0.9103535388652969\n",
      "train loss:0.9876308852555259\n",
      "train loss:1.0286929725025622\n",
      "train loss:0.8079078842677803\n",
      "train loss:0.9210126626268581\n",
      "train loss:1.034916521409363\n",
      "train loss:0.8913637212475923\n",
      "train loss:1.189415249065781\n",
      "train loss:0.780544276381054\n",
      "train loss:1.0359701817516411\n",
      "train loss:0.9436388267398508\n",
      "train loss:1.0162813851747219\n",
      "train loss:1.1061415046588035\n",
      "train loss:0.9177693292822688\n",
      "train loss:1.0503441956177264\n",
      "train loss:0.848462476764835\n",
      "train loss:0.8156658834008281\n",
      "train loss:0.8680333026818944\n",
      "train loss:1.09706270961645\n",
      "train loss:0.9275015168077958\n",
      "train loss:1.0845396124821276\n",
      "train loss:0.7887980382672677\n",
      "train loss:1.058813361996665\n",
      "train loss:0.9497331907402407\n",
      "train loss:0.9678621637097743\n",
      "train loss:0.9862308945964707\n",
      "train loss:0.8025955715735767\n",
      "train loss:0.9909788558751547\n",
      "train loss:1.0061112108844177\n",
      "train loss:1.0794557152605886\n",
      "train loss:0.9452392312720974\n",
      "train loss:0.8218378736851968\n",
      "train loss:0.8624222161023599\n",
      "train loss:1.0388770719573381\n",
      "train loss:0.9982506707410701\n",
      "train loss:1.146041098049571\n",
      "train loss:1.0385121801622457\n",
      "train loss:0.8424791513347608\n",
      "train loss:0.9444022115971616\n",
      "train loss:0.8450599364051001\n",
      "train loss:0.8140324002317106\n",
      "train loss:0.7335535380431104\n",
      "train loss:0.8881108408016138\n",
      "train loss:0.8692035868774058\n",
      "train loss:0.8910488356990295\n",
      "train loss:0.9455012822261462\n",
      "train loss:0.9245138632616026\n",
      "train loss:1.1277207367512003\n",
      "train loss:1.0903645815543719\n",
      "train loss:0.7712411767088813\n",
      "train loss:0.825271192574765\n",
      "train loss:1.0582947844308401\n",
      "train loss:1.130875980758819\n",
      "train loss:0.7837489655501894\n",
      "train loss:0.9500144868429582\n",
      "train loss:0.9676056334074125\n",
      "train loss:0.7609967744347673\n",
      "train loss:0.999631012752568\n",
      "train loss:0.926785498434763\n",
      "train loss:0.9321858146988674\n",
      "train loss:0.84935655067996\n",
      "train loss:1.278030680255857\n",
      "train loss:1.0331315576298614\n",
      "train loss:1.1185865411687168\n",
      "train loss:0.7948826921626544\n",
      "train loss:1.032288749839175\n",
      "train loss:0.8920043213856996\n",
      "train loss:0.8419817489303131\n",
      "train loss:0.8508346506376853\n",
      "train loss:1.1305846045876724\n",
      "train loss:1.1509798525493045\n",
      "train loss:0.8594329512534569\n",
      "train loss:0.8992707451373398\n",
      "train loss:0.9802864178081941\n",
      "train loss:0.851758608790125\n",
      "train loss:1.0914238253362314\n",
      "train loss:1.0080433425773228\n",
      "train loss:0.8468971950049818\n",
      "train loss:0.8766894253534018\n",
      "train loss:0.9339553057278793\n",
      "train loss:0.9742742327383754\n",
      "train loss:0.8256374117264816\n",
      "train loss:0.787170341784791\n",
      "train loss:0.912358315405338\n",
      "train loss:0.8070468048272808\n",
      "train loss:0.9805286548653208\n",
      "train loss:0.8939364734379127\n",
      "train loss:1.1458902202168997\n",
      "train loss:0.9845335154688601\n",
      "train loss:0.9647727043907903\n",
      "train loss:1.025785355577185\n",
      "train loss:0.9531046688327167\n",
      "train loss:1.0832474348145105\n",
      "train loss:0.8397079040072819\n",
      "train loss:0.7174439626036917\n",
      "train loss:0.8809509605231765\n",
      "train loss:0.9174059090650405\n",
      "train loss:0.962730587677165\n",
      "train loss:0.9310013866090676\n",
      "train loss:0.8872886219274474\n",
      "train loss:1.0175247245883163\n",
      "train loss:1.0656881802135052\n",
      "train loss:0.9000185507644276\n",
      "train loss:0.943710059148605\n",
      "train loss:0.9192948877211843\n",
      "train loss:1.0028182883507981\n",
      "train loss:1.056201193443771\n",
      "train loss:0.9988093269038157\n",
      "train loss:0.7583706120648839\n",
      "train loss:1.0673441291961394\n",
      "train loss:0.782116567426866\n",
      "train loss:0.954435720930282\n",
      "train loss:0.7925867059204204\n",
      "train loss:0.8488003335282229\n",
      "train loss:0.9951315718144156\n",
      "train loss:0.8623091580300656\n",
      "train loss:0.9957725166257196\n",
      "train loss:0.982071068687085\n",
      "train loss:0.9205355884322363\n",
      "train loss:0.7642996562510045\n",
      "train loss:1.0024600112829574\n",
      "train loss:0.8989019452547677\n",
      "train loss:0.9478942966001803\n",
      "train loss:0.6488937919119588\n",
      "train loss:0.79063246658563\n",
      "train loss:0.901835087257094\n",
      "train loss:0.8124470897576699\n",
      "train loss:0.8308440618182185\n",
      "train loss:0.9855577563687439\n",
      "train loss:0.8899744462591366\n",
      "train loss:1.0142956605657194\n",
      "train loss:1.0100442796639268\n",
      "train loss:0.8855131601712186\n",
      "train loss:0.8345466250799727\n",
      "train loss:0.9393557633034759\n",
      "train loss:1.08105021466232\n",
      "train loss:0.8085903955913482\n",
      "train loss:0.8275600062402863\n",
      "train loss:1.0354248088475095\n",
      "train loss:0.9783791256743831\n",
      "train loss:0.9125225635731452\n",
      "train loss:0.879241358595201\n",
      "train loss:0.9945623865503266\n",
      "train loss:0.879139749916672\n",
      "train loss:1.2322886365546633\n",
      "train loss:1.1170343359787838\n",
      "train loss:0.8730152139521976\n",
      "train loss:0.9117331845925246\n",
      "train loss:0.932545989992288\n",
      "train loss:0.8927937795890887\n",
      "train loss:0.874982342127531\n",
      "train loss:1.012612816502826\n",
      "train loss:0.7152135757749624\n",
      "train loss:0.9404627074169842\n",
      "train loss:0.9748909852720713\n",
      "train loss:0.8383152617909784\n",
      "train loss:0.8339821793323319\n",
      "train loss:0.8510693791514059\n",
      "train loss:0.7659708920228679\n",
      "train loss:0.781271240064097\n",
      "train loss:0.9014131297923161\n",
      "train loss:0.8990109732312213\n",
      "train loss:0.578103289482377\n",
      "train loss:0.8864838939078153\n",
      "train loss:0.82631364598473\n",
      "train loss:0.952261140493123\n",
      "train loss:1.0084856249316312\n",
      "train loss:0.9250675009557964\n",
      "train loss:0.8746546185234291\n",
      "train loss:1.0656533374927382\n",
      "train loss:0.8583999541699768\n",
      "train loss:0.9450267389417875\n",
      "train loss:0.9118664186150892\n",
      "train loss:0.6548367230238615\n",
      "train loss:0.7867110423389916\n",
      "train loss:0.9418729537451164\n",
      "train loss:0.9020210209984425\n",
      "train loss:0.9332619863499119\n",
      "train loss:1.118467567706394\n",
      "train loss:1.037429068760301\n",
      "train loss:0.9760111260074494\n",
      "train loss:0.925778236786753\n",
      "train loss:0.6482708395208404\n",
      "train loss:0.8950210833330061\n",
      "train loss:0.9454499934787244\n",
      "train loss:0.8116980665042552\n",
      "train loss:0.841656335622518\n",
      "train loss:0.8184340339775908\n",
      "train loss:0.8521682151253888\n",
      "train loss:0.9109877753452277\n",
      "train loss:1.1117942837985968\n",
      "train loss:0.9563225997439204\n",
      "train loss:0.8525171376631507\n",
      "train loss:0.7725496472025877\n",
      "train loss:0.9193099041117968\n",
      "train loss:0.8765840279119946\n",
      "train loss:1.0407659562500324\n",
      "train loss:0.9561403497695667\n",
      "train loss:0.9263108777893829\n",
      "train loss:1.0135992927165713\n",
      "train loss:0.9053599157365348\n",
      "train loss:0.7961694929542898\n",
      "train loss:0.7374997615692894\n",
      "train loss:0.8652143836290488\n",
      "train loss:0.8817936298731973\n",
      "train loss:1.0317108336045948\n",
      "train loss:0.9613239763025488\n",
      "train loss:1.014852314183049\n",
      "train loss:1.0544308742182305\n",
      "train loss:0.9098082403529898\n",
      "train loss:0.8117600247214086\n",
      "train loss:0.8424194221575486\n",
      "train loss:0.8881959079071404\n",
      "train loss:0.8670543636927713\n",
      "train loss:0.7836134461381065\n",
      "train loss:0.8544858994734834\n",
      "train loss:0.8110754034220943\n",
      "train loss:0.9860433817448221\n",
      "train loss:0.8767404619679872\n",
      "train loss:1.0259114787458141\n",
      "train loss:0.9512818027146055\n",
      "train loss:0.9183156711700993\n",
      "train loss:1.0210447161053942\n",
      "train loss:0.8655164135526944\n",
      "train loss:1.1231152215259497\n",
      "train loss:0.9020736678731057\n",
      "train loss:0.9984738383529581\n",
      "train loss:0.8686658067920858\n",
      "train loss:0.9529890721641414\n",
      "train loss:0.9475207797158838\n",
      "train loss:0.7607744414332189\n",
      "train loss:1.0054714574418495\n",
      "train loss:0.8458979916037377\n",
      "train loss:0.9667220213615461\n",
      "train loss:1.098042137103084\n",
      "train loss:0.8125625805387915\n",
      "train loss:0.8924726501271616\n",
      "train loss:0.6920678527857508\n",
      "train loss:0.9934208747835265\n",
      "train loss:0.7353038073281282\n",
      "train loss:0.8999040750035907\n",
      "train loss:0.9202958751928856\n",
      "train loss:0.9798186707604861\n",
      "train loss:0.9496985608947193\n",
      "train loss:0.7562548916234774\n",
      "train loss:0.9867877940731755\n",
      "train loss:0.9020711329048118\n",
      "train loss:0.7013918591625761\n",
      "train loss:0.949731062348683\n",
      "train loss:0.939224657173385\n",
      "train loss:1.1739668005647332\n",
      "train loss:0.9926097691624508\n",
      "train loss:0.9679303302183573\n",
      "train loss:1.138939684716993\n",
      "train loss:0.7355125371714987\n",
      "train loss:0.9496095089701696\n",
      "train loss:0.9330193165092565\n",
      "train loss:0.8818274402874745\n",
      "train loss:0.8139900544478725\n",
      "train loss:0.9787877113511122\n",
      "train loss:0.9155628736322656\n",
      "train loss:1.0168858066998099\n",
      "train loss:0.8287880433536692\n",
      "train loss:0.8477746715142719\n",
      "train loss:1.0711134541189131\n",
      "train loss:0.8859781995663296\n",
      "train loss:0.9035438270541003\n",
      "train loss:0.9595897540614081\n",
      "train loss:0.9601024431353892\n",
      "train loss:0.9203022217891332\n",
      "train loss:0.8477417758569922\n",
      "train loss:0.9599030764797747\n",
      "train loss:0.9076599253908628\n",
      "train loss:0.950849232317449\n",
      "train loss:0.8144787769004326\n",
      "train loss:0.9673297048374222\n",
      "train loss:0.9144690756344446\n",
      "train loss:0.7972492074182024\n",
      "train loss:0.7234063361282153\n",
      "train loss:0.809347556615274\n",
      "train loss:0.7192309041264084\n",
      "train loss:0.7795170367100822\n",
      "train loss:0.8648198019870356\n",
      "train loss:1.0046371839032775\n",
      "train loss:1.0168479597164535\n",
      "train loss:0.759433075749856\n",
      "train loss:0.8387084469939967\n",
      "train loss:0.8222884220496343\n",
      "train loss:0.8182015493714494\n",
      "train loss:0.9896678338607253\n",
      "train loss:0.9991860466967699\n",
      "train loss:1.0095715311504743\n",
      "train loss:0.7974240619350799\n",
      "train loss:0.9456828121520079\n",
      "train loss:0.9395384266722077\n",
      "train loss:1.0693179114390592\n",
      "train loss:0.9454624506427538\n",
      "train loss:0.8908143915364768\n",
      "train loss:0.8894020135289391\n",
      "train loss:0.9057597401451727\n",
      "train loss:0.7836034082669946\n",
      "train loss:0.897683163604543\n",
      "train loss:0.9539574749817246\n",
      "train loss:1.0147617131920967\n",
      "=== epoch:13, train acc:0.7, test acc:0.581 ===\n",
      "train loss:0.8621019584932226\n",
      "train loss:0.7484542358481613\n",
      "train loss:0.8882938156298991\n",
      "train loss:1.0066440273025572\n",
      "train loss:0.8788719595784417\n",
      "train loss:0.8177139783019095\n",
      "train loss:0.886467173423596\n",
      "train loss:0.8898995787740502\n",
      "train loss:1.0258681383528334\n",
      "train loss:0.9412301391662897\n",
      "train loss:0.802235860735706\n",
      "train loss:0.7791281490275804\n",
      "train loss:0.8462006507689119\n",
      "train loss:0.8584174360777138\n",
      "train loss:1.1090566317886028\n",
      "train loss:0.9531794696942626\n",
      "train loss:0.7755095406487843\n",
      "train loss:0.9540608248234582\n",
      "train loss:0.8188089813960764\n",
      "train loss:0.9181598042177415\n",
      "train loss:1.0003839647973571\n",
      "train loss:0.7177220728571012\n",
      "train loss:0.640078832813728\n",
      "train loss:0.8464458954530971\n",
      "train loss:0.8986561623741075\n",
      "train loss:1.0366362578265997\n",
      "train loss:1.0634285722425452\n",
      "train loss:0.9282606120242803\n",
      "train loss:1.2768650012372407\n",
      "train loss:1.0239876397468626\n",
      "train loss:0.8888706494472897\n",
      "train loss:0.7456356078485052\n",
      "train loss:1.057885959454773\n",
      "train loss:0.8986468306623159\n",
      "train loss:0.9173154109309642\n",
      "train loss:1.013804871718469\n",
      "train loss:0.94198760603606\n",
      "train loss:0.7666072329526747\n",
      "train loss:1.0301692528861413\n",
      "train loss:0.8710589745677103\n",
      "train loss:0.8478773810519858\n",
      "train loss:0.8838232321491283\n",
      "train loss:1.038213687105672\n",
      "train loss:0.9466397220272416\n",
      "train loss:0.9207296471093539\n",
      "train loss:0.6991247120635474\n",
      "train loss:1.1506452109720389\n",
      "train loss:0.8820544538439188\n",
      "train loss:1.0463229649883723\n",
      "train loss:1.016609453605926\n",
      "train loss:0.9997979554904064\n",
      "train loss:0.9035539966267113\n",
      "train loss:0.821905925003404\n",
      "train loss:0.9796681727488807\n",
      "train loss:0.9918485994155312\n",
      "train loss:0.8978786788343674\n",
      "train loss:0.9853953210447789\n",
      "train loss:0.7828424492568218\n",
      "train loss:0.8038468815508414\n",
      "train loss:0.7854387193390445\n",
      "train loss:0.9693179524522944\n",
      "train loss:0.941467514956078\n",
      "train loss:0.8304624461588632\n",
      "train loss:0.8021748850775781\n",
      "train loss:0.9524030041221455\n",
      "train loss:0.9323971368122242\n",
      "train loss:0.9536041987367899\n",
      "train loss:0.8976407300547763\n",
      "train loss:0.9220622843790638\n",
      "train loss:0.8956104821141375\n",
      "train loss:1.1455816239206527\n",
      "train loss:0.9256729041720759\n",
      "train loss:0.8663005061073913\n",
      "train loss:1.1785893344432021\n",
      "train loss:0.7971950494464174\n",
      "train loss:0.9165818056557272\n",
      "train loss:1.0302994359079691\n",
      "train loss:0.9097125729113058\n",
      "train loss:0.8883428893913498\n",
      "train loss:0.808618505968013\n",
      "train loss:0.8361690535478516\n",
      "train loss:0.9468861486032939\n",
      "train loss:0.857976775609023\n",
      "train loss:0.8903613318014169\n",
      "train loss:0.874872106515739\n",
      "train loss:0.9165144223412797\n",
      "train loss:0.7983306878728239\n",
      "train loss:0.8054450255148337\n",
      "train loss:0.7114608283906446\n",
      "train loss:1.0276001104812138\n",
      "train loss:0.8691348869478861\n",
      "train loss:1.1344132585196263\n",
      "train loss:0.9331164204498344\n",
      "train loss:0.9662865011274349\n",
      "train loss:0.8719158344575636\n",
      "train loss:1.037555268894206\n",
      "train loss:0.8358766415336681\n",
      "train loss:0.9115056229828723\n",
      "train loss:0.8160594525325999\n",
      "train loss:0.7873468919856589\n",
      "train loss:0.8189113481534892\n",
      "train loss:0.9639470549303233\n",
      "train loss:0.7840876012395733\n",
      "train loss:0.7656777210897754\n",
      "train loss:0.7120856025562152\n",
      "train loss:1.0167615210705607\n",
      "train loss:0.9002803831897875\n",
      "train loss:0.9392089336685955\n",
      "train loss:0.7950734611674578\n",
      "train loss:1.0107326609205796\n",
      "train loss:0.9168605780374358\n",
      "train loss:0.7787182894904633\n",
      "train loss:0.951151585363307\n",
      "train loss:0.9229343939843594\n",
      "train loss:0.7903474795901397\n",
      "train loss:0.7708457965971534\n",
      "train loss:1.0016414917882919\n",
      "train loss:0.8011936147942293\n",
      "train loss:0.8406977514065772\n",
      "train loss:0.8266594617233318\n",
      "train loss:0.8495482449968155\n",
      "train loss:0.9353981575807039\n",
      "train loss:0.8408641797327283\n",
      "train loss:0.8807701632807681\n",
      "train loss:1.045949822295237\n",
      "train loss:0.9253869756024862\n",
      "train loss:0.9883189294710784\n",
      "train loss:1.0289557901312099\n",
      "train loss:0.8160164470776498\n",
      "train loss:0.7958000537656589\n",
      "train loss:0.9701332663284141\n",
      "train loss:0.8121350905566992\n",
      "train loss:0.9646786904910474\n",
      "train loss:0.8558041477416889\n",
      "train loss:1.0515879902438323\n",
      "train loss:0.9601153179892072\n",
      "train loss:0.8760824477140554\n",
      "train loss:0.7916303643063561\n",
      "train loss:0.9609723926481124\n",
      "train loss:1.0738063563061941\n",
      "train loss:0.8892798967087905\n",
      "train loss:0.8627471240864059\n",
      "train loss:0.6647437222288265\n",
      "train loss:0.9467173055460119\n",
      "train loss:0.866188482554115\n",
      "train loss:0.6414390430839988\n",
      "train loss:1.0086829311252858\n",
      "train loss:0.9092313878018102\n",
      "train loss:0.8786761110703754\n",
      "train loss:0.8475479231337016\n",
      "train loss:0.8378332876171334\n",
      "train loss:1.1020649527992183\n",
      "train loss:0.8735143263513868\n",
      "train loss:1.0241239179082746\n",
      "train loss:0.8797553067739418\n",
      "train loss:0.9303562097629394\n",
      "train loss:0.9742989764544671\n",
      "train loss:0.896800544750585\n",
      "train loss:0.8633839090237169\n",
      "train loss:0.9865565254605034\n",
      "train loss:0.8566498820115895\n",
      "train loss:0.8918948128554796\n",
      "train loss:0.7897631596133248\n",
      "train loss:0.9358861057345349\n",
      "train loss:1.0265699972121471\n",
      "train loss:1.0725596146204357\n",
      "train loss:1.0107395072818282\n",
      "train loss:0.7993716407844087\n",
      "train loss:0.9355432128331335\n",
      "train loss:1.0636542485342724\n",
      "train loss:0.9305522164849822\n",
      "train loss:0.8189788809659759\n",
      "train loss:0.9969416672404305\n",
      "train loss:0.9042283445653555\n",
      "train loss:0.9361788516212053\n",
      "train loss:0.7512280266226393\n",
      "train loss:0.9448465609835084\n",
      "train loss:0.775297628464816\n",
      "train loss:0.8814615668600598\n",
      "train loss:0.8366889838562142\n",
      "train loss:0.789857485065913\n",
      "train loss:0.8400483814137452\n",
      "train loss:0.9028409458643516\n",
      "train loss:0.8196291291823985\n",
      "train loss:0.7871576356874488\n",
      "train loss:0.8691366153244806\n",
      "train loss:0.8378154628823858\n",
      "train loss:0.9114496171527301\n",
      "train loss:1.0727461413338986\n",
      "train loss:0.7179588534028939\n",
      "train loss:0.7475093103881167\n",
      "train loss:0.85356210584102\n",
      "train loss:0.8798507533679174\n",
      "train loss:0.6975178504281334\n",
      "train loss:0.8771212026904125\n",
      "train loss:0.9029112216152023\n",
      "train loss:0.8951500224875286\n",
      "train loss:0.9037853131475653\n",
      "train loss:0.9870319352466541\n",
      "train loss:0.8291441453182644\n",
      "train loss:1.0825258157619857\n",
      "train loss:0.7457883915338279\n",
      "train loss:0.7440334303209589\n",
      "train loss:0.933619652181553\n",
      "train loss:0.8977052392883585\n",
      "train loss:0.9048016599412791\n",
      "train loss:0.8822025890337423\n",
      "train loss:0.8852159209873145\n",
      "train loss:0.7639935905074067\n",
      "train loss:0.9356510538718418\n",
      "train loss:1.0696938709575021\n",
      "train loss:0.8707195601219498\n",
      "train loss:0.8132213004864467\n",
      "train loss:0.8512239559916632\n",
      "train loss:0.9510020436682305\n",
      "train loss:0.9454106576453305\n",
      "train loss:0.881511591869345\n",
      "train loss:0.9350167678027408\n",
      "train loss:0.8963605490380325\n",
      "train loss:0.9940480125381744\n",
      "train loss:1.0243821887960518\n",
      "train loss:0.689097728131882\n",
      "train loss:0.9895820324118358\n",
      "train loss:0.7963339391217733\n",
      "train loss:0.9193433337133904\n",
      "train loss:0.7977839842483572\n",
      "train loss:0.7830565270744071\n",
      "train loss:0.6355188448765507\n",
      "train loss:0.6937260240447276\n",
      "train loss:0.7435094371755833\n",
      "train loss:0.8099502651233889\n",
      "train loss:0.8942200913174525\n",
      "train loss:0.8583309315391286\n",
      "train loss:0.8583549299041978\n",
      "train loss:0.8158274838951469\n",
      "train loss:0.8970541896452799\n",
      "train loss:0.8377915692312021\n",
      "train loss:0.9181377149544745\n",
      "train loss:0.8640435695551278\n",
      "train loss:0.7697147878387809\n",
      "train loss:0.8365869904553277\n",
      "train loss:1.009251529966974\n",
      "train loss:0.7942022507162052\n",
      "train loss:0.9371128085683685\n",
      "train loss:0.8579688646515784\n",
      "train loss:1.0772460791785448\n",
      "train loss:0.9206973447445033\n",
      "train loss:1.03665142930345\n",
      "train loss:0.9157970383392737\n",
      "train loss:0.7350464103214889\n",
      "train loss:0.9499917775095656\n",
      "train loss:1.094901090817162\n",
      "train loss:0.8191908266431329\n",
      "train loss:0.8428372576584197\n",
      "train loss:0.8181758183616679\n",
      "train loss:0.8998433966648962\n",
      "train loss:0.8963454729396978\n",
      "train loss:0.8875203410613085\n",
      "train loss:0.789791734202514\n",
      "train loss:0.9715922915130669\n",
      "train loss:0.9610157456391561\n",
      "train loss:0.8475156827260846\n",
      "train loss:0.8232992648117546\n",
      "train loss:0.791435508691263\n",
      "train loss:1.1046713874722307\n",
      "train loss:0.9641266312826048\n",
      "train loss:0.9026079249505337\n",
      "train loss:0.8958483684747983\n",
      "train loss:0.7726776050989692\n",
      "train loss:0.7866333791574955\n",
      "train loss:0.9309050756757928\n",
      "train loss:0.9999600572045889\n",
      "train loss:0.9143724072811112\n",
      "train loss:1.1530715029159493\n",
      "train loss:1.0154104013332077\n",
      "train loss:1.169870854259284\n",
      "train loss:0.8884531995813424\n",
      "train loss:0.9796021358841429\n",
      "train loss:0.790780033763306\n",
      "train loss:0.8882346716350876\n",
      "train loss:0.8784790156271505\n",
      "train loss:0.9043855448064423\n",
      "train loss:0.8987041881760143\n",
      "train loss:1.1070280328885516\n",
      "train loss:0.9468416358605264\n",
      "train loss:0.8935491769809488\n",
      "train loss:0.9734499452538232\n",
      "train loss:0.8606333662132574\n",
      "train loss:0.8700297797696526\n",
      "train loss:0.795586003555718\n",
      "train loss:0.9038328296438667\n",
      "train loss:0.8826602885964298\n",
      "train loss:0.9728762555706022\n",
      "train loss:0.8637485084079286\n",
      "train loss:0.705382356341393\n",
      "train loss:0.8347946349513755\n",
      "train loss:1.0220951508119542\n",
      "train loss:0.805204689720541\n",
      "train loss:0.8917952736449467\n",
      "train loss:1.0077812868337812\n",
      "train loss:0.8243055415952055\n",
      "train loss:0.8586417604532613\n",
      "train loss:0.811593563574842\n",
      "train loss:0.782560459891457\n",
      "train loss:0.8391314556185475\n",
      "train loss:0.7812532466913286\n",
      "train loss:0.7850456489956342\n",
      "train loss:0.8397456058134961\n",
      "train loss:0.90606416045569\n",
      "train loss:0.8068154463302867\n",
      "train loss:0.9908000145035466\n",
      "train loss:0.7864416067248433\n",
      "train loss:0.7614042435266793\n",
      "train loss:1.1102230686779988\n",
      "train loss:0.8243013960506262\n",
      "train loss:0.7708809765220529\n",
      "train loss:1.0121847892531048\n",
      "train loss:0.9251070414485514\n",
      "train loss:0.9038417686421775\n",
      "train loss:0.8661915561068461\n",
      "train loss:0.7766113257013907\n",
      "train loss:0.9933009878776528\n",
      "train loss:0.8565688630899275\n",
      "train loss:0.8279493641170932\n",
      "train loss:0.8803247875049597\n",
      "train loss:0.8695354074144597\n",
      "train loss:1.0548450708705233\n",
      "train loss:0.6967787818451846\n",
      "train loss:0.9220032088062081\n",
      "train loss:1.0313784118968625\n",
      "train loss:0.8083911881479959\n",
      "train loss:0.8653445584363937\n",
      "train loss:0.841231872267534\n",
      "train loss:0.8975295503211673\n",
      "train loss:1.0175139883863498\n",
      "train loss:0.6708708778153334\n",
      "train loss:0.8915410742871036\n",
      "train loss:0.8210998487128794\n",
      "train loss:0.7300375943456686\n",
      "train loss:0.8535009717624784\n",
      "train loss:0.8538393815594502\n",
      "train loss:0.876961335409154\n",
      "train loss:0.8312837481287838\n",
      "train loss:0.8679110933654673\n",
      "train loss:0.8880868063458703\n",
      "train loss:0.9540397172190087\n",
      "train loss:0.7683166249083857\n",
      "train loss:0.8069809608826035\n",
      "train loss:0.860359213016913\n",
      "train loss:0.7463025919114719\n",
      "train loss:0.7926777347357846\n",
      "train loss:0.9390015907798941\n",
      "train loss:0.6718861478798343\n",
      "train loss:0.6621665629624341\n",
      "train loss:0.7487963049989331\n",
      "train loss:0.9005974629089691\n",
      "train loss:0.8127797897966123\n",
      "train loss:0.8187706469262267\n",
      "train loss:0.8862256896950411\n",
      "train loss:0.9456649509300428\n",
      "train loss:0.8731363012158792\n",
      "train loss:0.9622784936056362\n",
      "train loss:0.7613752217114655\n",
      "train loss:0.8585748197102219\n",
      "train loss:0.934811036525123\n",
      "train loss:1.01379900430879\n",
      "train loss:0.811070149112506\n",
      "train loss:0.9713249767263243\n",
      "train loss:0.7710383124762629\n",
      "train loss:0.8439926666961363\n",
      "train loss:0.799016541971945\n",
      "train loss:0.8818970442141071\n",
      "train loss:0.9546544926714191\n",
      "train loss:0.8996154336363787\n",
      "train loss:0.85485581384903\n",
      "train loss:1.0098683397250527\n",
      "train loss:0.9148940429213502\n",
      "train loss:0.8331391724597279\n",
      "train loss:0.8855655331062576\n",
      "train loss:1.016213080865116\n",
      "train loss:0.935408263898566\n",
      "train loss:0.8829974166743655\n",
      "train loss:0.6974979396801965\n",
      "train loss:0.7984520106870461\n",
      "train loss:0.7510248729228088\n",
      "train loss:0.7261997730466132\n",
      "train loss:0.9167587820291607\n",
      "train loss:0.8494618660433698\n",
      "train loss:0.8795402865209521\n",
      "train loss:0.8297732179851312\n",
      "train loss:0.7805527259312862\n",
      "train loss:0.8550904263837101\n",
      "train loss:0.8223022042095548\n",
      "train loss:0.8954826395774502\n",
      "train loss:0.9345277032948718\n",
      "train loss:0.7444703739546317\n",
      "train loss:0.8824564336557188\n",
      "train loss:0.8281976894008273\n",
      "train loss:0.9125723878594763\n",
      "train loss:0.6815892355830142\n",
      "=== epoch:14, train acc:0.704, test acc:0.583 ===\n",
      "train loss:0.7947632726539444\n",
      "train loss:1.204222119251251\n",
      "train loss:0.8471176759274183\n",
      "train loss:0.8399729576228434\n",
      "train loss:0.9313343463589783\n",
      "train loss:1.0779461314128331\n",
      "train loss:0.9280098070910197\n",
      "train loss:0.8117654422470015\n",
      "train loss:0.6759490323127584\n",
      "train loss:0.8652746888360008\n",
      "train loss:0.9172915434715871\n",
      "train loss:1.0048007525122993\n",
      "train loss:0.8053252677564116\n",
      "train loss:0.8298837956962676\n",
      "train loss:0.7391837806773607\n",
      "train loss:1.0178964244801698\n",
      "train loss:0.869228808186951\n",
      "train loss:0.8715783590291908\n",
      "train loss:0.8016779360253511\n",
      "train loss:0.8828592338125543\n",
      "train loss:0.8510609984632187\n",
      "train loss:0.8817311151454277\n",
      "train loss:0.860177372830183\n",
      "train loss:0.7058313427983944\n",
      "train loss:0.9963134088392267\n",
      "train loss:0.7695020718007122\n",
      "train loss:0.9163812479987722\n",
      "train loss:0.9223214391278302\n",
      "train loss:0.8512706104253545\n",
      "train loss:0.9259568571040958\n",
      "train loss:0.9009189451537495\n",
      "train loss:0.8379453394100784\n",
      "train loss:0.7044278149505572\n",
      "train loss:0.8126258925207853\n",
      "train loss:0.828121784432103\n",
      "train loss:0.9314179625311338\n",
      "train loss:0.9375106755283399\n",
      "train loss:0.7877374450946378\n",
      "train loss:0.812607181105864\n",
      "train loss:0.9074882989076732\n",
      "train loss:1.0136925216223829\n",
      "train loss:1.052999510969245\n",
      "train loss:0.8050156914541863\n",
      "train loss:0.9454896400610727\n",
      "train loss:0.8293130879117308\n",
      "train loss:0.7923826720362195\n",
      "train loss:0.8681995056698646\n",
      "train loss:0.9003009471563393\n",
      "train loss:0.7816705348310659\n",
      "train loss:0.8043458511957069\n",
      "train loss:0.9423530357757298\n",
      "train loss:1.0334215809020042\n",
      "train loss:0.7964764124389114\n",
      "train loss:1.055810320357066\n",
      "train loss:0.8837789189545012\n",
      "train loss:1.0166477664853044\n",
      "train loss:0.946729273972192\n",
      "train loss:0.8616685760002657\n",
      "train loss:0.8651615779315998\n",
      "train loss:0.9140886793758983\n",
      "train loss:0.8924281485257168\n",
      "train loss:0.7273274405407164\n",
      "train loss:0.9686879639736558\n",
      "train loss:0.7793391075683993\n",
      "train loss:0.8154517706916434\n",
      "train loss:0.7193694975374251\n",
      "train loss:0.9338393812559336\n",
      "train loss:0.7688398528115392\n",
      "train loss:1.0536800423517116\n",
      "train loss:0.8875075696915379\n",
      "train loss:1.0076900688671062\n",
      "train loss:0.8303514121329585\n",
      "train loss:0.8066499242408675\n",
      "train loss:0.7828167902486284\n",
      "train loss:0.6091005655954468\n",
      "train loss:0.9660279085410708\n",
      "train loss:0.8878798090191418\n",
      "train loss:0.7802128166489359\n",
      "train loss:0.8198759749883451\n",
      "train loss:0.7989953697774008\n",
      "train loss:0.8993107513208871\n",
      "train loss:0.8478756123424661\n",
      "train loss:0.7473420055956689\n",
      "train loss:0.8767097197555695\n",
      "train loss:0.9390142670081577\n",
      "train loss:0.8234173153406301\n",
      "train loss:1.1181457817172107\n",
      "train loss:0.8723508114998575\n",
      "train loss:0.7929410771196649\n",
      "train loss:0.8569688848748048\n",
      "train loss:0.6645747789986755\n",
      "train loss:0.9081771721850852\n",
      "train loss:1.0363206337356103\n",
      "train loss:0.8582478727612305\n",
      "train loss:0.8332855163363129\n",
      "train loss:0.8794475937594628\n",
      "train loss:0.7757902110335645\n",
      "train loss:0.9440408924033558\n",
      "train loss:0.9437552121154856\n",
      "train loss:0.7794718897742001\n",
      "train loss:0.6378919602370717\n",
      "train loss:0.6741469608455165\n",
      "train loss:0.9119601454164794\n",
      "train loss:0.9013987352694274\n",
      "train loss:0.7973781436426646\n",
      "train loss:0.9642763091226624\n",
      "train loss:0.9414944665013786\n",
      "train loss:0.7301546555806828\n",
      "train loss:0.8954396478501789\n",
      "train loss:1.0206899496244666\n",
      "train loss:0.9876860625013961\n",
      "train loss:0.8146762547252644\n",
      "train loss:0.9842117018135454\n",
      "train loss:0.9498121037605369\n",
      "train loss:1.0026083817769764\n",
      "train loss:1.067788776988769\n",
      "train loss:1.0022153998054335\n",
      "train loss:0.8656467162661485\n",
      "train loss:0.9620980168222748\n",
      "train loss:0.865173669419272\n",
      "train loss:0.8655901173317802\n",
      "train loss:0.6909967866190718\n",
      "train loss:0.8625492587800854\n",
      "train loss:0.9594783891888747\n",
      "train loss:0.8835038251058859\n",
      "train loss:1.0227174383833466\n",
      "train loss:1.0046693725087388\n",
      "train loss:0.8469979020759234\n",
      "train loss:0.8801069367844933\n",
      "train loss:0.8630767633375206\n",
      "train loss:0.901270568174543\n",
      "train loss:0.7580319224604777\n",
      "train loss:0.7957731451488997\n",
      "train loss:1.0940555812551636\n",
      "train loss:0.9788172510364539\n",
      "train loss:0.8800200827098955\n",
      "train loss:0.9537502587545132\n",
      "train loss:0.8898351856987295\n",
      "train loss:0.8698534482012699\n",
      "train loss:0.8530576150479072\n",
      "train loss:0.843576150479127\n",
      "train loss:0.9781060202151315\n",
      "train loss:1.1269728632359537\n",
      "train loss:0.8001735111836797\n",
      "train loss:0.8284199186150601\n",
      "train loss:0.7721941026704782\n",
      "train loss:0.8622888510717164\n",
      "train loss:0.8989186555395885\n",
      "train loss:0.8593523152013762\n",
      "train loss:0.8701073428560373\n",
      "train loss:0.9882776065069554\n",
      "train loss:0.955490358499488\n",
      "train loss:0.8813513923966818\n",
      "train loss:0.7927163629231648\n",
      "train loss:0.8522929671044546\n",
      "train loss:0.7710274491728901\n",
      "train loss:0.8995564478807805\n",
      "train loss:0.8241763268755371\n",
      "train loss:0.9065849517921163\n",
      "train loss:0.9006959236968218\n",
      "train loss:0.8987409803988267\n",
      "train loss:0.9052447779742079\n",
      "train loss:0.8020055477855405\n",
      "train loss:1.0572925727341873\n",
      "train loss:0.8683585165141655\n",
      "train loss:0.8393374144903472\n",
      "train loss:0.7896364732460589\n",
      "train loss:0.9376676298414527\n",
      "train loss:0.7954736676570286\n",
      "train loss:0.9521017881381845\n",
      "train loss:0.7114497258280317\n",
      "train loss:0.7276786292133448\n",
      "train loss:0.752695625775819\n",
      "train loss:0.9180297018185083\n",
      "train loss:0.9037044099993635\n",
      "train loss:0.8409934594489832\n",
      "train loss:1.0824315306461099\n",
      "train loss:0.8922417761837036\n",
      "train loss:0.9126795624376576\n",
      "train loss:1.1532266789583194\n",
      "train loss:0.780192387281309\n",
      "train loss:0.9207400340999117\n",
      "train loss:0.8977354723481764\n",
      "train loss:0.9068785495629648\n",
      "train loss:0.7707958804590919\n",
      "train loss:1.0340500626519609\n",
      "train loss:0.8214204976100571\n",
      "train loss:0.6448633880935543\n",
      "train loss:0.7464926852532165\n",
      "train loss:0.8904234594772165\n",
      "train loss:0.8117370757924911\n",
      "train loss:0.8771014603379155\n",
      "train loss:0.8195537820329126\n",
      "train loss:0.8562891793138886\n",
      "train loss:0.9088928418445135\n",
      "train loss:0.6646412824481317\n",
      "train loss:0.8526614626998682\n",
      "train loss:0.8773216155511773\n",
      "train loss:0.9086370004234898\n",
      "train loss:0.9426824753484913\n",
      "train loss:0.8313282367757319\n",
      "train loss:1.0336133817453292\n",
      "train loss:0.8869927788917252\n",
      "train loss:0.8000508707174343\n",
      "train loss:0.7622682095550616\n",
      "train loss:1.09938878290783\n",
      "train loss:0.8798478512275757\n",
      "train loss:0.7115151539252775\n",
      "train loss:0.7745347424892164\n",
      "train loss:0.9504914662650154\n",
      "train loss:0.8552226913754722\n",
      "train loss:0.8196093463531365\n",
      "train loss:0.8331099799588665\n",
      "train loss:0.7762444525884616\n",
      "train loss:0.7339504258257528\n",
      "train loss:0.956241051825821\n",
      "train loss:0.6777074078718803\n",
      "train loss:0.8769530566990837\n",
      "train loss:0.7435223827371302\n",
      "train loss:0.9301801750245545\n",
      "train loss:0.7991686532566089\n",
      "train loss:0.9622982209622357\n",
      "train loss:0.7770997135636007\n",
      "train loss:0.6359811186142211\n",
      "train loss:0.8729038820414526\n",
      "train loss:0.7900101710532703\n",
      "train loss:0.8667433822652988\n",
      "train loss:0.9402937437898514\n",
      "train loss:0.7818809093027406\n",
      "train loss:0.8891956846001077\n",
      "train loss:0.9076361019108039\n",
      "train loss:0.8911339697533749\n",
      "train loss:0.7321415264413349\n",
      "train loss:0.9663009411620529\n",
      "train loss:0.8522207456571806\n",
      "train loss:0.8546355527968648\n",
      "train loss:0.8683071759848637\n",
      "train loss:0.9023016974144756\n",
      "train loss:0.9512488753853748\n",
      "train loss:0.7559102032500599\n",
      "train loss:0.8041032730899138\n",
      "train loss:0.8196685248037363\n",
      "train loss:0.8169291629261763\n",
      "train loss:1.028383690737105\n",
      "train loss:0.8266659336944424\n",
      "train loss:0.918323073993713\n",
      "train loss:0.9154698608746871\n",
      "train loss:0.7988968447306694\n",
      "train loss:0.7979992977183165\n",
      "train loss:0.6899680789806706\n",
      "train loss:0.66694833628252\n",
      "train loss:0.9054376781839315\n",
      "train loss:0.8266918683520346\n",
      "train loss:0.9806015599476613\n",
      "train loss:0.7767867908295039\n",
      "train loss:0.7671765392015527\n",
      "train loss:0.7947230698647404\n",
      "train loss:0.8149073123755542\n",
      "train loss:0.6557416199357133\n",
      "train loss:0.8622733022683069\n",
      "train loss:0.8137025379230267\n",
      "train loss:0.8708374313636682\n",
      "train loss:0.6918645347981988\n",
      "train loss:0.7674742866907337\n",
      "train loss:0.8933552945998948\n",
      "train loss:0.8625941785625616\n",
      "train loss:0.6057008201325372\n",
      "train loss:0.7339965917765465\n",
      "train loss:0.7953573001701768\n",
      "train loss:0.8533974652889075\n",
      "train loss:0.7293217863623362\n",
      "train loss:0.6392985780363436\n",
      "train loss:0.6943620847441485\n",
      "train loss:0.7962095695310145\n",
      "train loss:0.8283329747541144\n",
      "train loss:0.8407056546620764\n",
      "train loss:0.9321957228998545\n",
      "train loss:0.8267127910940202\n",
      "train loss:0.9001237750544628\n",
      "train loss:0.8022776807992625\n",
      "train loss:0.7302004304537667\n",
      "train loss:0.7672908822287104\n",
      "train loss:0.7154974214366483\n",
      "train loss:1.0119588818662044\n",
      "train loss:0.857414416649874\n",
      "train loss:0.736064803850547\n",
      "train loss:0.9163455557444513\n",
      "train loss:0.908340042792846\n",
      "train loss:0.8257054236876372\n",
      "train loss:0.9449329952509489\n",
      "train loss:0.9038787311062906\n",
      "train loss:0.9112917740119745\n",
      "train loss:0.9117203878163557\n",
      "train loss:0.8510077201687294\n",
      "train loss:0.9392606559796923\n",
      "train loss:0.7644595493410619\n",
      "train loss:0.9322183387579398\n",
      "train loss:0.936678547881817\n",
      "train loss:0.80405680338941\n",
      "train loss:0.7752530594673003\n",
      "train loss:0.6923859434254283\n",
      "train loss:0.8211843025502429\n",
      "train loss:1.0027193573707407\n",
      "train loss:0.9541772969154155\n",
      "train loss:0.8798956114357813\n",
      "train loss:1.0136129229155117\n",
      "train loss:0.8877412975908769\n",
      "train loss:0.7126336614623296\n",
      "train loss:0.8603150296395842\n",
      "train loss:0.9845277319903346\n",
      "train loss:1.023935966033857\n",
      "train loss:0.7694436760759138\n",
      "train loss:1.0332370865488016\n",
      "train loss:0.8559627635495659\n",
      "train loss:0.9758886184524878\n",
      "train loss:0.7901713432445827\n",
      "train loss:0.8868575662813033\n",
      "train loss:0.8560405161037763\n",
      "train loss:0.9160553064141307\n",
      "train loss:0.85721479271877\n",
      "train loss:1.0899370927827625\n",
      "train loss:0.8079322952582808\n",
      "train loss:0.8231405511689475\n",
      "train loss:0.9133199662298788\n",
      "train loss:0.9539481106901408\n",
      "train loss:0.79561477298388\n",
      "train loss:0.8539260685327738\n",
      "train loss:0.8984749935229734\n",
      "train loss:0.8144081260954499\n",
      "train loss:0.9748184230449337\n",
      "train loss:0.8585097191401825\n",
      "train loss:0.7150597013455142\n",
      "train loss:0.5949175194117555\n",
      "train loss:1.1064537697275991\n",
      "train loss:0.953634214127835\n",
      "train loss:0.7430383405626608\n",
      "train loss:0.7573140595670766\n",
      "train loss:0.8494063352991053\n",
      "train loss:0.8186023630371748\n",
      "train loss:0.9670194825783744\n",
      "train loss:0.6684886547994263\n",
      "train loss:0.7740220237731742\n",
      "train loss:1.1528613519705964\n",
      "train loss:0.7590644736221985\n",
      "train loss:0.9970799050430463\n",
      "train loss:0.790316072730361\n",
      "train loss:0.8727154243736922\n",
      "train loss:0.8008492479673669\n",
      "train loss:0.8897716030393008\n",
      "train loss:0.9948306472547327\n",
      "train loss:0.8792262591600505\n",
      "train loss:1.1800730687977397\n",
      "train loss:1.0536576555187525\n",
      "train loss:0.7378811298196365\n",
      "train loss:0.8596028408373432\n",
      "train loss:0.9327233282273351\n",
      "train loss:1.0080273721736064\n",
      "train loss:0.6926543107067143\n",
      "train loss:0.8045423804264861\n",
      "train loss:0.8502167178340596\n",
      "train loss:0.8048154397679151\n",
      "train loss:0.8323383506749806\n",
      "train loss:1.0121010084118278\n",
      "train loss:0.7513845165111959\n",
      "train loss:0.8367158753667445\n",
      "train loss:0.9298594246863611\n",
      "train loss:0.6175208376243516\n",
      "train loss:0.7612715854003844\n",
      "train loss:0.9034695997864255\n",
      "train loss:0.829631200058803\n",
      "train loss:0.804306819944749\n",
      "train loss:0.7456962876385801\n",
      "train loss:1.05152051432363\n",
      "train loss:0.9276101983055304\n",
      "train loss:0.8928580857149205\n",
      "train loss:0.8613916987896608\n",
      "train loss:0.8000096969497298\n",
      "train loss:0.9032596889558709\n",
      "train loss:0.9306923193470351\n",
      "train loss:0.8071583959035391\n",
      "train loss:1.0038646704461334\n",
      "train loss:0.7834691752858205\n",
      "train loss:0.9265042066260695\n",
      "train loss:0.7681611541376319\n",
      "train loss:0.8016567604612505\n",
      "train loss:0.7314750111440479\n",
      "train loss:0.6984805499749785\n",
      "train loss:0.7616621830555045\n",
      "train loss:0.8037989015348915\n",
      "train loss:0.650559150415933\n",
      "train loss:0.9515800811479711\n",
      "train loss:0.6352405834148004\n",
      "train loss:0.8095383250572061\n",
      "train loss:1.0600655953587204\n",
      "train loss:0.7038998190183651\n",
      "train loss:0.8630609150493476\n",
      "train loss:0.7840485690867064\n",
      "train loss:0.7177923779957177\n",
      "train loss:0.8916974288546002\n",
      "train loss:0.90710449720937\n",
      "=== epoch:15, train acc:0.703, test acc:0.573 ===\n",
      "train loss:0.6659019826451972\n",
      "train loss:0.8342113378072871\n",
      "train loss:0.787649183443152\n",
      "train loss:0.8056747937409305\n",
      "train loss:0.774459733175942\n",
      "train loss:0.8262081685392606\n",
      "train loss:0.9270622655498325\n",
      "train loss:0.9776506362299068\n",
      "train loss:0.8163716847919601\n",
      "train loss:0.7170993382613148\n",
      "train loss:0.6370807151531355\n",
      "train loss:0.8352271798877904\n",
      "train loss:0.9313781076958932\n",
      "train loss:0.7561633122204091\n",
      "train loss:0.7645058894764684\n",
      "train loss:0.7377836894244298\n",
      "train loss:0.8831955701927029\n",
      "train loss:0.9892624939746629\n",
      "train loss:0.7117950950580187\n",
      "train loss:0.8232187084046003\n",
      "train loss:0.8290199665322219\n",
      "train loss:0.8847538497063373\n",
      "train loss:0.7589751605294275\n",
      "train loss:0.8114796599069587\n",
      "train loss:0.8765699089816779\n",
      "train loss:0.7651022552000716\n",
      "train loss:0.9130842991723527\n",
      "train loss:0.8073331489639684\n",
      "train loss:0.7730303144426213\n",
      "train loss:0.8317949078702407\n",
      "train loss:0.7066719593335603\n",
      "train loss:0.7803731543449334\n",
      "train loss:0.911559345590717\n",
      "train loss:0.8023755621855991\n",
      "train loss:0.908988201927336\n",
      "train loss:0.8916346849663735\n",
      "train loss:0.9059475235908081\n",
      "train loss:0.8249862870776816\n",
      "train loss:0.7668382624925556\n",
      "train loss:0.8423394448029982\n",
      "train loss:0.8759597023300786\n",
      "train loss:0.7739400588097979\n",
      "train loss:0.8777458110750619\n",
      "train loss:0.6524708896230904\n",
      "train loss:0.6583746158331172\n",
      "train loss:0.925307116803324\n",
      "train loss:0.7405589470564178\n",
      "train loss:0.9181627483550721\n",
      "train loss:0.755126485590686\n",
      "train loss:0.6779319954912174\n",
      "train loss:0.909673683547348\n",
      "train loss:0.7715134470946172\n",
      "train loss:0.7466752984395052\n",
      "train loss:0.8162357525000941\n",
      "train loss:1.1871297136467647\n",
      "train loss:0.8071160708154119\n",
      "train loss:0.8870964559719456\n",
      "train loss:0.7624097851307592\n",
      "train loss:0.6804846333813586\n",
      "train loss:0.8149107486957444\n",
      "train loss:0.9243774739961742\n",
      "train loss:0.9297331221904941\n",
      "train loss:0.8551499850198723\n",
      "train loss:0.8007213490985247\n",
      "train loss:0.9103031779841878\n",
      "train loss:0.9505719746994585\n",
      "train loss:0.7077157940125225\n",
      "train loss:0.7016304952683428\n",
      "train loss:0.8426485639269901\n",
      "train loss:0.8389142747415288\n",
      "train loss:0.7108038637710301\n",
      "train loss:0.8288361026036227\n",
      "train loss:0.8496098254674347\n",
      "train loss:0.8927651627855415\n",
      "train loss:0.866608577973438\n",
      "train loss:0.8433810838257446\n",
      "train loss:0.7877181263088329\n",
      "train loss:0.8896281595490774\n",
      "train loss:0.872024930605048\n",
      "train loss:0.7834184365742248\n",
      "train loss:0.9206856362733573\n",
      "train loss:0.6718847022862048\n",
      "train loss:0.8221964824136007\n",
      "train loss:0.9880784411250626\n",
      "train loss:0.8368793176729913\n",
      "train loss:0.8486181869130056\n",
      "train loss:0.9512398133822016\n",
      "train loss:0.7480558775750694\n",
      "train loss:0.8462252241402307\n",
      "train loss:0.8463662885764585\n",
      "train loss:0.7611023034111866\n",
      "train loss:0.7375652266287999\n",
      "train loss:0.9413499678465453\n",
      "train loss:0.9047382110305354\n",
      "train loss:0.7434152036955584\n",
      "train loss:0.8100585134208883\n",
      "train loss:0.809723370734284\n",
      "train loss:0.5899573415986041\n",
      "train loss:0.83215042396466\n",
      "train loss:0.9311397214727696\n",
      "train loss:0.873332800615422\n",
      "train loss:0.8769252710387095\n",
      "train loss:0.9411091853941812\n",
      "train loss:0.7904262242918456\n",
      "train loss:0.9133417403212737\n",
      "train loss:0.96906468697601\n",
      "train loss:0.6815471132599566\n",
      "train loss:0.8210238807379975\n",
      "train loss:0.8899003567981717\n",
      "train loss:0.8234709259201637\n",
      "train loss:0.7924508753067527\n",
      "train loss:0.8760181023877733\n",
      "train loss:0.6808777117369642\n",
      "train loss:0.8768593223791374\n",
      "train loss:0.7519412361088985\n",
      "train loss:0.9434626977545575\n",
      "train loss:0.937780915866547\n",
      "train loss:0.7521031095546062\n",
      "train loss:0.7769931358520265\n",
      "train loss:0.8287319170965175\n",
      "train loss:0.8198320062813248\n",
      "train loss:0.8503996832929288\n",
      "train loss:0.8280332221074\n",
      "train loss:0.7475555290617854\n",
      "train loss:0.778060028049541\n",
      "train loss:0.6604867885206636\n",
      "train loss:0.6984715534488022\n",
      "train loss:0.7806022831201451\n",
      "train loss:0.8411924664006317\n",
      "train loss:0.825132593594116\n",
      "train loss:0.8569459614905003\n",
      "train loss:0.858017527001059\n",
      "train loss:0.8072243281649619\n",
      "train loss:0.8878789946186326\n",
      "train loss:0.7292304717290016\n",
      "train loss:0.8337311864566916\n",
      "train loss:1.0326029017290896\n",
      "train loss:0.8398432790117465\n",
      "train loss:0.7467524759973071\n",
      "train loss:0.74309308940029\n",
      "train loss:0.7831444408162161\n",
      "train loss:0.8412027825778116\n",
      "train loss:0.7449532336324661\n",
      "train loss:0.7917871594723827\n",
      "train loss:0.7986565946182155\n",
      "train loss:0.6974061881226801\n",
      "train loss:0.8063093825388618\n",
      "train loss:0.9795865056054592\n",
      "train loss:0.763093720362097\n",
      "train loss:0.9749523033641393\n",
      "train loss:0.8700441963080834\n",
      "train loss:0.8250911559018084\n",
      "train loss:0.8295842284073619\n",
      "train loss:1.0322008288777147\n",
      "train loss:0.8905214487334157\n",
      "train loss:1.1313301749222389\n",
      "train loss:0.710913781434823\n",
      "train loss:1.018175780918813\n",
      "train loss:0.8307443955006957\n",
      "train loss:0.7925899842639476\n",
      "train loss:0.8433885181662134\n",
      "train loss:0.685088354800427\n",
      "train loss:0.869234565366723\n",
      "train loss:0.7033242615536733\n",
      "train loss:0.8539289105995087\n",
      "train loss:0.7908934021027626\n",
      "train loss:0.9377638641301536\n",
      "train loss:0.6993087322293791\n",
      "train loss:0.9469929575300452\n",
      "train loss:0.8378974319017276\n",
      "train loss:0.8090084748082578\n",
      "train loss:0.8354944813100831\n",
      "train loss:0.9217553068136077\n",
      "train loss:0.8407949242168882\n",
      "train loss:0.8119955732666891\n",
      "train loss:0.8644856269513093\n",
      "train loss:0.6673816596724241\n",
      "train loss:0.7466224293824989\n",
      "train loss:0.6438118685173531\n",
      "train loss:0.691066889699512\n",
      "train loss:0.8972954485278215\n",
      "train loss:0.8326283302064945\n",
      "train loss:0.8384409725163774\n",
      "train loss:0.7062570586350246\n",
      "train loss:0.882085480273932\n",
      "train loss:0.7359071592990116\n",
      "train loss:0.8733955727736555\n",
      "train loss:0.6915224381641419\n",
      "train loss:0.8387282143286872\n",
      "train loss:0.9757229850088148\n",
      "train loss:0.7416222988291633\n",
      "train loss:0.6354209626820488\n",
      "train loss:0.7866544348543689\n",
      "train loss:0.8069952132258258\n",
      "train loss:0.7701427304788345\n",
      "train loss:0.9038654850808059\n",
      "train loss:0.7886293222582664\n",
      "train loss:0.8675374566197941\n",
      "train loss:0.7399265363606057\n",
      "train loss:0.8928343133610207\n",
      "train loss:0.6800252268369966\n",
      "train loss:0.9036408783105863\n",
      "train loss:1.0350208770711176\n",
      "train loss:0.8316103715024201\n",
      "train loss:0.7250079057678258\n",
      "train loss:0.7316414107154553\n",
      "train loss:0.802641857279149\n",
      "train loss:0.841653670189498\n",
      "train loss:0.771262907371289\n",
      "train loss:0.8288455338430788\n",
      "train loss:0.7944274693731976\n",
      "train loss:0.6739278186702384\n",
      "train loss:0.7226992236073486\n",
      "train loss:0.7809426696693221\n",
      "train loss:0.9272812400196417\n",
      "train loss:0.755163404046843\n",
      "train loss:0.7434317023200623\n",
      "train loss:0.9569006605471562\n",
      "train loss:0.7583583434388614\n",
      "train loss:0.869804378282598\n",
      "train loss:0.6786820335168882\n",
      "train loss:0.7323110079405822\n",
      "train loss:0.6558476738347092\n",
      "train loss:0.7377630409944218\n",
      "train loss:0.7150535090173237\n",
      "train loss:0.7477142448318381\n",
      "train loss:0.7871193404963628\n",
      "train loss:0.7322697709858188\n",
      "train loss:0.7194009678886752\n",
      "train loss:0.8945429987613218\n",
      "train loss:0.6290944332169915\n",
      "train loss:0.806896722882756\n",
      "train loss:0.822686741350441\n",
      "train loss:0.8401987767211513\n",
      "train loss:0.8937113263166637\n",
      "train loss:0.9133949435216097\n",
      "train loss:0.9582518901635265\n",
      "train loss:0.7985663583787282\n",
      "train loss:0.7849617311420185\n",
      "train loss:0.8797625648682207\n",
      "train loss:0.8314042524300382\n",
      "train loss:0.7198382982343722\n",
      "train loss:0.8455529932121066\n",
      "train loss:0.8017348139236232\n",
      "train loss:0.7551761781116313\n",
      "train loss:0.7947611614586957\n",
      "train loss:0.6739796437941661\n",
      "train loss:0.7970137136544895\n",
      "train loss:0.8067192588607839\n",
      "train loss:0.9477785606487376\n",
      "train loss:0.7286424596256252\n",
      "train loss:0.7361932827781843\n",
      "train loss:0.7994402675856357\n",
      "train loss:0.8416203927473747\n",
      "train loss:0.976876502090209\n",
      "train loss:0.7940469007502929\n",
      "train loss:0.7356878680832406\n",
      "train loss:0.9155090436526534\n",
      "train loss:0.7547004564137941\n",
      "train loss:0.8336785085639411\n",
      "train loss:0.7593528905207511\n",
      "train loss:0.7734919831423678\n",
      "train loss:0.7850502165185769\n",
      "train loss:0.7866217760063825\n",
      "train loss:0.7890702653884218\n",
      "train loss:0.9888762124869246\n",
      "train loss:0.8648212686768708\n",
      "train loss:0.7810522919633773\n",
      "train loss:0.7257248869714518\n",
      "train loss:0.9217532120114028\n",
      "train loss:0.9861142033457697\n",
      "train loss:0.9057846083460208\n",
      "train loss:0.8277916461215505\n",
      "train loss:0.7620319252292238\n",
      "train loss:0.869406074450717\n",
      "train loss:0.6116994611533121\n",
      "train loss:0.8212035732216506\n",
      "train loss:0.9277810226760752\n",
      "train loss:0.8090177000702861\n",
      "train loss:0.6610723334904931\n",
      "train loss:0.9017892987750378\n",
      "train loss:0.8556660380838038\n",
      "train loss:0.9886995117818163\n",
      "train loss:0.7068681450454963\n",
      "train loss:0.7429820291180761\n",
      "train loss:0.9475268547298835\n",
      "train loss:0.8969763859151203\n",
      "train loss:0.6961563296406267\n",
      "train loss:0.6292075430226924\n",
      "train loss:0.76206530748449\n",
      "train loss:0.6477565368017822\n",
      "train loss:0.769160439761943\n",
      "train loss:0.7577232601522045\n",
      "train loss:0.9033829192287862\n",
      "train loss:1.021478409107072\n",
      "train loss:0.8906609533270763\n",
      "train loss:0.7489465024645858\n",
      "train loss:0.8431409569857078\n",
      "train loss:0.894603831793123\n",
      "train loss:0.9985742080722605\n",
      "train loss:0.7539551135527774\n",
      "train loss:0.785555753524475\n",
      "train loss:0.9501393773774031\n",
      "train loss:0.6777466250143374\n",
      "train loss:0.792424270659283\n",
      "train loss:0.8543246002592635\n",
      "train loss:0.737974059792803\n",
      "train loss:0.6547976383388181\n",
      "train loss:0.8726397282715694\n",
      "train loss:0.8650742034484636\n",
      "train loss:1.0652091251402167\n",
      "train loss:0.8262896319983419\n",
      "train loss:0.8060989268894845\n",
      "train loss:0.9167653947234043\n",
      "train loss:0.6336841703016196\n",
      "train loss:0.8246060049073214\n",
      "train loss:0.7924456507703312\n",
      "train loss:0.9859503966014097\n",
      "train loss:0.9094434985798633\n",
      "train loss:0.8533633658778913\n",
      "train loss:0.78038474084574\n",
      "train loss:0.7978423751311797\n",
      "train loss:0.831255085739859\n",
      "train loss:0.674313053629223\n",
      "train loss:0.8966259377200552\n",
      "train loss:0.7593364163787583\n",
      "train loss:0.6846052345273645\n",
      "train loss:0.8509737678209163\n",
      "train loss:1.0231695369313167\n",
      "train loss:0.9064477350504418\n",
      "train loss:0.857288718007436\n",
      "train loss:0.701383919366648\n",
      "train loss:0.6592504686913039\n",
      "train loss:0.895700172986795\n",
      "train loss:0.9096201188279861\n",
      "train loss:0.7190828590422249\n",
      "train loss:0.6102370872908864\n",
      "train loss:1.052758514364195\n",
      "train loss:0.7763337543622838\n",
      "train loss:1.0151850163425082\n",
      "train loss:0.6712536251717256\n",
      "train loss:0.8115316086862294\n",
      "train loss:0.7637663915126127\n",
      "train loss:0.7602327306140657\n",
      "train loss:0.6719476394302457\n",
      "train loss:0.869378788330178\n",
      "train loss:0.81428328740754\n",
      "train loss:0.9143782030679495\n",
      "train loss:0.8327106278105635\n",
      "train loss:0.6701968349394659\n",
      "train loss:0.8721389192740727\n",
      "train loss:1.0317594449519856\n",
      "train loss:1.1001136571198364\n",
      "train loss:0.5973299655584756\n",
      "train loss:0.735968584637177\n",
      "train loss:0.8044523894479922\n",
      "train loss:0.9048990530598495\n",
      "train loss:0.6585417951728529\n",
      "train loss:0.8163198947513663\n",
      "train loss:0.7348921036035229\n",
      "train loss:0.7789647665160373\n",
      "train loss:0.8040390174590105\n",
      "train loss:0.6975685994744154\n",
      "train loss:0.7118249919468819\n",
      "train loss:0.823157542561008\n",
      "train loss:0.9161936783840094\n",
      "train loss:0.8510464409257438\n",
      "train loss:0.9727128540262817\n",
      "train loss:0.5792800749834348\n",
      "train loss:0.7999825650474649\n",
      "train loss:0.7427334750542598\n",
      "train loss:0.8566042304367326\n",
      "train loss:0.9364638213520362\n",
      "train loss:0.8955108886619526\n",
      "train loss:0.9711647735062519\n",
      "train loss:0.8148755853668195\n",
      "train loss:0.7685149121250546\n",
      "train loss:0.7289694749511318\n",
      "train loss:0.8577754312265986\n",
      "train loss:0.7677380980488774\n",
      "train loss:0.7322512803974213\n",
      "train loss:0.7841773262242724\n",
      "train loss:0.8310866842587482\n",
      "train loss:0.8754751370725201\n",
      "train loss:0.6994618266766531\n",
      "train loss:0.9102796393406009\n",
      "train loss:1.0608229290220068\n",
      "train loss:0.6730639509484619\n",
      "train loss:0.721044945501595\n",
      "train loss:0.8876383947787392\n",
      "train loss:0.8954161549706146\n",
      "train loss:0.987249895394907\n",
      "train loss:0.9617082310572667\n",
      "train loss:0.8500631551788002\n",
      "train loss:0.765755606706574\n",
      "train loss:0.9453807893944404\n",
      "train loss:0.7245395766481024\n",
      "train loss:0.8649239313732288\n",
      "train loss:0.7706955493459511\n",
      "train loss:0.8969505328879899\n",
      "=== epoch:16, train acc:0.738, test acc:0.59 ===\n",
      "train loss:0.9302088351559068\n",
      "train loss:0.7713816813738694\n",
      "train loss:0.8698432660255367\n",
      "train loss:0.8365112906991099\n",
      "train loss:0.8744650789789438\n",
      "train loss:0.8722892685271944\n",
      "train loss:0.8673121879050376\n",
      "train loss:1.0118617065202857\n",
      "train loss:0.9218103436532769\n",
      "train loss:0.7353237089637102\n",
      "train loss:0.7652284276634447\n",
      "train loss:0.8659980647627197\n",
      "train loss:0.7093683450509891\n",
      "train loss:0.8339057681932021\n",
      "train loss:0.7611260799248227\n",
      "train loss:0.9195789423476775\n",
      "train loss:0.6820722757749962\n",
      "train loss:0.7260490391708668\n",
      "train loss:0.715269986905491\n",
      "train loss:0.8380809282422209\n",
      "train loss:0.8601917846800456\n",
      "train loss:0.9190661505271381\n",
      "train loss:0.7972368889508874\n",
      "train loss:0.9311299468538973\n",
      "train loss:0.808137474503242\n",
      "train loss:0.778420751652845\n",
      "train loss:0.7486023680179714\n",
      "train loss:0.8709558500691094\n",
      "train loss:0.8108196592620243\n",
      "train loss:0.6657469576245413\n",
      "train loss:0.7642113776452425\n",
      "train loss:0.7894477736409986\n",
      "train loss:0.8999943716022343\n",
      "train loss:0.8391058384760154\n",
      "train loss:0.6970699240603393\n",
      "train loss:0.7052363672657457\n",
      "train loss:0.8962474922692355\n",
      "train loss:0.812057037683821\n",
      "train loss:0.7605466730505461\n",
      "train loss:0.7879042152339867\n",
      "train loss:0.7042915378225126\n",
      "train loss:0.7056558176130985\n",
      "train loss:0.912891533303814\n",
      "train loss:0.7339626444798523\n",
      "train loss:0.8206917043495174\n",
      "train loss:0.8648375514081965\n",
      "train loss:0.81300131501933\n",
      "train loss:0.838680921663383\n",
      "train loss:0.8465281472937061\n",
      "train loss:0.83999478630154\n",
      "train loss:0.857085195026101\n",
      "train loss:0.7580785874025137\n",
      "train loss:0.955280841610503\n",
      "train loss:0.9529654298007338\n",
      "train loss:0.8578256733005941\n",
      "train loss:0.7668499309330815\n",
      "train loss:0.7380831192931236\n",
      "train loss:0.7880529801136508\n",
      "train loss:0.8373523929114108\n",
      "train loss:0.847745430314241\n",
      "train loss:0.885448375562178\n",
      "train loss:0.7148195396345138\n",
      "train loss:0.6993679634235447\n",
      "train loss:0.8853321024843203\n",
      "train loss:0.8961258690383105\n",
      "train loss:0.797008632962987\n",
      "train loss:0.7988333900795618\n",
      "train loss:0.6649487422140343\n",
      "train loss:0.9420182751401953\n",
      "train loss:0.874620945826106\n",
      "train loss:1.0097610460629114\n",
      "train loss:0.7433020179116179\n",
      "train loss:0.9958733805950847\n",
      "train loss:0.841207996129641\n",
      "train loss:0.7548600891834144\n",
      "train loss:0.9066859766227532\n",
      "train loss:1.0321925998627457\n",
      "train loss:0.8458742885975374\n",
      "train loss:0.8445085025251653\n",
      "train loss:0.9219244616123605\n",
      "train loss:0.85730727203136\n",
      "train loss:0.8975216735322512\n",
      "train loss:1.0172412799499126\n",
      "train loss:0.860766602706883\n",
      "train loss:0.6258584850503285\n",
      "train loss:0.8662208452759397\n",
      "train loss:0.8743488955197105\n",
      "train loss:0.8389573567088946\n",
      "train loss:0.9027628766167252\n",
      "train loss:0.8329483747121915\n",
      "train loss:0.7786246147649852\n",
      "train loss:0.7094942509122097\n",
      "train loss:0.6700086294322037\n",
      "train loss:0.8470084943706233\n",
      "train loss:0.8544111189267102\n",
      "train loss:0.7287585582293683\n",
      "train loss:0.6963415271284096\n",
      "train loss:0.8003151128709872\n",
      "train loss:0.781806580806471\n",
      "train loss:0.7525386947724994\n",
      "train loss:0.7985985800498434\n",
      "train loss:0.7405667158515888\n",
      "train loss:0.7541458542604009\n",
      "train loss:1.1102832064001347\n",
      "train loss:0.8793281800041095\n",
      "train loss:0.9047819925362032\n",
      "train loss:0.8614103419639751\n",
      "train loss:0.7273667212828059\n",
      "train loss:0.6839845424908798\n",
      "train loss:0.7076302011967787\n",
      "train loss:0.7761571987371159\n",
      "train loss:0.7985057445651031\n",
      "train loss:0.7759253050018141\n",
      "train loss:0.8312243499280159\n",
      "train loss:0.8350904056347689\n",
      "train loss:0.8309751492304247\n",
      "train loss:0.7796815995276957\n",
      "train loss:0.6852181856662939\n",
      "train loss:0.6581936045453942\n",
      "train loss:0.7631331683615418\n",
      "train loss:1.014634050345361\n",
      "train loss:0.9070870087740055\n",
      "train loss:0.8353285957766006\n",
      "train loss:0.8511275331736309\n",
      "train loss:0.7569963679545348\n",
      "train loss:0.7151857543869088\n",
      "train loss:0.669412119841964\n",
      "train loss:0.8055780583294435\n",
      "train loss:0.6425476884469006\n",
      "train loss:0.9556420919137034\n",
      "train loss:0.8543332262252413\n",
      "train loss:0.6789539966001858\n",
      "train loss:0.7281059598788536\n",
      "train loss:0.5990871532166353\n",
      "train loss:0.8365818100840773\n",
      "train loss:0.9918709309005699\n",
      "train loss:0.7590967184210402\n",
      "train loss:0.771638937356311\n",
      "train loss:0.7566436674160741\n",
      "train loss:0.7931661409116302\n",
      "train loss:0.8883240708109126\n",
      "train loss:0.8383894379660388\n",
      "train loss:0.75437142489642\n",
      "train loss:0.8810754926817677\n",
      "train loss:0.7283181945621534\n",
      "train loss:0.8126560625162113\n",
      "train loss:0.9190477722564289\n",
      "train loss:0.7765593821804383\n",
      "train loss:0.8543534003386201\n",
      "train loss:0.7464285010656068\n",
      "train loss:0.8441097673533144\n",
      "train loss:0.6919904810222102\n",
      "train loss:0.7141559576910255\n",
      "train loss:0.8202622910256534\n",
      "train loss:0.6731213903533765\n",
      "train loss:0.705287217913189\n",
      "train loss:0.6942163476131131\n",
      "train loss:0.7317544090618786\n",
      "train loss:0.6717959563598889\n",
      "train loss:0.7546398060850847\n",
      "train loss:0.7538417566730539\n",
      "train loss:0.5796030570897376\n",
      "train loss:0.8708663592894388\n",
      "train loss:0.7574743939645111\n",
      "train loss:0.7506933528020204\n",
      "train loss:0.85851422742823\n",
      "train loss:0.9329068778552262\n",
      "train loss:0.7430339904020932\n",
      "train loss:0.7434644205277469\n",
      "train loss:0.5679160959791499\n",
      "train loss:0.8200003303064528\n",
      "train loss:0.8775926002516208\n",
      "train loss:0.7602797388198995\n",
      "train loss:0.6524040956211705\n",
      "train loss:0.9571909841469598\n",
      "train loss:0.7624146335590115\n",
      "train loss:0.6326198075322111\n",
      "train loss:0.7729778035001612\n",
      "train loss:0.8108888167421117\n",
      "train loss:0.7750996120320844\n",
      "train loss:0.7236149566607765\n",
      "train loss:0.7453308230554861\n",
      "train loss:0.8293525363022362\n",
      "train loss:0.7964714829180772\n",
      "train loss:0.7857794739325783\n",
      "train loss:0.9250843541050148\n",
      "train loss:0.6368056989385988\n",
      "train loss:0.7248435898056215\n",
      "train loss:0.6937369239770146\n",
      "train loss:0.6908730506876638\n",
      "train loss:0.8078654753829081\n",
      "train loss:0.8514432777546284\n",
      "train loss:0.6253403199961882\n",
      "train loss:0.7893001975576511\n",
      "train loss:0.8034183782507237\n",
      "train loss:0.6922975419439659\n",
      "train loss:0.7735489089252853\n",
      "train loss:0.8147727461876461\n",
      "train loss:1.0135364848780735\n",
      "train loss:0.634056349825308\n",
      "train loss:0.7251512921421334\n",
      "train loss:1.0716492915649725\n",
      "train loss:0.9457977667757932\n",
      "train loss:0.8356937683082272\n",
      "train loss:0.7153943143756915\n",
      "train loss:0.8556335245139856\n",
      "train loss:0.6754488544830604\n",
      "train loss:0.865659733871503\n",
      "train loss:0.591975883933832\n",
      "train loss:0.8475757437181276\n",
      "train loss:0.667292619050202\n",
      "train loss:0.7747067506182783\n",
      "train loss:0.8079844169806382\n",
      "train loss:0.7812560852345478\n",
      "train loss:0.8177179922768001\n",
      "train loss:0.7712897338592063\n",
      "train loss:0.7556266031252917\n",
      "train loss:0.8488569979315389\n",
      "train loss:0.8303409080715558\n",
      "train loss:0.9200257609372735\n",
      "train loss:0.8613761605030688\n",
      "train loss:0.8544374055192046\n",
      "train loss:0.6334811442418372\n",
      "train loss:0.8832808723163219\n",
      "train loss:0.7962196799225474\n",
      "train loss:0.7448417640639607\n",
      "train loss:0.769104439493012\n",
      "train loss:0.8015652695749391\n",
      "train loss:0.6776377860121007\n",
      "train loss:0.8724504234630294\n",
      "train loss:0.8485733812903439\n",
      "train loss:0.725607959895682\n",
      "train loss:0.7460132315106565\n",
      "train loss:0.7354145045972303\n",
      "train loss:0.8934431863052746\n",
      "train loss:0.8497840737047839\n",
      "train loss:0.8338955439230533\n",
      "train loss:0.9017890636932112\n",
      "train loss:0.855911823726685\n",
      "train loss:0.7802735618528507\n",
      "train loss:0.786163518591127\n",
      "train loss:0.8247780406018665\n",
      "train loss:0.5763422067168099\n",
      "train loss:0.8020563316205874\n",
      "train loss:0.8402401504964927\n",
      "train loss:0.6456477611909723\n",
      "train loss:0.7581443654420099\n",
      "train loss:0.8945017610794389\n",
      "train loss:0.7783420968587471\n",
      "train loss:0.8306739636253443\n",
      "train loss:0.8613014425388031\n",
      "train loss:0.8683213402654283\n",
      "train loss:0.8043558877187569\n",
      "train loss:0.8490345931848516\n",
      "train loss:0.6292335149501049\n",
      "train loss:0.7281750837141202\n",
      "train loss:0.7518800878899977\n",
      "train loss:0.9071208206630584\n",
      "train loss:1.012370319720291\n",
      "train loss:0.7387076915952488\n",
      "train loss:0.9772998193655014\n",
      "train loss:0.8573243291761078\n",
      "train loss:0.6380059250742565\n",
      "train loss:0.8862312310301887\n",
      "train loss:0.783640345505283\n",
      "train loss:0.9577138406370872\n",
      "train loss:0.732778119089301\n",
      "train loss:0.8399281020278779\n",
      "train loss:0.6879832666928648\n",
      "train loss:0.7178401122816161\n",
      "train loss:0.7515027435213575\n",
      "train loss:0.7600912136306955\n",
      "train loss:0.7831551554099363\n",
      "train loss:0.7237979504276939\n",
      "train loss:0.8255230297590238\n",
      "train loss:0.7079002635738892\n",
      "train loss:0.6667862357540174\n",
      "train loss:0.827743401732178\n",
      "train loss:0.921697091312108\n",
      "train loss:0.7139641576760549\n",
      "train loss:0.683521738208518\n",
      "train loss:0.6897987751016313\n",
      "train loss:0.7998357072526531\n",
      "train loss:0.8363332735366363\n",
      "train loss:0.6311343430548845\n",
      "train loss:0.7086906154458827\n",
      "train loss:0.9185137377693064\n",
      "train loss:0.7293237864278507\n",
      "train loss:0.8990902851136293\n",
      "train loss:0.8288854137715242\n",
      "train loss:0.7341661874102597\n",
      "train loss:0.7641636845974626\n",
      "train loss:1.0066640138251441\n",
      "train loss:0.730515764310962\n",
      "train loss:0.850320247303457\n",
      "train loss:0.9064475601885643\n",
      "train loss:0.7161066296372425\n",
      "train loss:0.6235759866686117\n",
      "train loss:0.7567329910176934\n",
      "train loss:0.691166282597726\n",
      "train loss:0.8656507968057515\n",
      "train loss:0.8839011134721058\n",
      "train loss:0.8183907716947997\n",
      "train loss:0.7166425628640586\n",
      "train loss:0.9016904724008874\n",
      "train loss:0.747536736180096\n",
      "train loss:0.9044878032267795\n",
      "train loss:0.805466755381453\n",
      "train loss:0.8627225548548395\n",
      "train loss:0.8456355189125518\n",
      "train loss:0.798021142639928\n",
      "train loss:0.8354452267444098\n",
      "train loss:0.7592486995875702\n",
      "train loss:0.7615356900557988\n",
      "train loss:0.7384169965566494\n",
      "train loss:0.8523694665452696\n",
      "train loss:0.7523990029290164\n",
      "train loss:0.7165275720234296\n",
      "train loss:0.8588672683368546\n",
      "train loss:1.0797221252760874\n",
      "train loss:1.03664352152627\n",
      "train loss:0.8518626781727453\n",
      "train loss:0.6239001936670444\n",
      "train loss:0.7892085957196119\n",
      "train loss:0.8185026874990533\n",
      "train loss:0.8283146417504037\n",
      "train loss:0.8552098810464369\n",
      "train loss:0.7810160531618422\n",
      "train loss:0.8326263808116775\n",
      "train loss:0.7442328686076618\n",
      "train loss:0.8292497036132658\n",
      "train loss:0.7249793438954575\n",
      "train loss:0.8688375898199021\n",
      "train loss:0.8584877897965302\n",
      "train loss:0.7757453236490471\n",
      "train loss:0.7659182086055754\n",
      "train loss:0.7535328712078989\n",
      "train loss:0.8270839117951744\n",
      "train loss:0.7736352170133006\n",
      "train loss:0.6568105447700152\n",
      "train loss:0.7369176712129074\n",
      "train loss:0.8593073751607649\n",
      "train loss:0.64362323541077\n",
      "train loss:0.6999685942732274\n",
      "train loss:0.7721575209184097\n",
      "train loss:0.9263570580897741\n",
      "train loss:0.8646515761469941\n",
      "train loss:0.7390191312208394\n",
      "train loss:0.7987144611073276\n",
      "train loss:0.7522830472561747\n",
      "train loss:0.7566211963990476\n",
      "train loss:0.7294102080633854\n",
      "train loss:0.8473499445715612\n",
      "train loss:0.6063536919440865\n",
      "train loss:0.8962739363315664\n",
      "train loss:0.7591066055903124\n",
      "train loss:0.8169655908688707\n",
      "train loss:0.7962698989903814\n",
      "train loss:0.6927896031578799\n",
      "train loss:0.8124229039655201\n",
      "train loss:0.7591626817517663\n",
      "train loss:0.8678588926996932\n",
      "train loss:0.7525386560195682\n",
      "train loss:0.831525520026882\n",
      "train loss:0.6341388660240227\n",
      "train loss:0.6825644433201573\n",
      "train loss:0.8885399908004872\n",
      "train loss:0.8133115012045963\n",
      "train loss:0.867299584287053\n",
      "train loss:0.8742180893101319\n",
      "train loss:0.6902106915186459\n",
      "train loss:0.6687209958768324\n",
      "train loss:0.9083744484010035\n",
      "train loss:0.8386739051655914\n",
      "train loss:0.7407654289010253\n",
      "train loss:0.5950055244839123\n",
      "train loss:0.8267098222761871\n",
      "train loss:0.7713013701025502\n",
      "train loss:0.74089682408742\n",
      "train loss:0.875414791682677\n",
      "train loss:0.7480803472313498\n",
      "train loss:0.6856099188946403\n",
      "train loss:0.7354251920159561\n",
      "train loss:0.9393958158231069\n",
      "train loss:1.0093249493324918\n",
      "train loss:0.7013229116821968\n",
      "train loss:0.8076695818492533\n",
      "train loss:0.7949966549896047\n",
      "train loss:0.7758692015441012\n",
      "train loss:0.9321113843703479\n",
      "train loss:0.9364823354073214\n",
      "train loss:0.7615469129890746\n",
      "train loss:0.7985213567539458\n",
      "train loss:0.8955800055649753\n",
      "train loss:0.7497552522017312\n",
      "train loss:0.7070543633236486\n",
      "train loss:0.7073203921893645\n",
      "train loss:0.8189841003058733\n",
      "train loss:0.6703045990859724\n",
      "train loss:0.7665775623750632\n",
      "=== epoch:17, train acc:0.735, test acc:0.588 ===\n",
      "train loss:0.6979548998644026\n",
      "train loss:0.7838641798347471\n",
      "train loss:0.7388215136275832\n",
      "train loss:0.8025611087492929\n",
      "train loss:0.7946662759598102\n",
      "train loss:1.1632002336677096\n",
      "train loss:0.8195333872051562\n",
      "train loss:0.7064792013580654\n",
      "train loss:0.7754501156876791\n",
      "train loss:0.8556484273863506\n",
      "train loss:0.8408593966558019\n",
      "train loss:0.6886278196138897\n",
      "train loss:0.82544010594797\n",
      "train loss:0.8200549559896965\n",
      "train loss:0.7076351074788192\n",
      "train loss:0.8224035045806104\n",
      "train loss:0.8884408484504661\n",
      "train loss:0.7063286835215828\n",
      "train loss:0.7517205681651332\n",
      "train loss:0.7932200515550594\n",
      "train loss:0.7650937268664363\n",
      "train loss:0.5699657319622792\n",
      "train loss:0.6734968842620994\n",
      "train loss:0.583783201725394\n",
      "train loss:0.7594567734029641\n",
      "train loss:0.6496061421674914\n",
      "train loss:0.8606702252677976\n",
      "train loss:0.7237354939559988\n",
      "train loss:0.8431382498861529\n",
      "train loss:0.8241891871621465\n",
      "train loss:0.8182910184785739\n",
      "train loss:0.8118825758606744\n",
      "train loss:0.7696988239192563\n",
      "train loss:0.6983062669876403\n",
      "train loss:0.8188244396381902\n",
      "train loss:0.695726239676327\n",
      "train loss:0.8125566989362192\n",
      "train loss:0.7544006096106617\n",
      "train loss:0.7597813511473768\n",
      "train loss:0.9991898744079535\n",
      "train loss:0.7311043826504257\n",
      "train loss:0.7002811587421579\n",
      "train loss:0.7397274890919074\n",
      "train loss:0.8088173602733987\n",
      "train loss:0.8465715358704304\n",
      "train loss:0.6873040574606609\n",
      "train loss:0.7262232137004611\n",
      "train loss:0.9102862459767048\n",
      "train loss:0.6120725368592871\n",
      "train loss:0.7712342334885817\n",
      "train loss:0.929658290893781\n",
      "train loss:0.8504320553057677\n",
      "train loss:0.7273498454465366\n",
      "train loss:0.7641121830721934\n",
      "train loss:0.860189085961056\n",
      "train loss:0.7496924066291593\n",
      "train loss:0.696661537657767\n",
      "train loss:0.7221797142675898\n",
      "train loss:0.8203993989738824\n",
      "train loss:0.7081501783167148\n",
      "train loss:0.769418854170583\n",
      "train loss:0.8431760385942831\n",
      "train loss:0.8691162992714204\n",
      "train loss:0.7733385472961197\n",
      "train loss:0.7795724873289116\n",
      "train loss:0.8167996702077737\n",
      "train loss:0.6932752479142684\n",
      "train loss:0.9565327740087732\n",
      "train loss:0.7094047139441357\n",
      "train loss:0.8085290915099208\n",
      "train loss:0.7280116198224873\n",
      "train loss:0.8163716373714982\n",
      "train loss:0.8305430126415054\n",
      "train loss:0.8056713206781702\n",
      "train loss:0.7509219532671179\n",
      "train loss:0.8641740310721837\n",
      "train loss:0.6663203274219748\n",
      "train loss:0.8115354545062797\n",
      "train loss:0.8545337729183015\n",
      "train loss:0.7107654659423965\n",
      "train loss:0.9013757474056764\n",
      "train loss:0.7487616941475818\n",
      "train loss:0.6936316898664012\n",
      "train loss:0.9203094574396395\n",
      "train loss:0.8425729053303942\n",
      "train loss:0.7958128780721069\n",
      "train loss:0.8030490787913817\n",
      "train loss:0.7404356946395846\n",
      "train loss:0.9230273888103127\n",
      "train loss:0.7655398035466321\n",
      "train loss:0.7101159548896628\n",
      "train loss:0.7207373426907978\n",
      "train loss:0.9260493712072381\n",
      "train loss:0.9750716332661975\n",
      "train loss:0.7438566942853455\n",
      "train loss:0.8510747208377041\n",
      "train loss:0.7688706230807094\n",
      "train loss:0.8102358197661716\n",
      "train loss:0.8498665845269596\n",
      "train loss:0.9338980423700914\n",
      "train loss:0.8972306309093995\n",
      "train loss:0.793522328721239\n",
      "train loss:0.6517999722063208\n",
      "train loss:0.8937007772943035\n",
      "train loss:0.7931004310712663\n",
      "train loss:0.8725181352106602\n",
      "train loss:0.7498740330001371\n",
      "train loss:0.8259278221928441\n",
      "train loss:0.6893062751278032\n",
      "train loss:0.8017578952810852\n",
      "train loss:0.7259105378239412\n",
      "train loss:0.8580454123746875\n",
      "train loss:0.7545589445567312\n",
      "train loss:0.778147918608893\n",
      "train loss:0.8505188866234894\n",
      "train loss:0.7496266088555384\n",
      "train loss:0.5950506378775666\n",
      "train loss:0.8596342836220104\n",
      "train loss:0.7823235038910248\n",
      "train loss:0.9101262985937687\n",
      "train loss:0.7709997735971811\n",
      "train loss:0.7366442970593451\n",
      "train loss:0.6254705136735591\n",
      "train loss:0.8827907009398086\n",
      "train loss:0.9207649416582164\n",
      "train loss:0.8204101590026598\n",
      "train loss:1.0391829675299733\n",
      "train loss:0.7578850293591287\n",
      "train loss:0.7051244036048148\n",
      "train loss:0.7691027807385624\n",
      "train loss:0.77828501686498\n",
      "train loss:0.5697657316084463\n",
      "train loss:0.8750846345792369\n",
      "train loss:0.8471412690613347\n",
      "train loss:0.8455456762050366\n",
      "train loss:0.8579156462269065\n",
      "train loss:0.7910613824226389\n",
      "train loss:0.6989231522266272\n",
      "train loss:0.9196474300981795\n",
      "train loss:0.647264404826796\n",
      "train loss:0.7642607850697388\n",
      "train loss:0.8140296992626452\n",
      "train loss:0.7592523416380726\n",
      "train loss:0.6301041217345745\n",
      "train loss:0.7499747913061757\n",
      "train loss:0.9466352361203281\n",
      "train loss:0.9203986757101751\n",
      "train loss:0.8308225231005001\n",
      "train loss:0.7563028938095261\n",
      "train loss:0.868684250906938\n",
      "train loss:0.5751903992158297\n",
      "train loss:0.7297148819639447\n",
      "train loss:1.0522754065742779\n",
      "train loss:0.745005463283246\n",
      "train loss:0.7960522881211591\n",
      "train loss:0.8660707950742064\n",
      "train loss:0.8264123031121317\n",
      "train loss:0.8049870459715217\n",
      "train loss:0.9423962609506902\n",
      "train loss:0.8894227261059366\n",
      "train loss:0.9319921576771134\n",
      "train loss:0.8079610076597313\n",
      "train loss:0.7083582146490213\n",
      "train loss:0.5755713742015794\n",
      "train loss:0.6293024840851164\n",
      "train loss:0.7601977360769508\n",
      "train loss:0.682403551109263\n",
      "train loss:0.9364675812260295\n",
      "train loss:0.7728808981359871\n",
      "train loss:0.7178538337355701\n",
      "train loss:0.9661542208145697\n",
      "train loss:0.7234762656076864\n",
      "train loss:0.8326642920739507\n",
      "train loss:0.8342138306857888\n",
      "train loss:0.5041823848645937\n",
      "train loss:0.8352977854145912\n",
      "train loss:0.7769450954639788\n",
      "train loss:0.7767934629691993\n",
      "train loss:0.6440692602158025\n",
      "train loss:0.7037508495901829\n",
      "train loss:0.766969089968114\n",
      "train loss:0.6565011766729613\n",
      "train loss:0.7453872901503176\n",
      "train loss:0.8244762339175413\n",
      "train loss:0.8072890499920973\n",
      "train loss:0.7890906356131546\n",
      "train loss:0.7077075185465372\n",
      "train loss:0.798379838956835\n",
      "train loss:1.1140966015790434\n",
      "train loss:0.6810626013615942\n",
      "train loss:0.6645556711040307\n",
      "train loss:0.7879195122589082\n",
      "train loss:0.8204550204086596\n",
      "train loss:0.7290628177058445\n",
      "train loss:0.8266951280514725\n",
      "train loss:0.7409744261830978\n",
      "train loss:0.7620772391911136\n",
      "train loss:0.8812362111126941\n",
      "train loss:0.6660609503958972\n",
      "train loss:0.8424210986328171\n",
      "train loss:0.7223085650068539\n",
      "train loss:0.8623573375773513\n",
      "train loss:0.793852887058981\n",
      "train loss:0.9216886225707175\n",
      "train loss:0.8170961563368832\n",
      "train loss:0.9231040973042808\n",
      "train loss:0.782601746310554\n",
      "train loss:0.7068714365480875\n",
      "train loss:0.7167139185440011\n",
      "train loss:0.7732803022380708\n",
      "train loss:0.5774223520685616\n",
      "train loss:0.8104457726003035\n",
      "train loss:0.684564846884946\n",
      "train loss:0.7361491518261615\n",
      "train loss:0.9244446010720955\n",
      "train loss:0.7518402630590321\n",
      "train loss:0.6528413626521163\n",
      "train loss:0.6234261098199056\n",
      "train loss:0.9421676757343029\n",
      "train loss:0.6960072998965235\n",
      "train loss:0.7980782557482522\n",
      "train loss:0.9033085250679234\n",
      "train loss:0.6842708775086301\n",
      "train loss:0.8208049843557786\n",
      "train loss:0.8001013243680134\n",
      "train loss:0.6854552742472829\n",
      "train loss:0.6640412802434754\n",
      "train loss:0.8944587069155351\n",
      "train loss:0.7658835579915155\n",
      "train loss:0.7915307065515207\n",
      "train loss:0.6257852766934209\n",
      "train loss:0.741658390120553\n",
      "train loss:0.7608988997093319\n",
      "train loss:0.6362324417972465\n",
      "train loss:0.7292756444626363\n",
      "train loss:0.7714646443739573\n",
      "train loss:0.8411122394784141\n",
      "train loss:0.6640140247701767\n",
      "train loss:1.1405194821522255\n",
      "train loss:0.7408677203598506\n",
      "train loss:0.7874653531215479\n",
      "train loss:0.9434507880262594\n",
      "train loss:0.7206932251503688\n",
      "train loss:0.6894711647287148\n",
      "train loss:0.7129580379449435\n",
      "train loss:0.6250653941969911\n",
      "train loss:0.8457353018590703\n",
      "train loss:0.8316453688076437\n",
      "train loss:0.7977654519585226\n",
      "train loss:0.6674036008713783\n",
      "train loss:0.8098793379391858\n",
      "train loss:0.63790895823603\n",
      "train loss:0.7086323507866757\n",
      "train loss:0.790213048396263\n",
      "train loss:0.6092938751456034\n",
      "train loss:0.7875583985095039\n",
      "train loss:0.7719711471570017\n",
      "train loss:0.722589113505969\n",
      "train loss:0.7938371776398505\n",
      "train loss:0.7519182365239692\n",
      "train loss:0.6595049637829662\n",
      "train loss:0.7913253364767979\n",
      "train loss:0.8533896084087437\n",
      "train loss:0.8380137505976306\n",
      "train loss:0.7463065431709497\n",
      "train loss:0.7943729644742801\n",
      "train loss:0.801426757596127\n",
      "train loss:0.6662827861166113\n",
      "train loss:0.769866886017779\n",
      "train loss:0.7657845362334654\n",
      "train loss:0.7432112304083338\n",
      "train loss:0.5195583564352719\n",
      "train loss:0.6962575353327926\n",
      "train loss:0.7427675539118836\n",
      "train loss:0.6941505540886029\n",
      "train loss:0.7912251628472395\n",
      "train loss:0.7594778601221341\n",
      "train loss:0.617729818091577\n",
      "train loss:0.9493825880547199\n",
      "train loss:0.6221725511796428\n",
      "train loss:0.8600761015401618\n",
      "train loss:0.5913109418710518\n",
      "train loss:0.8952290552760175\n",
      "train loss:0.914603829189039\n",
      "train loss:0.548974591313731\n",
      "train loss:0.7261003684284139\n",
      "train loss:0.8198014107544388\n",
      "train loss:0.648532543529699\n",
      "train loss:1.0024157276120909\n",
      "train loss:0.6770120872742253\n",
      "train loss:0.8444165673006359\n",
      "train loss:0.7592065525199826\n",
      "train loss:0.8943131777255764\n",
      "train loss:0.8275386916246936\n",
      "train loss:0.8100356973479369\n",
      "train loss:0.6808837410044474\n",
      "train loss:0.7865253313419324\n",
      "train loss:0.7880482272007525\n",
      "train loss:0.919216837503081\n",
      "train loss:0.7629842717081915\n",
      "train loss:0.8505026867787856\n",
      "train loss:0.7651639846498225\n",
      "train loss:0.6783400144748284\n",
      "train loss:0.8604208166959474\n",
      "train loss:0.7560817017337064\n",
      "train loss:0.7224230927748132\n",
      "train loss:0.7299247540827034\n",
      "train loss:0.6975485497847962\n",
      "train loss:0.8537659262349366\n",
      "train loss:0.7566740463180133\n",
      "train loss:0.8428106158766842\n",
      "train loss:0.7337504841803725\n",
      "train loss:0.8688580728210568\n",
      "train loss:0.8290019135196545\n",
      "train loss:0.7726651058035716\n",
      "train loss:0.6852150783685655\n",
      "train loss:0.6930392155981346\n",
      "train loss:0.8654616138538027\n",
      "train loss:0.961512129477208\n",
      "train loss:0.774047188045567\n",
      "train loss:0.7637095422383868\n",
      "train loss:0.6558883616169058\n",
      "train loss:0.5921999533340006\n",
      "train loss:0.7388037916258314\n",
      "train loss:0.6233256639587927\n",
      "train loss:0.9241635050451265\n",
      "train loss:0.6773609325363281\n",
      "train loss:0.6529251694850511\n",
      "train loss:0.847912263509308\n",
      "train loss:0.7653997633740092\n",
      "train loss:0.6822397975058887\n",
      "train loss:0.8800557365851478\n",
      "train loss:0.6854383535467473\n",
      "train loss:0.7111793635633871\n",
      "train loss:0.6355851234562128\n",
      "train loss:0.7057988598906806\n",
      "train loss:0.5927330844021818\n",
      "train loss:0.8089941109489655\n",
      "train loss:0.6813375855803449\n",
      "train loss:0.9475876618014982\n",
      "train loss:0.7505081504022515\n",
      "train loss:0.6808196928877952\n",
      "train loss:0.9949512716624618\n",
      "train loss:0.7682332317956582\n",
      "train loss:0.7627863049193588\n",
      "train loss:0.5818400229371425\n",
      "train loss:0.6494920039898701\n",
      "train loss:0.8945042521132837\n",
      "train loss:0.6341538702802765\n",
      "train loss:0.650874346014968\n",
      "train loss:0.9575347419868304\n",
      "train loss:0.7852277351322405\n",
      "train loss:0.6979999377744365\n",
      "train loss:0.7217503456485609\n",
      "train loss:0.8357541006708717\n",
      "train loss:0.6500835555322237\n",
      "train loss:0.6372002856089667\n",
      "train loss:0.7961882953281488\n",
      "train loss:0.6571882918003457\n",
      "train loss:0.7508455954858451\n",
      "train loss:0.7580843567442074\n",
      "train loss:0.6377631222340703\n",
      "train loss:0.7961278197043528\n",
      "train loss:0.7765234969944548\n",
      "train loss:0.7989830163796954\n",
      "train loss:0.7416475056935101\n",
      "train loss:0.7686923836270578\n",
      "train loss:0.6408882086857808\n",
      "train loss:0.5768154613906263\n",
      "train loss:0.9065737745532394\n",
      "train loss:0.8005226168996984\n",
      "train loss:0.7004209431257782\n",
      "train loss:0.7429804771736808\n",
      "train loss:0.8253754362267318\n",
      "train loss:0.7921480730380114\n",
      "train loss:0.6220523546733062\n",
      "train loss:0.7048972232465454\n",
      "train loss:0.7250399978850133\n",
      "train loss:0.9323529341071928\n",
      "train loss:0.6635258532072126\n",
      "train loss:0.6895710026455549\n",
      "train loss:0.7278921277961008\n",
      "train loss:0.727647231504977\n",
      "train loss:0.6265856357401831\n",
      "train loss:0.7349978780171085\n",
      "train loss:0.8357438945823296\n",
      "train loss:0.6795186378088789\n",
      "train loss:0.9070853716562713\n",
      "train loss:0.9449515990371665\n",
      "train loss:0.96858748472155\n",
      "train loss:0.815876356921114\n",
      "train loss:0.7221483242970423\n",
      "train loss:0.8181912517424088\n",
      "train loss:0.9463942401820787\n",
      "train loss:0.8601563482466184\n",
      "train loss:0.6675811069921287\n",
      "train loss:0.7263632164120863\n",
      "train loss:0.8359550473132334\n",
      "train loss:0.7737431167721102\n",
      "train loss:0.7067754193416229\n",
      "=== epoch:18, train acc:0.745, test acc:0.583 ===\n",
      "train loss:0.7141808211599538\n",
      "train loss:0.5977079326221681\n",
      "train loss:0.6917990037872115\n",
      "train loss:0.749926770658127\n",
      "train loss:0.8049546373816721\n",
      "train loss:0.977547343272608\n",
      "train loss:0.6972049968904466\n",
      "train loss:0.836545497082086\n",
      "train loss:0.7452102011042616\n",
      "train loss:0.8701934701046813\n",
      "train loss:0.6682665540943487\n",
      "train loss:0.7591809709468587\n",
      "train loss:0.9192725300471274\n",
      "train loss:0.7684009008104024\n",
      "train loss:0.6992843285343612\n",
      "train loss:0.5757052174260505\n",
      "train loss:0.7909549250081389\n",
      "train loss:0.7401501930651083\n",
      "train loss:0.8247521296138567\n",
      "train loss:0.770195296206567\n",
      "train loss:0.7434291338909473\n",
      "train loss:0.7093683440001345\n",
      "train loss:0.676027728283318\n",
      "train loss:1.0757632098823653\n",
      "train loss:0.7745403085444333\n",
      "train loss:0.7844332113122345\n",
      "train loss:0.8862412090198997\n",
      "train loss:0.6773553297886232\n",
      "train loss:0.8617805858234171\n",
      "train loss:0.7936265920730868\n",
      "train loss:0.8789010009296142\n",
      "train loss:0.9655907185132004\n",
      "train loss:0.7923234015384287\n",
      "train loss:0.6141335231076801\n",
      "train loss:0.8316739909731148\n",
      "train loss:0.7595831719701487\n",
      "train loss:0.5310100009346822\n",
      "train loss:0.9571854825308505\n",
      "train loss:0.6637708702079774\n",
      "train loss:0.5953761251296161\n",
      "train loss:0.7323786158928688\n",
      "train loss:0.6357635403894251\n",
      "train loss:0.6246384904677078\n",
      "train loss:0.7350926191396213\n",
      "train loss:0.8093025031207364\n",
      "train loss:0.7729397322405837\n",
      "train loss:0.9603130965834833\n",
      "train loss:0.7266776751089563\n",
      "train loss:0.798895283611246\n",
      "train loss:0.7820709589343441\n",
      "train loss:0.6638305829676077\n",
      "train loss:0.6188907490207375\n",
      "train loss:0.878625888986558\n",
      "train loss:0.8365313579077739\n",
      "train loss:0.7455851822217341\n",
      "train loss:0.7605185899642484\n",
      "train loss:0.7460848715266813\n",
      "train loss:0.5278511826713735\n",
      "train loss:0.6492814318089758\n",
      "train loss:0.6831308232764818\n",
      "train loss:0.6611591628232196\n",
      "train loss:0.7866495169277712\n",
      "train loss:0.8977882642092784\n",
      "train loss:0.7788704901197084\n",
      "train loss:0.6696423739597179\n",
      "train loss:0.7801900715272941\n",
      "train loss:0.5566171178005468\n",
      "train loss:0.6332063503948434\n",
      "train loss:0.8523568907529028\n",
      "train loss:0.6972075099259155\n",
      "train loss:0.8407154037779233\n",
      "train loss:0.9286906603056795\n",
      "train loss:0.8651768013570937\n",
      "train loss:0.7294932410015487\n",
      "train loss:0.9199368004898129\n",
      "train loss:0.8019012383679671\n",
      "train loss:0.6747192949164293\n",
      "train loss:0.7833782802013088\n",
      "train loss:0.5994821879782534\n",
      "train loss:0.8139108253381777\n",
      "train loss:0.7460790043389788\n",
      "train loss:0.682287581053938\n",
      "train loss:0.7567921297054191\n",
      "train loss:0.7895695062271418\n",
      "train loss:0.7096553381086472\n",
      "train loss:0.8239383459699111\n",
      "train loss:0.706340607059206\n",
      "train loss:0.7431345328108054\n",
      "train loss:0.6056121628047892\n",
      "train loss:0.6338365853841741\n",
      "train loss:0.6952770203258045\n",
      "train loss:0.767414000871514\n",
      "train loss:0.5553519710925646\n",
      "train loss:0.6771935258063922\n",
      "train loss:0.8078578290607239\n",
      "train loss:0.7076476085240752\n",
      "train loss:0.7827364062249154\n",
      "train loss:0.7382125309716591\n",
      "train loss:0.7127844064870811\n",
      "train loss:0.6174842954242568\n",
      "train loss:0.7018319564627636\n",
      "train loss:0.9684769890234262\n",
      "train loss:0.7282505293166243\n",
      "train loss:0.7095294153571396\n",
      "train loss:0.7356299454980311\n",
      "train loss:0.6766075734124045\n",
      "train loss:1.077662989271343\n",
      "train loss:0.6998463292082255\n",
      "train loss:0.7527956260859028\n",
      "train loss:0.8100756005117327\n",
      "train loss:0.7140363570304088\n",
      "train loss:0.7583214714033116\n",
      "train loss:0.7256488973682376\n",
      "train loss:0.7105611719670479\n",
      "train loss:0.6389032727230723\n",
      "train loss:0.7062863970792108\n",
      "train loss:0.7589448283487229\n",
      "train loss:0.676244842889485\n",
      "train loss:0.7993372252746869\n",
      "train loss:0.6550294440662665\n",
      "train loss:0.8862467175832414\n",
      "train loss:0.9120736476090595\n",
      "train loss:0.8814896907737103\n",
      "train loss:0.7307143107571307\n",
      "train loss:0.657528239703744\n",
      "train loss:0.7526705869720378\n",
      "train loss:0.9184932468624933\n",
      "train loss:0.6384516621982871\n",
      "train loss:0.9385789217124461\n",
      "train loss:0.8449961292094954\n",
      "train loss:0.6921254770055947\n",
      "train loss:0.9059983330682095\n",
      "train loss:0.8136016963157771\n",
      "train loss:0.8014408702924375\n",
      "train loss:0.6477486362605\n",
      "train loss:0.760390209697392\n",
      "train loss:0.8105357170512884\n",
      "train loss:0.6668380929555147\n",
      "train loss:0.8019791812565615\n",
      "train loss:0.9081197462167432\n",
      "train loss:0.8094473656495664\n",
      "train loss:0.9492256016170738\n",
      "train loss:0.7137131637886753\n",
      "train loss:0.7709365497303815\n",
      "train loss:0.7071077063813925\n",
      "train loss:0.7076798348592778\n",
      "train loss:0.6284323967372542\n",
      "train loss:0.692466115369847\n",
      "train loss:0.9535225376303917\n",
      "train loss:0.866175385156464\n",
      "train loss:0.7818093888587953\n",
      "train loss:0.7313352931023626\n",
      "train loss:0.626637923877043\n",
      "train loss:0.5548786054974294\n",
      "train loss:0.7847430798117796\n",
      "train loss:0.6856349849946326\n",
      "train loss:0.8721460339277933\n",
      "train loss:0.6270051070451637\n",
      "train loss:0.689953255486766\n",
      "train loss:0.8567850797439291\n",
      "train loss:0.6835147574361582\n",
      "train loss:0.8125477435927422\n",
      "train loss:0.8667113893059338\n",
      "train loss:0.5901607680369558\n",
      "train loss:0.7383901613555592\n",
      "train loss:0.8008207698579958\n",
      "train loss:0.5887159214798838\n",
      "train loss:0.7274096787428194\n",
      "train loss:0.6253961109690357\n",
      "train loss:0.7395493637719881\n",
      "train loss:0.8807429725621625\n",
      "train loss:0.6912863078085385\n",
      "train loss:0.7291449781771309\n",
      "train loss:0.7436069240170938\n",
      "train loss:0.5940243797509779\n",
      "train loss:0.6225276979123614\n",
      "train loss:0.7463934571597879\n",
      "train loss:0.6626801884175613\n",
      "train loss:0.7186612993539327\n",
      "train loss:0.7290473057667611\n",
      "train loss:0.6972537368533369\n",
      "train loss:0.78356097768886\n",
      "train loss:0.6126676877877418\n",
      "train loss:0.6105426370764683\n",
      "train loss:0.6594894843089136\n",
      "train loss:0.6935847151668252\n",
      "train loss:0.7257378681169119\n",
      "train loss:0.48437277652828575\n",
      "train loss:0.9299880972515497\n",
      "train loss:0.7428378941595539\n",
      "train loss:0.6733171789115316\n",
      "train loss:0.6114345007430143\n",
      "train loss:0.7651236343446223\n",
      "train loss:0.8935517247300027\n",
      "train loss:0.791289107348772\n",
      "train loss:0.8824838714790911\n",
      "train loss:0.6295261895673364\n",
      "train loss:0.6443803780584781\n",
      "train loss:0.799307292386224\n",
      "train loss:0.8908206892785767\n",
      "train loss:0.6489463630337453\n",
      "train loss:0.6647552065968434\n",
      "train loss:0.7918324599842861\n",
      "train loss:0.7999009387477379\n",
      "train loss:0.7082079387310845\n",
      "train loss:0.7874284997954366\n",
      "train loss:0.6511693533933333\n",
      "train loss:0.6444068109768252\n",
      "train loss:0.7392288346812742\n",
      "train loss:0.7355183018076202\n",
      "train loss:0.6171435994270089\n",
      "train loss:0.6415889939209655\n",
      "train loss:0.8996241315931077\n",
      "train loss:0.5233414788414898\n",
      "train loss:0.6842316232833844\n",
      "train loss:0.713628912235275\n",
      "train loss:0.738500189231395\n",
      "train loss:0.7309510470678872\n",
      "train loss:0.5956283675077051\n",
      "train loss:0.8455986504107871\n",
      "train loss:0.9970706109583571\n",
      "train loss:0.6935573832930548\n",
      "train loss:0.814903195711248\n",
      "train loss:0.7209700873124661\n",
      "train loss:0.737762015947184\n",
      "train loss:0.6919867353536749\n",
      "train loss:0.6657622701186706\n",
      "train loss:0.7055901987279531\n",
      "train loss:0.685704896052666\n",
      "train loss:0.7360440987185464\n",
      "train loss:0.9193478094639757\n",
      "train loss:0.8240069076373271\n",
      "train loss:0.6686230344436573\n",
      "train loss:0.8630775578239471\n",
      "train loss:0.7303393181348325\n",
      "train loss:0.727678400870102\n",
      "train loss:0.7555801943236057\n",
      "train loss:0.7571421057436639\n",
      "train loss:0.7462908918776564\n",
      "train loss:0.7736155573717238\n",
      "train loss:0.5138719821075882\n",
      "train loss:0.6304819147862055\n",
      "train loss:0.7734609240818797\n",
      "train loss:0.7951772249675447\n",
      "train loss:0.7438247675334766\n",
      "train loss:0.7317450555849535\n",
      "train loss:0.6824698825465351\n",
      "train loss:0.801611396289172\n",
      "train loss:0.766463924253594\n",
      "train loss:0.737557072370237\n",
      "train loss:0.6763471493540955\n",
      "train loss:0.8104273118723161\n",
      "train loss:0.713084495803852\n",
      "train loss:0.6127268085464724\n",
      "train loss:0.7606628035337075\n",
      "train loss:0.8319025560522348\n",
      "train loss:0.9529533711273794\n",
      "train loss:0.6514944415677317\n",
      "train loss:0.7263987471657241\n",
      "train loss:0.8610102378664187\n",
      "train loss:0.7613316125380396\n",
      "train loss:0.5846305841967208\n",
      "train loss:0.7474222298374782\n",
      "train loss:0.7489850688957531\n",
      "train loss:0.6410543260340296\n",
      "train loss:0.5874458210982422\n",
      "train loss:0.7409885028101785\n",
      "train loss:0.650035536714332\n",
      "train loss:0.6764121110327056\n",
      "train loss:0.7496616086087912\n",
      "train loss:0.7745740272223738\n",
      "train loss:0.7586226861209653\n",
      "train loss:0.7190490469301225\n",
      "train loss:0.6380335120662525\n",
      "train loss:0.6169145536427691\n",
      "train loss:0.6482569973417956\n",
      "train loss:0.6757338554801655\n",
      "train loss:0.7821810657681632\n",
      "train loss:0.7216637501359933\n",
      "train loss:0.7264591919952081\n",
      "train loss:0.6005678999452584\n",
      "train loss:0.8406039639279578\n",
      "train loss:0.590939548226741\n",
      "train loss:0.6510623588248573\n",
      "train loss:0.7374254574078744\n",
      "train loss:0.7332054309177255\n",
      "train loss:0.6331120685793398\n",
      "train loss:0.5971004151462601\n",
      "train loss:0.6609226022985021\n",
      "train loss:0.7456705860149576\n",
      "train loss:0.6232895950573798\n",
      "train loss:0.7799794050781577\n",
      "train loss:0.6898930422840353\n",
      "train loss:0.9371204009489695\n",
      "train loss:0.5959008052068938\n",
      "train loss:0.7091425392727281\n",
      "train loss:0.720734951031628\n",
      "train loss:0.8833510480357489\n",
      "train loss:0.7792271553775617\n",
      "train loss:0.9061789038539066\n",
      "train loss:0.6037637346487156\n",
      "train loss:0.8716629371414037\n",
      "train loss:0.7729874030666707\n",
      "train loss:0.78016133122934\n",
      "train loss:0.6742210950186239\n",
      "train loss:0.7495014010537588\n",
      "train loss:0.6827972598965407\n",
      "train loss:0.9187672078965068\n",
      "train loss:0.6436810082463974\n",
      "train loss:0.708230608509735\n",
      "train loss:0.8779444821850728\n",
      "train loss:0.676792658895478\n",
      "train loss:0.5512229334111374\n",
      "train loss:0.6874842178757362\n",
      "train loss:0.7147280571052207\n",
      "train loss:0.6349961284650171\n",
      "train loss:0.7585170886940333\n",
      "train loss:0.9028005433488613\n",
      "train loss:0.7534766196086246\n",
      "train loss:0.6727613491972751\n",
      "train loss:0.8635182641295733\n",
      "train loss:0.7106490147359285\n",
      "train loss:0.5972107002964342\n",
      "train loss:0.6736804539242709\n",
      "train loss:0.9223058467650795\n",
      "train loss:0.7556454900058458\n",
      "train loss:0.8593257061532609\n",
      "train loss:0.8861576321186557\n",
      "train loss:0.7645915488005909\n",
      "train loss:0.8018009739654454\n",
      "train loss:0.699874437265857\n",
      "train loss:0.6954117975326584\n",
      "train loss:0.7685812764311569\n",
      "train loss:0.6025645635631846\n",
      "train loss:0.7655072665330619\n",
      "train loss:0.704031049325128\n",
      "train loss:0.646423766887467\n",
      "train loss:0.7938889054590043\n",
      "train loss:0.7179719116085734\n",
      "train loss:0.6580595354349918\n",
      "train loss:0.6808268973313729\n",
      "train loss:0.7987806679477238\n",
      "train loss:0.710240772448189\n",
      "train loss:0.6448706395726578\n",
      "train loss:0.7411230216390439\n",
      "train loss:0.7892760055240495\n",
      "train loss:0.6372543318225456\n",
      "train loss:0.8586070606660529\n",
      "train loss:0.6797533742727592\n",
      "train loss:0.7997203383741619\n",
      "train loss:0.8059206882169971\n",
      "train loss:0.8264936029646419\n",
      "train loss:0.7622566076947238\n",
      "train loss:0.8588957156316499\n",
      "train loss:0.7389230006212408\n",
      "train loss:0.574501281417172\n",
      "train loss:0.7103394228518937\n",
      "train loss:0.7375033399362607\n",
      "train loss:0.7368393532787758\n",
      "train loss:0.8233732563945648\n",
      "train loss:0.6819184221436855\n",
      "train loss:0.67708925191526\n",
      "train loss:0.6596645322996038\n",
      "train loss:0.6097206316728818\n",
      "train loss:0.7738001815636107\n",
      "train loss:0.7108371930929542\n",
      "train loss:0.8214787811468862\n",
      "train loss:0.6529552975105075\n",
      "train loss:0.692862971022872\n",
      "train loss:0.8414926764582847\n",
      "train loss:0.6795839500344517\n",
      "train loss:0.6796500400309707\n",
      "train loss:0.7291444484808882\n",
      "train loss:0.8965456939146742\n",
      "train loss:0.78238059541333\n",
      "train loss:0.8968747947927059\n",
      "train loss:0.6413833849533782\n",
      "train loss:0.6835358894390551\n",
      "train loss:0.8305435252476486\n",
      "train loss:0.668868289787769\n",
      "train loss:0.7421889706649222\n",
      "train loss:0.6549236281740296\n",
      "train loss:0.5970146835779415\n",
      "train loss:0.7473847054487861\n",
      "train loss:0.8908232371646051\n",
      "train loss:0.7494684756716401\n",
      "train loss:0.7236649926978026\n",
      "train loss:0.7097176013002369\n",
      "train loss:0.6196039187818905\n",
      "train loss:0.9566156562705248\n",
      "train loss:0.7297237297806625\n",
      "train loss:0.6992053808188509\n",
      "train loss:0.6648311944460036\n",
      "train loss:0.5721147015571522\n",
      "train loss:0.8084214274426837\n",
      "train loss:0.8303674234219878\n",
      "train loss:0.7634324839743275\n",
      "train loss:0.7026545495917731\n",
      "train loss:0.7810553445951662\n",
      "train loss:0.698950536918748\n",
      "=== epoch:19, train acc:0.771, test acc:0.592 ===\n",
      "train loss:0.8883990548950065\n",
      "train loss:0.657577737351956\n",
      "train loss:0.8089819881257974\n",
      "train loss:0.5791892965918779\n",
      "train loss:0.7645987260040797\n",
      "train loss:0.8223226211560869\n",
      "train loss:0.766173189121019\n",
      "train loss:0.7685096775736376\n",
      "train loss:0.6091566577418057\n",
      "train loss:0.7716004909867463\n",
      "train loss:0.6978478710270646\n",
      "train loss:0.6966446619081696\n",
      "train loss:0.7908146193156845\n",
      "train loss:0.8527813048325377\n",
      "train loss:0.7164232496600985\n",
      "train loss:0.7523391660984534\n",
      "train loss:0.5709187393887416\n",
      "train loss:0.7579913811588077\n",
      "train loss:0.8660729601958757\n",
      "train loss:0.7162745094610274\n",
      "train loss:0.5309048837619893\n",
      "train loss:0.7117185971552646\n",
      "train loss:0.776143307694817\n",
      "train loss:0.7610611655311185\n",
      "train loss:0.6929689149776124\n",
      "train loss:0.8435240233219622\n",
      "train loss:0.9564230911755577\n",
      "train loss:0.8403186987449949\n",
      "train loss:0.9352825956375468\n",
      "train loss:0.8534439441136054\n",
      "train loss:0.8101769522822793\n",
      "train loss:0.9081219430664373\n",
      "train loss:0.5800674464071102\n",
      "train loss:0.660085382409862\n",
      "train loss:0.7337809711282923\n",
      "train loss:0.8863867838628268\n",
      "train loss:0.6133860454584229\n",
      "train loss:0.5813859050610509\n",
      "train loss:0.6081548191242198\n",
      "train loss:0.8056814525428494\n",
      "train loss:0.7610992649997067\n",
      "train loss:0.6564413283948117\n",
      "train loss:0.8325557039617907\n",
      "train loss:0.7451201587944593\n",
      "train loss:0.6758722557788603\n",
      "train loss:0.8597758516587642\n",
      "train loss:0.8442150595023954\n",
      "train loss:0.5598433597342297\n",
      "train loss:0.653489987726125\n",
      "train loss:0.639005024674778\n",
      "train loss:0.7927682710129942\n",
      "train loss:0.7480488408286703\n",
      "train loss:0.8317653236505599\n",
      "train loss:0.634423462692569\n",
      "train loss:0.74066767305155\n",
      "train loss:0.8423839185618627\n",
      "train loss:0.652547347418915\n",
      "train loss:0.6054609948219026\n",
      "train loss:0.9599397023781379\n",
      "train loss:0.6840252654283602\n",
      "train loss:0.7789874776966245\n",
      "train loss:0.8138576672218563\n",
      "train loss:0.7380660982786322\n",
      "train loss:0.5906777150571645\n",
      "train loss:0.6253904026316126\n",
      "train loss:0.8248691527326664\n",
      "train loss:0.7297430023667608\n",
      "train loss:0.7752327828204189\n",
      "train loss:0.6341723412591223\n",
      "train loss:0.748168248980041\n",
      "train loss:0.8377220932008796\n",
      "train loss:0.7458704387447855\n",
      "train loss:0.7872151094840423\n",
      "train loss:0.6370492114953891\n",
      "train loss:0.7903993585994934\n",
      "train loss:0.5646360563209843\n",
      "train loss:0.8413156728717155\n",
      "train loss:0.6138891302270791\n",
      "train loss:0.7354434259181772\n",
      "train loss:0.7175894253646447\n",
      "train loss:0.6923906175649707\n",
      "train loss:0.6496985320256294\n",
      "train loss:0.6640190225421727\n",
      "train loss:0.6611939110683157\n",
      "train loss:0.5181914629206837\n",
      "train loss:0.8229660731148399\n",
      "train loss:0.5581869814792584\n",
      "train loss:0.7663605137025137\n",
      "train loss:0.8388719520018073\n",
      "train loss:0.602368001623672\n",
      "train loss:0.5873109134255108\n",
      "train loss:0.7088925581756602\n",
      "train loss:0.6542234857544753\n",
      "train loss:0.5971294934098116\n",
      "train loss:0.7334186783184817\n",
      "train loss:0.631573942719814\n",
      "train loss:0.637427048534303\n",
      "train loss:0.6573140023230344\n",
      "train loss:0.8616031083304899\n",
      "train loss:0.8241556612650429\n",
      "train loss:0.676018225869041\n",
      "train loss:0.5462092655992963\n",
      "train loss:0.6876777021540019\n",
      "train loss:0.5297633552845956\n",
      "train loss:0.8119725466217089\n",
      "train loss:0.5592266080927897\n",
      "train loss:0.7632288648198717\n",
      "train loss:0.6682806572283705\n",
      "train loss:0.6574835382362784\n",
      "train loss:0.7381833583545709\n",
      "train loss:0.7202720969229657\n",
      "train loss:0.6998629267787725\n",
      "train loss:0.70171497153882\n",
      "train loss:0.5784203894569788\n",
      "train loss:0.7373690840566667\n",
      "train loss:0.7196298889583468\n",
      "train loss:0.6089707078186155\n",
      "train loss:0.8097603912428224\n",
      "train loss:0.7795607445725223\n",
      "train loss:0.7849007293450767\n",
      "train loss:0.6238569009413608\n",
      "train loss:0.6201145235585259\n",
      "train loss:0.8751791948296185\n",
      "train loss:0.6479723106291745\n",
      "train loss:0.7372033601563976\n",
      "train loss:0.629302121166144\n",
      "train loss:0.6341659406590471\n",
      "train loss:0.7566527906716628\n",
      "train loss:0.5836827769252606\n",
      "train loss:0.5940155279021394\n",
      "train loss:0.5647275377218491\n",
      "train loss:0.6515686502600615\n",
      "train loss:0.7284380132540249\n",
      "train loss:0.636936498199191\n",
      "train loss:0.8861836494674816\n",
      "train loss:0.5747838802468691\n",
      "train loss:0.7264679186386986\n",
      "train loss:0.6289432548005878\n",
      "train loss:0.6997297961401856\n",
      "train loss:0.6039033341218814\n",
      "train loss:0.794726127168849\n",
      "train loss:0.7785613326472509\n",
      "train loss:0.6890957688032604\n",
      "train loss:0.6809402529722982\n",
      "train loss:0.7356824765326394\n",
      "train loss:0.7912907332980076\n",
      "train loss:0.5498759019699146\n",
      "train loss:0.7833032257480785\n",
      "train loss:0.6583532594017885\n",
      "train loss:0.6523578872238854\n",
      "train loss:0.7548700416898252\n",
      "train loss:0.7066425324393929\n",
      "train loss:0.6405454937224111\n",
      "train loss:0.7271633390081347\n",
      "train loss:0.9145265522955183\n",
      "train loss:0.7225847585671932\n",
      "train loss:0.7655300326509094\n",
      "train loss:0.664840527654109\n",
      "train loss:0.665831825448191\n",
      "train loss:0.7982599127196432\n",
      "train loss:0.5044443873581301\n",
      "train loss:0.8656460071857964\n",
      "train loss:0.707339301552854\n",
      "train loss:0.7880491563666123\n",
      "train loss:0.7029468188894801\n",
      "train loss:0.7745095787861196\n",
      "train loss:0.7155099502314995\n",
      "train loss:0.8605361378975634\n",
      "train loss:0.6149354128471355\n",
      "train loss:0.6437076523452044\n",
      "train loss:0.7022493654620665\n",
      "train loss:0.8617815810532174\n",
      "train loss:0.6060689346678578\n",
      "train loss:0.70540478933372\n",
      "train loss:0.7216337342725246\n",
      "train loss:0.7548440494664379\n",
      "train loss:0.5860901636939436\n",
      "train loss:0.7229581090875302\n",
      "train loss:0.6108894701601639\n",
      "train loss:0.7660664202784179\n",
      "train loss:0.7525175315478522\n",
      "train loss:0.5160484087739818\n",
      "train loss:0.6488897919410583\n",
      "train loss:0.6985898367597667\n",
      "train loss:0.9127104891017335\n",
      "train loss:0.7118082902466525\n",
      "train loss:0.615679458176731\n",
      "train loss:0.7112413533281263\n",
      "train loss:0.6909016472884957\n",
      "train loss:0.7172408680559721\n",
      "train loss:0.5756451967998809\n",
      "train loss:0.7045395659248536\n",
      "train loss:0.5753065373454687\n",
      "train loss:0.7383983474314293\n",
      "train loss:0.7707533839767581\n",
      "train loss:0.7114848111661081\n",
      "train loss:0.6891957565175578\n",
      "train loss:0.6577216426390141\n",
      "train loss:0.7950342492489252\n",
      "train loss:0.5881896802069133\n",
      "train loss:0.6214998505495288\n",
      "train loss:0.6724087207379063\n",
      "train loss:0.6826425361885117\n",
      "train loss:0.574034916655251\n",
      "train loss:0.5669759851114979\n",
      "train loss:0.6103697516558096\n",
      "train loss:0.6149217935745649\n",
      "train loss:0.730338250161996\n",
      "train loss:0.7022433926996379\n",
      "train loss:0.6373531643689879\n",
      "train loss:0.5745235608998415\n",
      "train loss:0.858329372735465\n",
      "train loss:0.6868078910379879\n",
      "train loss:0.8661006068644835\n",
      "train loss:0.7234651232697827\n",
      "train loss:0.5391131974847666\n",
      "train loss:0.5532619799492737\n",
      "train loss:0.6332318106525792\n",
      "train loss:0.6390842271196256\n",
      "train loss:0.8227379636082718\n",
      "train loss:0.625251776964314\n",
      "train loss:0.5749807478644164\n",
      "train loss:0.589913694570341\n",
      "train loss:0.6186290036466972\n",
      "train loss:0.895590471525091\n",
      "train loss:0.6852152257857408\n",
      "train loss:0.5579269543602193\n",
      "train loss:0.6512774216496537\n",
      "train loss:0.6838228355068249\n",
      "train loss:0.6502302398856766\n",
      "train loss:0.7201608049879689\n",
      "train loss:0.6993203857087632\n",
      "train loss:0.7119564583397119\n",
      "train loss:0.7289672054839719\n",
      "train loss:0.6179472529015158\n",
      "train loss:0.6874141089195581\n",
      "train loss:0.7505495651237881\n",
      "train loss:0.6611162280313794\n",
      "train loss:0.6667265640200699\n",
      "train loss:0.6035443128858882\n",
      "train loss:0.830041771462995\n",
      "train loss:0.6551479593999185\n",
      "train loss:0.7324654171014353\n",
      "train loss:0.6205132569126578\n",
      "train loss:0.7036673438737482\n",
      "train loss:0.5407962218514119\n",
      "train loss:0.6302420753136069\n",
      "train loss:0.7504299618411265\n",
      "train loss:0.7273451085550431\n",
      "train loss:0.7102848985492257\n",
      "train loss:0.5562144771195296\n",
      "train loss:0.61401107255603\n",
      "train loss:0.7167975396766114\n",
      "train loss:0.7078887550521684\n",
      "train loss:0.7545484415768664\n",
      "train loss:0.6674807250330113\n",
      "train loss:0.8905998210907851\n",
      "train loss:0.901886782134058\n",
      "train loss:0.688485617424706\n",
      "train loss:0.709154136242555\n",
      "train loss:0.7607120550561062\n",
      "train loss:0.5708098528444119\n",
      "train loss:0.7264024028993843\n",
      "train loss:0.7997970400115484\n",
      "train loss:0.7189005041736372\n",
      "train loss:0.6533242654457773\n",
      "train loss:0.7429711404270343\n",
      "train loss:0.7498951010484095\n",
      "train loss:0.7529816314472771\n",
      "train loss:0.6513519275173693\n",
      "train loss:0.6399875082369761\n",
      "train loss:0.7394611924248737\n",
      "train loss:0.6994897933685283\n",
      "train loss:0.5517976517356173\n",
      "train loss:0.9434612781990782\n",
      "train loss:0.7303265929750935\n",
      "train loss:0.7555081459886308\n",
      "train loss:0.7590329122096507\n",
      "train loss:0.6022173370900795\n",
      "train loss:0.7827679553897025\n",
      "train loss:0.5168754759742015\n",
      "train loss:0.6735017102218748\n",
      "train loss:0.528708598056011\n",
      "train loss:0.7520667577945449\n",
      "train loss:0.6727751354754384\n",
      "train loss:0.778012439499185\n",
      "train loss:0.8723031903954157\n",
      "train loss:0.7529823548191444\n",
      "train loss:0.7404934662482987\n",
      "train loss:0.7952650604994598\n",
      "train loss:0.7350285070688675\n",
      "train loss:0.7197003979718879\n",
      "train loss:0.7677205423824204\n",
      "train loss:0.7344532614237791\n",
      "train loss:0.7843701946675882\n",
      "train loss:0.5512484808688393\n",
      "train loss:0.6398355297310446\n",
      "train loss:0.8574485701973495\n",
      "train loss:0.6490387214081089\n",
      "train loss:0.7449340480861112\n",
      "train loss:0.8325869884704601\n",
      "train loss:0.8414265693458179\n",
      "train loss:0.7174082683771574\n",
      "train loss:0.6666299818590911\n",
      "train loss:0.8726715068362718\n",
      "train loss:0.6403310881036706\n",
      "train loss:0.6665870705569255\n",
      "train loss:0.7005033453341717\n",
      "train loss:0.7722746596881807\n",
      "train loss:0.5471287604000387\n",
      "train loss:0.6332212698783574\n",
      "train loss:0.8056815578623663\n",
      "train loss:0.6213102376995748\n",
      "train loss:0.7705485068995632\n",
      "train loss:0.611125618531883\n",
      "train loss:0.6953262986983562\n",
      "train loss:0.7781839407001491\n",
      "train loss:0.5833371897154542\n",
      "train loss:0.7995070048608492\n",
      "train loss:0.7657713488834882\n",
      "train loss:0.7825267713085599\n",
      "train loss:0.7257665334839145\n",
      "train loss:0.5950772437157005\n",
      "train loss:0.7692547666346371\n",
      "train loss:0.7663735065899339\n",
      "train loss:0.669274943468923\n",
      "train loss:0.702672868565416\n",
      "train loss:0.7916958478564973\n",
      "train loss:0.7592517298723197\n",
      "train loss:0.7575108403572919\n",
      "train loss:0.8378853054810693\n",
      "train loss:0.6144321498061219\n",
      "train loss:0.5850064709047605\n",
      "train loss:0.7389486350235525\n",
      "train loss:0.5758647344373881\n",
      "train loss:0.5751366664417594\n",
      "train loss:0.7399891898588716\n",
      "train loss:0.5947590417483761\n",
      "train loss:0.7218944146176591\n",
      "train loss:0.583644594001899\n",
      "train loss:0.6634421152645237\n",
      "train loss:0.6458885467224039\n",
      "train loss:0.6665013255111641\n",
      "train loss:0.7420877925072712\n",
      "train loss:0.5661144865239893\n",
      "train loss:0.7075290617205593\n",
      "train loss:0.7664982793570084\n",
      "train loss:0.7851841846874354\n",
      "train loss:0.7335398535646723\n",
      "train loss:0.6730461098779061\n",
      "train loss:0.7440611457996485\n",
      "train loss:0.6521248430948383\n",
      "train loss:0.5684141507548647\n",
      "train loss:0.7773889489976215\n",
      "train loss:0.8078403072348642\n",
      "train loss:0.6708252398881288\n",
      "train loss:0.6619838449981938\n",
      "train loss:0.6656869198624894\n",
      "train loss:0.6949539453725335\n",
      "train loss:0.7332490998927392\n",
      "train loss:0.6198430159950102\n",
      "train loss:0.7890747716674794\n",
      "train loss:0.7200340315516743\n",
      "train loss:0.7458182779523725\n",
      "train loss:0.6607101462046178\n",
      "train loss:0.6413987793217828\n",
      "train loss:0.692013233713714\n",
      "train loss:0.7878007766938612\n",
      "train loss:0.852405844533325\n",
      "train loss:0.5084732302797342\n",
      "train loss:0.7033495902826215\n",
      "train loss:0.7298656894194668\n",
      "train loss:0.7523823542415436\n",
      "train loss:0.7291053440359876\n",
      "train loss:0.8773007673303566\n",
      "train loss:0.8503257363624438\n",
      "train loss:0.6947835701689519\n",
      "train loss:0.6394493865935367\n",
      "train loss:0.7255156115451369\n",
      "train loss:0.7381909339464109\n",
      "train loss:0.6916403904264742\n",
      "train loss:0.8280984700492562\n",
      "train loss:0.504642286395521\n",
      "train loss:0.8621650050075346\n",
      "train loss:0.7307860422665474\n",
      "train loss:0.7031574189980482\n",
      "train loss:0.6926838192369007\n",
      "train loss:0.5440307909774041\n",
      "train loss:0.7135552007672527\n",
      "train loss:0.9026761156107631\n",
      "train loss:0.7632215085360248\n",
      "train loss:0.47352524558256875\n",
      "train loss:0.586842252603616\n",
      "train loss:0.814142127400919\n",
      "train loss:0.7326658440018187\n",
      "train loss:0.6969558767582172\n",
      "train loss:0.6962388412859984\n",
      "train loss:0.6446946447754134\n",
      "train loss:0.667376385928304\n",
      "train loss:0.7918538287986974\n",
      "=== epoch:20, train acc:0.756, test acc:0.597 ===\n",
      "train loss:0.6712850499611922\n",
      "train loss:0.5940856614608229\n",
      "train loss:0.6609763952826363\n",
      "train loss:0.6656089004891284\n",
      "train loss:0.7377404701943746\n",
      "train loss:0.793393859877206\n",
      "train loss:0.7384693520796614\n",
      "train loss:0.6526713065569478\n",
      "train loss:0.6915629133077643\n",
      "train loss:0.6293552074184476\n",
      "train loss:0.824168270803447\n",
      "train loss:0.8171701793588517\n",
      "train loss:0.7849464379933292\n",
      "train loss:0.6934636087065351\n",
      "train loss:0.7965052706727227\n",
      "train loss:0.7810385224251252\n",
      "train loss:0.629185140881853\n",
      "train loss:0.6042169127095445\n",
      "train loss:0.6776298778732049\n",
      "train loss:0.7570123709091497\n",
      "train loss:0.7623242290105402\n",
      "train loss:0.6343590595980441\n",
      "train loss:0.7759173436021647\n",
      "train loss:0.6891521613175888\n",
      "train loss:0.7856299316409143\n",
      "train loss:0.5165995206217088\n",
      "train loss:0.7145135931756745\n",
      "train loss:0.6403824284177041\n",
      "train loss:0.784326679758105\n",
      "train loss:0.6905343804042914\n",
      "train loss:0.6110554404424542\n",
      "train loss:0.5531302716827862\n",
      "train loss:0.7068434220475371\n",
      "train loss:0.7443716272796774\n",
      "train loss:0.6355421739152244\n",
      "train loss:0.9555065027933151\n",
      "train loss:0.752047706011248\n",
      "train loss:0.7134806681781035\n",
      "train loss:0.8511569007721015\n",
      "train loss:0.7551532097958593\n",
      "train loss:0.7376430613965229\n",
      "train loss:0.7960424188940145\n",
      "train loss:0.5752728038437331\n",
      "train loss:0.7648065042275938\n",
      "train loss:0.6799337911962372\n",
      "train loss:0.6256840372618109\n",
      "train loss:0.6510780905885106\n",
      "train loss:0.8468604436327428\n",
      "train loss:0.5655378059022558\n",
      "train loss:0.8324816442860726\n",
      "train loss:0.5724633509219367\n",
      "train loss:0.6499328506180337\n",
      "train loss:0.8000148029967239\n",
      "train loss:0.678800788396751\n",
      "train loss:0.6991599458221898\n",
      "train loss:0.703559625398084\n",
      "train loss:0.5732232920958196\n",
      "train loss:0.6697677918014476\n",
      "train loss:0.7256936563425843\n",
      "train loss:0.5625917094868825\n",
      "train loss:0.7232858491673325\n",
      "train loss:0.6473217276738629\n",
      "train loss:0.6720705269255904\n",
      "train loss:0.6867920871710785\n",
      "train loss:0.794864619754438\n",
      "train loss:0.5306726388190998\n",
      "train loss:0.6242354314068311\n",
      "train loss:0.6911441848729823\n",
      "train loss:0.6201089512387983\n",
      "train loss:0.7588677075434195\n",
      "train loss:0.7722437059257694\n",
      "train loss:0.7014709071490646\n",
      "train loss:0.5735646462067705\n",
      "train loss:0.6310081665107556\n",
      "train loss:0.7866147582725851\n",
      "train loss:0.8591318156326649\n",
      "train loss:0.6092437799549845\n",
      "train loss:0.704993643763188\n",
      "train loss:0.6795136358679873\n",
      "train loss:0.6066635931264832\n",
      "train loss:0.5746526216254604\n",
      "train loss:0.5784517919615773\n",
      "train loss:0.6556160359351049\n",
      "train loss:0.7527456460626764\n",
      "train loss:0.6404525296896663\n",
      "train loss:0.6546143016559686\n",
      "train loss:0.5143241498917025\n",
      "train loss:0.5378357598746573\n",
      "train loss:0.6754223026701327\n",
      "train loss:0.6037703117090899\n",
      "train loss:0.7015247126012162\n",
      "train loss:0.7920930028995166\n",
      "train loss:0.650382194538203\n",
      "train loss:0.7680277292085287\n",
      "train loss:0.8079087755065233\n",
      "train loss:0.6247261352888729\n",
      "train loss:0.7591650776378949\n",
      "train loss:0.8723136218546682\n",
      "train loss:0.668820315703897\n",
      "train loss:0.6818292012886777\n",
      "train loss:0.7970436128169581\n",
      "train loss:0.6453705307897438\n",
      "train loss:0.6298805362784141\n",
      "train loss:0.8780221189115103\n",
      "train loss:0.7845268293663571\n",
      "train loss:0.5608811528079561\n",
      "train loss:0.49693525661798327\n",
      "train loss:0.5804033807074181\n",
      "train loss:0.6361139352571401\n",
      "train loss:0.6546382086255091\n",
      "train loss:0.6761918459441286\n",
      "train loss:0.5412243794473697\n",
      "train loss:0.7617944557843699\n",
      "train loss:0.7587263648640475\n",
      "train loss:0.7906838367232111\n",
      "train loss:0.6675975195660591\n",
      "train loss:0.8964091794663375\n",
      "train loss:0.7626037385060356\n",
      "train loss:0.5255136387553518\n",
      "train loss:0.6949375156708881\n",
      "train loss:0.7061960747826062\n",
      "train loss:0.8484610921229748\n",
      "train loss:0.667789394611171\n",
      "train loss:0.5084436946855976\n",
      "train loss:0.7516814266435253\n",
      "train loss:0.6599409111530212\n",
      "train loss:0.6639669570541966\n",
      "train loss:0.607096593126589\n",
      "train loss:0.534351582447092\n",
      "train loss:0.7512574722310055\n",
      "train loss:0.6175985809482907\n",
      "train loss:0.6705163892268415\n",
      "train loss:0.6739815756742993\n",
      "train loss:0.7082796379853231\n",
      "train loss:0.7398628630849253\n",
      "train loss:0.6304744537606156\n",
      "train loss:0.763673724265253\n",
      "train loss:0.7565105316117955\n",
      "train loss:0.7136921573942739\n",
      "train loss:0.8109671235639355\n",
      "train loss:0.7973975022643319\n",
      "train loss:0.6885221600588801\n",
      "train loss:0.7262453219899535\n",
      "train loss:0.8240296140463012\n",
      "train loss:0.7482232210890081\n",
      "train loss:0.5328723680770092\n",
      "train loss:0.6759752150664365\n",
      "train loss:0.6721520490636621\n",
      "train loss:0.6580776059934687\n",
      "train loss:0.7725231142991315\n",
      "train loss:0.8633056413778251\n",
      "train loss:0.6958469670592704\n",
      "train loss:0.6426346110047918\n",
      "train loss:0.6185009759831935\n",
      "train loss:0.7884440899642625\n",
      "train loss:0.6158909203476004\n",
      "train loss:0.6570535363522949\n",
      "train loss:0.791979249935569\n",
      "train loss:0.685240474495035\n",
      "train loss:0.7203311548687428\n",
      "train loss:0.6568827233540045\n",
      "train loss:0.6227088433174263\n",
      "train loss:0.761098223699304\n",
      "train loss:0.6774482070429144\n",
      "train loss:0.6428715685401504\n",
      "train loss:0.5579984001089975\n",
      "train loss:0.7173618792538744\n",
      "train loss:0.8776405688040945\n",
      "train loss:0.5990852928488756\n",
      "train loss:0.69134272086536\n",
      "train loss:0.675438285840024\n",
      "train loss:0.7729234471132174\n",
      "train loss:0.7001875442779908\n",
      "train loss:0.7028814749474799\n",
      "train loss:1.0363371248130824\n",
      "train loss:0.6347301935837623\n",
      "train loss:0.8665469432801538\n",
      "train loss:0.739756577393272\n",
      "train loss:0.6408639117547565\n",
      "train loss:0.9099439200493488\n",
      "train loss:0.632122232177367\n",
      "train loss:0.6093698238404667\n",
      "train loss:0.8046137751061865\n",
      "train loss:0.6537341835358832\n",
      "train loss:0.5943846657996424\n",
      "train loss:0.8396800051190457\n",
      "train loss:0.6144380446557239\n",
      "train loss:0.796236622243569\n",
      "train loss:0.7663361617784388\n",
      "train loss:0.676344978368529\n",
      "train loss:0.562264065721515\n",
      "train loss:0.5463296451911562\n",
      "train loss:0.6272549343984057\n",
      "train loss:0.6263599237899473\n",
      "train loss:0.6325328809116564\n",
      "train loss:0.6408256471845408\n",
      "train loss:0.6027754790782448\n",
      "train loss:0.7628536330121016\n",
      "train loss:0.8697464657074114\n",
      "train loss:0.621343540705755\n",
      "train loss:0.6967632145329632\n",
      "train loss:0.8443976370775675\n",
      "train loss:0.626081740807666\n",
      "train loss:0.5986302210086136\n",
      "train loss:0.5886712901006627\n",
      "train loss:0.6727039982451621\n",
      "train loss:0.6794429142652393\n",
      "train loss:0.810732461722455\n",
      "train loss:0.7579497696376335\n",
      "train loss:0.6695580339261687\n",
      "train loss:0.6473532526998244\n",
      "train loss:0.5193234023197488\n",
      "train loss:1.0259301230295756\n",
      "train loss:0.7228428876226128\n",
      "train loss:0.6305413507427997\n",
      "train loss:0.6615247063337537\n",
      "train loss:0.5647216500939758\n",
      "train loss:0.8237583614623474\n",
      "train loss:0.7068564192007663\n",
      "train loss:0.7496209964752576\n",
      "train loss:0.8676895392159949\n",
      "train loss:0.6791660495009749\n",
      "train loss:0.6761988155990342\n",
      "train loss:0.6898611270781161\n",
      "train loss:0.6830918677598865\n",
      "train loss:0.6222033627169862\n",
      "train loss:0.7540912098073939\n",
      "train loss:0.6909877812418608\n",
      "train loss:0.6653399915356512\n",
      "train loss:0.7179635265934438\n",
      "train loss:0.6818153843679755\n",
      "train loss:0.7371957486744135\n",
      "train loss:0.6202902103875243\n",
      "train loss:0.6382925854683367\n",
      "train loss:0.601894967426685\n",
      "train loss:0.6986021453165862\n",
      "train loss:0.8039449003076325\n",
      "train loss:0.6349156715568878\n",
      "train loss:0.5333372067318475\n",
      "train loss:0.8525611058325039\n",
      "train loss:0.5825641025932278\n",
      "train loss:0.7005053715739868\n",
      "train loss:0.5328509226482507\n",
      "train loss:0.6215031761665597\n",
      "train loss:0.7421886151655843\n",
      "train loss:0.6661684351130438\n",
      "train loss:0.6980192946036752\n",
      "train loss:0.610698349661938\n",
      "train loss:0.6503130276062707\n",
      "train loss:0.606711469458626\n",
      "train loss:0.5974866798178882\n",
      "train loss:0.7593283265970117\n",
      "train loss:0.8499643314045982\n",
      "train loss:0.5523526954753699\n",
      "train loss:0.7754800874057175\n",
      "train loss:0.5971103942905132\n",
      "train loss:0.6193426788273952\n",
      "train loss:0.59227497407301\n",
      "train loss:0.6334674661392544\n",
      "train loss:0.6104382941424804\n",
      "train loss:0.7269704874387205\n",
      "train loss:0.6601786465667675\n",
      "train loss:0.7470792761255869\n",
      "train loss:0.7140023678485676\n",
      "train loss:0.7890951099827112\n",
      "train loss:0.6298559052542743\n",
      "train loss:0.6074600461229818\n",
      "train loss:0.6656697149136208\n",
      "train loss:0.7676468799755444\n",
      "train loss:0.6092053642289069\n",
      "train loss:0.5302029692568025\n",
      "train loss:0.49363242698572907\n",
      "train loss:0.6255662514457268\n",
      "train loss:0.7056504907755812\n",
      "train loss:0.7407974946575244\n",
      "train loss:0.7153050645189315\n",
      "train loss:0.7343145939198424\n",
      "train loss:0.5472279323351422\n",
      "train loss:0.6323902475158235\n",
      "train loss:0.6071604067388823\n",
      "train loss:0.6478597710578572\n",
      "train loss:0.8481754302821614\n",
      "train loss:0.6659281249768351\n",
      "train loss:0.6376983429476336\n",
      "train loss:0.6322417442202185\n",
      "train loss:0.7583195597439858\n",
      "train loss:0.7143021605518959\n",
      "train loss:0.6936913428492387\n",
      "train loss:0.6539848366764082\n",
      "train loss:0.7121443989564343\n",
      "train loss:0.5513717676248947\n",
      "train loss:0.684145325578613\n",
      "train loss:0.7513387082501158\n",
      "train loss:0.48727529977420864\n",
      "train loss:0.7063071180080764\n",
      "train loss:0.5481395339829165\n",
      "train loss:0.6660844450151341\n",
      "train loss:0.5302560077485285\n",
      "train loss:0.558275065711951\n",
      "train loss:0.7412063439825858\n",
      "train loss:0.5898625210215507\n",
      "train loss:0.7670311588631761\n",
      "train loss:0.6784667071118571\n",
      "train loss:0.8979393268640804\n",
      "train loss:0.6141868036375724\n",
      "train loss:0.8862565114771102\n",
      "train loss:0.6076281326520099\n",
      "train loss:0.65620751511292\n",
      "train loss:0.7476667402212682\n",
      "train loss:0.6143724137526995\n",
      "train loss:0.7439108674966652\n",
      "train loss:0.7323519965957864\n",
      "train loss:0.628224106025877\n",
      "train loss:0.6357136037010309\n",
      "train loss:0.7006502479890315\n",
      "train loss:0.6814051238758668\n",
      "train loss:0.7662817794629926\n",
      "train loss:0.7706551186804981\n",
      "train loss:0.7971507588964178\n",
      "train loss:0.7137736426185681\n",
      "train loss:0.7483344575899454\n",
      "train loss:0.6055281199723836\n",
      "train loss:0.6030364022058778\n",
      "train loss:0.7274139390161075\n",
      "train loss:0.5594275583684574\n",
      "train loss:0.7978454858369106\n",
      "train loss:0.6370747359614419\n",
      "train loss:0.713582702541825\n",
      "train loss:0.7813663212285076\n",
      "train loss:0.5194385539052749\n",
      "train loss:0.570961045978186\n",
      "train loss:0.6175132477432634\n",
      "train loss:0.6249921353120523\n",
      "train loss:0.6753653793251252\n",
      "train loss:0.7069259759023625\n",
      "train loss:0.7852771165394951\n",
      "train loss:0.6003031124462428\n",
      "train loss:0.7294515146080062\n",
      "train loss:0.6077041924127742\n",
      "train loss:0.7008891467334295\n",
      "train loss:0.587582874850903\n",
      "train loss:0.6236581086058185\n",
      "train loss:0.753107484479917\n",
      "train loss:0.760735101029\n",
      "train loss:0.7456074968496845\n",
      "train loss:0.6317349273712666\n",
      "train loss:0.5667761926491832\n",
      "train loss:0.6034835919763818\n",
      "train loss:0.5854020971471963\n",
      "train loss:0.531644957839005\n",
      "train loss:0.6412102125441318\n",
      "train loss:0.6080296917448063\n",
      "train loss:0.648885470544889\n",
      "train loss:0.7957669784629984\n",
      "train loss:0.6659863327467154\n",
      "train loss:0.6684666694956597\n",
      "train loss:0.7027083286137232\n",
      "train loss:0.6328473211475167\n",
      "train loss:0.7794807260218863\n",
      "train loss:0.8093704813746703\n",
      "train loss:0.5944846418193459\n",
      "train loss:0.6265574460644876\n",
      "train loss:0.6087272052618008\n",
      "train loss:0.8185715071224656\n",
      "train loss:0.5971709647047275\n",
      "train loss:0.6908296400372242\n",
      "train loss:0.6612204737298474\n",
      "train loss:0.5877064674399416\n",
      "train loss:0.738709543657064\n",
      "train loss:0.6971077913032621\n",
      "train loss:0.7452503461815917\n",
      "train loss:0.6790476722926586\n",
      "train loss:0.6798668171711378\n",
      "train loss:0.6379092852659344\n",
      "train loss:0.8887761787503072\n",
      "train loss:0.7625392293307379\n",
      "train loss:0.6659596047072796\n",
      "train loss:0.6956073839643989\n",
      "train loss:0.5363115915296818\n",
      "train loss:0.6167465703905074\n",
      "train loss:0.6451707985023118\n",
      "train loss:0.6561794472902389\n",
      "train loss:0.7513054433610484\n",
      "train loss:0.6594423988841899\n",
      "train loss:0.570491903856053\n",
      "train loss:0.7363421589363058\n",
      "train loss:0.7043778630477264\n",
      "train loss:0.6941750104357781\n",
      "train loss:0.6168132658444826\n",
      "train loss:0.6734626418771329\n",
      "train loss:0.6573397596361928\n",
      "train loss:0.7008661480477191\n",
      "train loss:0.6901358711290088\n",
      "train loss:0.7120335097912792\n",
      "train loss:0.5899506815186496\n",
      "train loss:0.5405439872861652\n",
      "train loss:0.605532501166697\n",
      "train loss:0.6260174381440732\n",
      "train loss:0.7048230885255728\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.597\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAt1UlEQVR4nO3deXxc9Xnv8c+jfbMlS14leRG2MTYYbJANhCUQAsaEsjWhQMlNkyYODeSS3osLlCYhpWnpdZNLuUmgJKVpNpIQA4bgBMK+GiPbsuUNLK9avMiSJVu7NPrdP87YHsuj0djS0Yw13/frNa+ZOcucR8fj3zPnd37nOeacQ0REEldSrAMQEZHYUiIQEUlwSgQiIglOiUBEJMEpEYiIJDglAhGRBOdbIjCzJ81sn5mt72O+mdmjZlZpZuvM7Fy/YhERkb75eUTwU+DqCPMXAtODj0XAYz7GIiIiffAtETjn3gIaIixyPfAz51kB5JnZBL/iERGR8FJiuO0ioCrkfXVw2u7eC5rZIryjBrKzs88744wzhiRAEZHhYtWqVfudc2PCzYtlIrAw08LWu3DOPQE8AVBaWurKysr8jEtEZNgxs519zYvlqKFqYGLI+2KgNkaxiIgkrFgmgueB/xEcPXQB0OScO65bSERE/OVb15CZPQVcBow2s2rg20AqgHPucWA5cA1QCbQCX/QrFhER6ZtvicA5d2s/8x1wp1/bFxGR6OjKYhGRBKdEICKS4JQIREQSnBKBiEiCUyIQEUlwSgQiIglOiUBEJMEpEYiIJDglAhGRBKdEICKS4JQIREQSnBKBiEiCUyIQEUlwSgQiIglOiUBEJMEpEYiIJDglAhGRBKdEICKS4JQIREQSnBKBiEiCUyIQEUlwSgQiIglOiUBEJMEpEYiIJDglAhGRBKdEICKS4JQIREQSnBKBiEiCUyIQEUlwSgQiIglOiUBEJMEpEYiIJDglAhGRBKdEICKS4JQIREQSnK+JwMyuNrOPzKzSzO4LMz/XzF4ws7VmtsHMvuhnPCIicjzfEoGZJQM/BBYCs4BbzWxWr8XuBDY6584BLgO+Z2ZpfsUkIiLH8/OIYD5Q6Zzb5pzrBH4NXN9rGQeMMDMDcoAGoNvHmEREpBc/E0ERUBXyvjo4LdQPgJlALVAB3O2c6+n9QWa2yMzKzKysrq7Or3hFRBKSn4nAwkxzvd4vAMqBQmAO8AMzG3ncSs494Zwrdc6VjhkzZrDjFBFJaH4mgmpgYsj7Yrxf/qG+CDzjPJXAduAMH2MSEZFeUnz87A+B6WZWAtQAtwC39VpmF3AF8LaZjQNmANt8jElEZMg9t6aGJS99RG1jG4V5mSxeMIMb5vbuKY8d3xKBc67bzO4CXgKSgSedcxvM7I7g/MeBh4CfmlkFXlfSvc65/X7FJCIy1J5bU8P9z1TQ1hUAoKaxjfufqQCIm2Tg5xEBzrnlwPJe0x4PeV0LXOVnDCIisbTkpc1HksBhbV0Blrz0UWIkAhGRRLV9fwvLymuoaWwPO7+msY2vP7WGc4pzmV2Uy5lFueSkx6ZJViIQERkk+w6188La3TxfXsPa6ibMIC0lic7u40bFk5GaxKodDbyw1htDYwZTx+RwdlEus4tzObs4l1kTcslMS/Y9biUCEZEBONjexUvr97CsvJb3tu6nx8GZhSP5+2vO4M/OKeSDbQ3HnCMAyExN5l9ums0Nc4uoO9TB+pom1lU3UVHTyNuV+3lmTQ0AyUnG9LE5nF2cy+ziPC48LZ9pY0cM+t9gzvUe2h/fSktLXVlZWazDEJEE1t4V4I2P6lhWXsOrm/fR2d3DpPwsrp9TyPVzCo9rrE9k1JBzjr0HO1hX3UhFMEGsq27kQGsXd3xyKvctPLkR9ma2yjlXGnaeEoGISP8CPY4PttWzrLyW5et3c6i9m9E5aVx7ttf4z5mYh1ctZ/A556hpbCMlKYnxuRkn9RmREoG6hkRk2Iv2F3lPj2PfoQ521rews6GVqoZWdta3srOhlR37W2hq6yI7LZkFZ43n+jlFXDS1gJRk/6v5mxnFo7J8+3wlAhGJe+1dAV7asIfWzgBZaclkpCaTlZZMZmoymcHnrLQUMlOTyUhLIi056civ83Dj+O9duo6NtU0U5mWys6GVXcHGvqqhlY6QE7tJBkWjMpmUn8U1sydw0bQCPj1zHBmp/p/AHUpKBCISt5o7uvnlip385J3t1B3qiHq95CQ7kiQaWjoJ9BzbBd7R3cMTb28HICstmUn5WZw2OpvLZ4xhUkE2k/KzmJyfRdGoTFKH4Bd/rCkRiEjcaWjp5Kfvbuen7+3gYHs3F08bzSN/MYfTxmTT2hmgrTNAW9fxz62dAdq7ArR2dtPW2UNbV4CnVu4Kuw0DVj7waUbnpPnWt3+qUCIQkbixp6mdH7+9jV99sIu2rgALzhzH1y6bxjkT8076M9/6uI6axrbjphfmZTJmRPoAoh0+lAhEJOa272/hP97cytLV1fQ4uH5OIX/zyalMHzfwMfOLF8wIO45/8YIZA/7s4UKJQERiZmPtQX70RiXLK3aTkpzELfMmsejS05iYP3gjZA6PDorn6p+xpkQgIr7rPXzzz88roqK6idc/qiMnPYVFl07lSxdPYeyIkxsj358b5hap4Y9AiUAkAQxGPfyugDesMtmMpKToT66GG7756KuVZKclc89Vp/P5C6eQm5l6QrHI4FIiEBnmvIZ4HW1dXkNe09jG3/1uLR9sr2fGuBG0dAY41N5Nc0cXze3dNHd0B98HH+3dHOroPqZwmhmkJBlJZiQnHX0cnpaS5CWLlCSj+kAb3T3HVzAYmZnKXZ+aPmT7QfqmRCAyDDW1dlFe3ciaXQd47I2tx1wkBdAZcDy1surI+7SUJEakp5CTkUJOuvcYPzLj6PuMFLLTUjAg4ByBnmMf3T2OHhd87jn2eUd9a9gY9zSFL88sQ0+JQOQU1x3oYfOeQ5RXNbJmVyNrqg6wra4F8H6591VOzIBV37yS7PRk0lP8u1J21c4DfQ7flPigRCAyBAbznrV7mtoprzrgNfq7vAqVh/vfR+ekMWfiKP783GLmTsxjdnEuVz/ydp8NcX522oD+rmho+Gb8UyIQiUJrZzfPrakl0NNDdvrR7pIR6alHuk9GZKSQnpJ03FWq/d2ztqfHcaijm6bWLpravEdjW+eR14en72/uZENtE7uDXSppyUmcWTSSW+ZPZO6kUcydmEfxqMzjth/rhljDN+OfylCL9OOtj+t44LkKqhqO/1XdW0qSHdPPnpOeQkVN03F99ODVw8lJT+FQexdhzqUekZaSRF5mKnlZqZwxfiRzJ+UxZ2IeswpHRt2lM5hHJHJqUhlqkZPQ0NLJP/1+I8+sqeG0Mdk89ZULmD4uJ8zImq4jI2taQkbZHF4uXBIAr7799XMKyctMZWRmKrmZqeRlpZF75LX3PBiVLjWOXiJRIhDpxTnHc+U1PPT7TRxs6+Lrn5rGnZdPO9Igj845sfo0Fz38Wtg++qK8TP7x+rMGJWaRgVAiEAlR1dDKA8+t562P65g7KY+HbzqbGeMHVu8m1n30Iv1RIhDBG4L50/d28L2XPybJ4DvXncntF0wm+QSuoO2LTpZKvFMikIS3obaJ+5ZWUFHTxBVnjOWhG84a9DHu6qOXeKZEIAmrvSvAI69s4cdvb2NUVir/79a5XHv2hIS/SYkkHiUCSUjvVu7n75+tYGd9KzeXFvP318wkL8v/i6tE4pESgcQ95xyrdzXy5sd1pKckkZ+dRn52GgVHntMZkZESsSJm6Dj6zLRkWjsDTC7I4ldfPp9PTBs9hH+NSPxRIpC4tWXvIZ4rr2FZeS3VB9oi1s1JTjJGZR1NDvk5aeRnea+rD7Ty/NpaugLeyq2dAVKSjLsun6YkIIISgcSZ2sY2nl9by7LyWjbtPkiSwUXTRvO3nz6dq84cR2pyEg0tnTS0dFLf0klDSwf1zZ0caA1Oa/aeN9UepKG1k8bWrrDb6e5xPPLKFj5XOnGI/0KR+KNEIDHX2NrJixW7WVZey8rtDQDMmZjHg382i8+cXXjcDcYL8zKjHtXTHehh+gN/INyBRG2Yi7xEEpESgQyJ3rVu7r5iOhlpyTxfXsObH9fRFXBMHZPN/77ydK6bU8jkguxB2W5KchKFeZkqgywSgRKB+C5c9c2/W7oOgPEjM/jiRSVcd04hZxaO9GXopq7sFYlMiUB809Pj+HjfIb79/IZjGuHDRuek8e59nxqUq3cj0ZW9IpH5mgjM7Grg34Fk4CfOuYfDLHMZ8AiQCux3zn3Sz5jEP92BHjbtPsQH2+v5YHsDH+5o6PNkLUB9c6fvSeAwXdkr0jffEoGZJQM/BK4EqoEPzex559zGkGXygB8BVzvndpnZWL/ikcHXFehhXXUTK7c38MH2esp2HKC5oxuAyQVZXDVrHPNLCljy0mb2Huw4bn310YvEBz+PCOYDlc65bQBm9mvgemBjyDK3Ac8453YBOOf2+RiPDFB7V4DyqsYjDf/qnY1Hunymjc3h+jmFzC/J5/ySAsbnZhxZLyXJ1EcviWvJdGgJ07Rlj4XFW4Y+njD8TARFQFXI+2rg/F7LnA6kmtkbwAjg351zP+v9QWa2CFgEMGnSJF+ClfACPY73tu7n6bJqXtqwh47uHszgjPEj+Yt5Ezm/JJ95JfkRa/Srj15iKtYNcbhtH57eE4D2JmhvhLYD0NZ47Ou2A8H3wcdZN8G8vx70EP1MBOE6f3sP504BzgOuADKB981shXPu42NWcu4J4AnwblXpQ6zSy876Fn63qpqlq6qpbWonNzOVm0sn8snTxzBvSj65Wakn9Hnqo4+hWDeEg6G7E/ZthEAnJKdBSnrIczqkpHnPyWmQlHTsupEaYr90tkBjFTRVRV7uHws4vlkMkZIBmaMgIw8y88CS+l52AKJKBGa2FHgS+INzLvx9945XDYRetlkM1IZZZr9zrgVoMbO3gHOAj5Eh19rZzfKKPTxdVsUH2xswg0umj+HvPzOTT88cNyi3TJQYiEVDOFBtB6BqJexaAVUfQM0q6G6Pbt2k1KOJIrmfQoJvLvEa2NDG9vDrjFxI7qOJbGv0GvnGXUcb/MZd3qOpClrro4v10sXe9jLzgtsfdWwMqRmR1x8k0R4RPAZ8EXjUzJ4Gfuqc29zPOh8C082sBKgBbsE7JxBqGfADM0sB0vC6jv5vtMHLwDnnWLXzAE+XVfP7dbW0dAaYUpDF4gUzuOncIibk6oTusLbyx9DdAYEO71f3Mc8d3i/ww8+BLhgxDkZNgVElkF/iPWeOgkjXf/R3ROIcNGzzGvzDDX9dsHlJSoHxZ0Ppl6B4HqSPDB9bpL9hzc/7ju31f4q8f9JHHm2kM3K9BNW4CzoOHrtcSibkTYTciVA4B/ImQe4kb9qTC/r+/E89EHn7QySqROCcewV4xcxygVuBP5lZFfBj4BfOuePGCDrnus3sLuAlvOGjTzrnNpjZHcH5jzvnNpnZH4F1QA/eENP1g/KXyRG9r+pdvGAGF5xWwNLVXtfPtv0tZKUl85nZE/hc6UTmTRmlmvyDaai6Znp6oHEn7P/Ya0jrPvIekSy/59j3ob+mU9IhOTXY9ZIOScmwZx007z12nfRcyJ8SkhxCXo8sinxE8pvbYdcHR5dJz4WJ82H2Z2HiBVB0HqRlnczeOCpSIviHupA++AORX7c3eQ395E94z3nBhj53EmSPjpwM41zU5wjMrAC4Hfg8sAb4JXAx8AXgsnDrOOeWA8t7TXu81/slwJITCVqiF+6q3v/123J6gt2S86fk8zeXTeWa2RPITtf1hcfp6fEav8o/wc73vQYxq8B7ZI+GrNHB54Kjz2m9ymMMdtdMoBsObA829puhLtjw798C3SGlNHLGwZh+RmbdUxm5fz2czhY4sMN7NGz3YmnYDnsqYPOL0BPyuzCpn3NJeypg6qdg0vlewz/mjOhiGCwpaZAz1nv4JXts3z8E4kS05wieAc4Afg78mXNud3DWb8yszK/gZOCWvPTRcVf19jgYkZ7CC1+/mCmjB6emz7DS2gBbX4PKV6Dy1aP/icedBRjUroGW/cc2eKFSMo9NDpG88qA3csT1QE+397qnG1wg+DrkfXen14VSX3nstnMneg1+yaUw+nSvMR1zutdlA/Bgbt/bzxkT7V45Ki0bxp3pPXrrCUBTdTBRBBPEu4/0/Vl3rz3x7Z+oWDfEp8AJ+Wh/Av7AOfdauBnOudJBjEcG0abdB8MWWwNo7uhWEjispwd2l3sN/5Y/QU2Z1zBnjoKpV8D0K73n0EbTOa+fuGW/d2KwZT+07j/6PnRaJO/9wOtySUoBSw6+Dn2fdPR1cqrX3XL6gmBjP8Nr+NNzIm9jKBvCpGQYNdl7ECwSECkRDIVToCGOtWgTwUwzW+2cawQws1HArc65H/kWmZwU5xxvflzHT97ezjuV+zHCD06L6qrewyfxtr4GW1+H2tUwshBGz/AaocONUd4krwHoy8n0kff0wMFq79dv/Vav26Opyjt5lzPW6/YYMT74OvickRu+n7av7aePhBnXwNZXoaUOMCic643kmHYlFJ3b999l5m0vIxcKpvb9t0PkX+Tf6idRDAY1hNKPaBPBV5xzPzz8xjl3wMy+glceQuJAe1eAZeU1/OTt7WzZ18y4ken83dUzyMtM5aHfb4r+qt7WBtj+ptfwb30dmnZ50/Mmw5RLvBOFW1+Dtb86uk5KBoyeHvIrNZgk8ku8X7GR+shbG7xGvr4y5LEVGrYeO1wwLcdLOB3N0LzHGynSW0rG0SQR+uhr+x0HYcvLMO0Kr+GfdkX/XTly4mLdNSP9ijYRJJmZOefdKDBYR0h3+o4DDS2d/Pz9nfx8xQ72N3cyc8JIvn/zOVx7diFpKUmwZDq3Je/zxm2FemUszN3i9TtXrww2/K95/d8479dyyaVw8d3eybz8045dv63x+NEpuz6AiqePLpOUCgXTIv8B/6ckZPkUb7RJwTSYermXXAqmeY+ccUd/7TvnjeJo3uclpkN7vefQR8M22PketDVE3v7iyshHM4Mh0RtCHZHEvWgTwUvAb83scbyehjuAP/oWlfRra10z//nOdpauqqaju4fLZ4zhK5ecxoVTC44d+hnp1/gvb4Yd70BXi9cHXTwPLrvPa/gLz+37YhrwxlZPnO89QnU0Q/2WYHI4PKJlU9+fs+Cfjzb2eZMjb/Mws+CFN6P6HxXT3Qn/FOGEqN9JANQQStyLNhHcC3wV+Bu80hEvAz/xKygJzznHim0N/OTtbby6eR9pKUncNLeIv764hOnjRpz4B9ZXwpxbvYZ/ysVef/dAped4/eyFc49Oi9RHfuGdA99mJCk6cBXpT7QXlPXgXV38mL/hSDgtHd28sLaWX3ywk/U1B8nPTuPuK6bz+QsnRyz2huunLNP/XD24gYrIKSna6wimA/8CzAKOFL9wzp3W50oyIM451lY38euVu3hhrVf6YfrYHP75xtncdG5R5Lo/gS5Y/wy8++9DF3Akse4jj/X2ReJctF1D/wV8G68O0OV4dYdO3eup41hTaxfPldfw1MpdbN5ziMzUZK49ewK3zJ/EuZPyIpd+6GiG1T+D93/oDb0cM3PoAo8k1n3ksd6+SJyLNhFkOudeDY4c2gk8aGZv4yUHGSDnHCu3N/CbD6t4sWI3Hd09zC7K5bs3nsV15xQyIqOfy/Sb62Dlf3gFxNobYfJFcO33vSGR35uhX8MiElG0iaDdzJKALcFCcjWAWpIohSv6dsPcIuqbO1i6uppff1jFtroWRqSn8LnSYm6ZN4mziqI4cVu/Fd7/AZT/yquyOPNa+MTdMHHe0WX0a1hE+mGuvxOKgJnNAzYBecBDwEhgiXNuha/RhVFaWurKyk6d8ka9i74BpCUnMWvCCDbsPkhXwFE6eRS3zJ/EZ2ZPIDMtiuGMNau8/v+Nz3sXbJ1zK3zi6964exGRMMxsVV8lgfo9IghePHazc24x0Ix3fkCiFK7oW2egh3U1TXzpohL+Yt7E6IZ+9vR4pRDe/XfY8bZXrvfiv4Xz7/BqxIuInKR+E4FzLmBm54VeWSzRq+2j6Jtz8A/Xzoq8snNeCeSKp6FiKRyqhRGFcNV34bwvQPpJXDsgItJLtOcI1gDLgncnazk80Tn3jC9RDSP52WnUtxxfFydi0beGbV7DX/E07P/IK70w7Uq46iGYeZ0ukhKRQRVtIsgH6oFPhUxzgBJBH5xzPPHWNupbOo+rABq26FvzPtjwrNf4V3/oTZt8EVxwB8y6AbLyhyhyEUk00V5ZrPMCJ6C1s5t7l1bwwtpa1mXfycjAgeMXemUszFzl3dGp4mnY9oZ385Fxs+HT34Gz/ty7DZ6IiM+ivbL4vwhT1t4596VBj+gUV9XQyld+VsZHew9x79VnMPKNMEkAvLH9/zbdK7WcNwku/gbM/hyMjZOLwEQkYUTbNfT7kNcZwI1A7eCHc2p7Z8t+7npqNT09jv/6q3lcNmMsvBFhhbmf9xr/ifNP6Rtfi8ipLdquoaWh783sKeAVXyI6BTnn+PHb23j4D5uZNjaHJz5fGt1tID/zb/4HJyLSj2iPCHqbDkwazEBOVW2dAe5duo7n19ZyzezxLPnsOWSnp3hX+q58ItbhiYj0K9pzBIc49hzBHrx7FCS0qoZWvvrzVWzac5DFC2bwtcumepX41j8DrzwIjTtjHKGISP+i7RrSlUu9vFu5n7t+tZpAj+PJv5rH5TPGerdqfPkBb/jn2DPh9mfg2TtU9E1E4lq0RwQ3Aq8555qC7/OAy5xzz/kXWnxyzvGf72znn5dvOno+IGkv/HYxbHwOcsbDdT+AObd5t0FU0TcRiXPRniP4tnPu2cNvnHONZvZt4DlfoopTbZ0B7ntmHcvKa1l41niWXDuJnBXf9c4FJKfCZffDhXd5t2sUETlFRJsIkgaw7rDQ2NrJbT/+gE17DnLvladxR9Zr2OM3QXsTzL0dLn8ARk6IdZgiIics2sa8zMy+D/wQ76Tx14FVvkUVh16s2M3G3U08e1k9c9c/AAe2ezd9v/IhGH9WrMMTETlp0SaCrwPfBH4TfP8y8A++RBSntmyv4pmMh5i7YjOMnQW3L4Vpn451WCIiAxbtqKEW4D6fY4lro3e+wLlshmv+DUq/5J0IFhEZBsL1/R/HzP4UHCl0+P0oM3vJt6jiTFtngMLmDbSk5sO8LysJiMiwElUiAEY75xoPv3HOHSCB7lm8obaJc6ySljFzVRNIRIadaBNBj5kdKSlhZlMIU410uNq0vYqpSbvJKpkf61BERAZdtCeLHwDeMbM3g+8vBRb5E1L8ad66AoCcqRfEOBIRkcEX7cniP5pZKV7jXw4sA8LfjHcYSt+7hh6MpMJzYx2KiMigi/Zk8ZeBV4H/HXz8HHgwivWuNrOPzKzSzPocdWRm88wsYGafjS7sodPU2sWU9k00ZpVAxshYhyMiMuiiPUdwNzAP2OmcuxyYC9RFWsHMkvEuQFsIzAJuNbNZfSz3r0BcjkJaV32AOUmVdE44L9ahiIj4ItpE0O6cawcws3Tn3GZgRj/rzAcqnXPbnHOdwK+B68Ms93VgKRCmRGfs7ajcQL41M3Kazg+IyPAUbSKoDl5H8BzwJzNbRv+3qiwCqkI/IzjtCDMrwrvt5eORPsjMFplZmZmV1dVFPBAZdB07VgKQVXL+kG5XRGSoRHuy+MbgywfN7HUgF/hjP6uFG3Dfe8jpI8C9zrmARRif75x7AngCoLS0dEiHrY7cX06HZZA+RjeVF5Hh6YQriDrn3ux/KcA7ApgY8r6Y448iSoFfB5PAaOAaM+uOl/sc7DvYzundH9GQfyYTkhOq2KqIJBA/W7cPgelmVgLUALcAt4Uu4JwrOfzazH4K/D5ekgDAup11XGI7OVB8RaxDERHxjW+JwDnXbWZ34Y0GSgaedM5tMLM7gvMjnheIB3s+Wkm6dTPq9ItiHYqIiG987e9wzi0HlveaFjYBOOf+ys9YToar/hCA9CkqLSEiw1e0o4YSjnOOgsYKmlLGwMjCWIcjIuIbJYI+7GpoZVbPFpoKzol1KCIivlIi6MOmrduZkrSXtMnzYh2KiIivlAj60Pjx+wCMPkMnikVkeFMi6EPK7tUESCKlaG6sQxER8ZUSQRjdgR7GN6+nLnMqpOfEOhwREV8pEYRRue8gs6mkbeycWIciIuI7JYIwtm9eR661kn2aKo6KyPCnRBBG8zbv1pSjZ3wixpGIiPhPiSCM7H1raLUsksb2d8sFEZFTnxJBLx3dASa1b2LfiFmQlBzrcEREfKdE0MvmqjpmsIvABN2oXkQSgxJBL7Wb3ifVAuSp4qiIJAglgl46d3oVR/NPvzDGkYiIDA0lgl5y69eyP3kcNmJcrEMRERkSSgQhmju6mda1mYZRZ8c6FBGRIaNEEGLzlkqKbT9JE0tjHYqIyJBRIgixf/O7AIxVxVERSSBKBCGspoxukhl5mo4IRCRxKBGEKGiqoCZ9KqRmxjoUEZEho0QQVH+wlRmBSppH69aUIpJYlAiCKjetYYS1kTb5/FiHIiIypJQIgpq2eLemLDzr4hhHIiIytJQIgtL3rOIQ2WSPV8VREUksSgSAc44JzRuozZ4FSdolIpJY1OoBu+vqmep20T5ON6oXkcSjRABUrX+XZHPkTFOhORFJPEoEQOv2lQAU60SxiCQgJQIgu24NtUkTSB85NtahiIgMuYRPBD09jsltm9g38qxYhyIiEhMJnwh27tjCOGvAFZ0X61BERGIi4RPB3o3vAJB/+idiHImISGwkfCII7Cqj06VQPFOlJUQkMSV8Isg7sJYdadNITsuIdSgiIjHhayIws6vN7CMzqzSz+8LM/0szWxd8vGdmQ1r6s6urk5LOLTTq1pQiksB8SwRmlgz8EFgIzAJuNbNZvRbbDnzSOXc28BDwhF/xhLNz0yqyrIPkSfOGcrMiInHFzyOC+UClc26bc64T+DVwfegCzrn3nHMHgm9XAMU+xnOc+o/eA2D8LN2aUkQSl5+JoAioCnlfHZzWl78G/hBuhpktMrMyMyurq6sbtACTaspoYASFU2YO2meKiJxq/EwEFmaaC7ug2eV4ieDecPOdc08450qdc6VjxowZtADHHqxgV8ZMTBVHRSSB+dkCVgMTQ94XA7W9FzKzs4GfANc75+p9jOcYbYcOMDFQTcuYOUO1SRGRuORnIvgQmG5mJWaWBtwCPB+6gJlNAp4BPu+c+9jHWI6zq+IdksyRUXLBUG5WRCTupPj1wc65bjO7C3gJSAaedM5tMLM7gvMfB74FFAA/MjOAbudcqV8xhTq0dQUAk1RxVEQSnG+JAMA5txxY3mva4yGvvwx82c8Y+pK+dw07KGLK2HGx2LyISNzwNRHELecoatnA5px5TIl1LCIyJLq6uqiurqa9vT3WofgqIyOD4uJiUlNTo14nIRPBwT3byHeNdI0/N9ahiMgQqa6uZsSIEUyZMoVgV/Sw45yjvr6e6upqSkpKol4vIcdN1qx/G4CRujWlSMJob2+noKBg2CYBADOjoKDghI96EjIRdOxYSbtL5bQzVXFUJJEM5yRw2Mn8jQmZCHL2l7MleRq5I7JiHYqISMwlXiIIdFHcsYX9ubNjHYmIxLHn1tRw0cOvUXLfi1z08Gs8t6ZmQJ/X2NjIj370oxNe75prrqGxsXFA2+5PwiWChm2ryaATV6xbU4pIeM+tqeH+ZyqoaWzDATWNbdz/TMWAkkFfiSAQCERcb/ny5eTl5Z30dqORcKOG9m56l3xg9AzdmlIkUX3nhQ1srD3Y5/w1uxrpDPQcM62tK8Df/W4dT63cFXadWYUj+fafndnnZ953331s3bqVOXPmkJqaSk5ODhMmTKC8vJyNGzdyww03UFVVRXt7O3fffTeLFi0CYMqUKZSVldHc3MzChQu5+OKLee+99ygqKmLZsmVkZmaexB44VsIdEfRUraTO5TJ9eu9bI4iIeHongf6mR+Phhx9m6tSplJeXs2TJElauXMl3v/tdNm7cCMCTTz7JqlWrKCsr49FHH6W+/vjSa1u2bOHOO+9kw4YN5OXlsXTp0pOOJ1TCHRHkH6igMvUMLkxPuD9dRIIi/XIHuOjh16hpbDtuelFeJr/56uAMO58/f/4xY/0fffRRnn32WQCqqqrYsmULBQUFx6xTUlLCnDlzADjvvPPYsWPHoMSSUEcErvUAE7qraSoY0jtiisgpZvGCGWSmJh8zLTM1mcULZgzaNrKzs4+8fuONN3jllVd4//33Wbt2LXPnzg17LUB6evqR18nJyXR3dw9KLAn1s3jf5vcYB6ROnh/rUEQkjt0w17uH1pKXPqK2sY3CvEwWL5hxZPrJGDFiBIcOHQo7r6mpiVGjRpGVlcXmzZtZsWLFSW/nZCRUIjiw5T3GOGPCTF1RLCKR3TC3aEANf28FBQVcdNFFnHXWWWRmZjJu3NGCl1dffTWPP/44Z599NjNmzOCCC4a2PL45F/amYXGrtLTUlZWVRb/CkunQsu/46dljYfGWwQtMROLapk2bmDkzMW5LG+5vNbNVfZX5H/7nCMIlgUjTRUQSzPBPBCIiEpESgYhIglMiEBFJcEoEIiIJbtgngvb0ghOaLiKSaIb9dQQZ92/juTU1g3phiIgMcz4MO29sbORXv/oVX/va10543UceeYRFixaRleXPPVSGfSKAwb8wRESGOR+GnR8uQ32yieD2229XIhARGTR/uA/2VJzcuv/1mfDTx8+GhQ/3uVpoGeorr7ySsWPH8tvf/paOjg5uvPFGvvOd79DS0sLNN99MdXU1gUCAb37zm+zdu5fa2louv/xyRo8ezeuvv35ycUegRCAiMgQefvhh1q9fT3l5OS+//DK/+93vWLlyJc45rrvuOt566y3q6uooLCzkxRdfBLwaRLm5uXz/+9/n9ddfZ/To0b7EpkQgIoknwi93AB7M7XveF18c8OZffvllXn75ZebOnQtAc3MzW7Zs4ZJLLuGee+7h3nvv5dprr+WSSy4Z8LaioUQgIjLEnHPcf//9fPWrXz1u3qpVq1i+fDn3338/V111Fd/61rd8j2fYDx8VETlh2WNPbHoUQstQL1iwgCeffJLm5mYAampq2LdvH7W1tWRlZXH77bdzzz33sHr16uPW9YOOCEREevOhMnFoGeqFCxdy2223ceGFXkn8nJwcfvGLX1BZWcnixYtJSkoiNTWVxx57DIBFixaxcOFCJkyY4MvJ4uFfhlpEBJWhTuwy1CIiEpESgYhIglMiEJGEcap1hZ+Mk/kblQhEJCFkZGRQX18/rJOBc476+noyMjJOaD2NGhKRhFBcXEx1dTV1dXWxDsVXGRkZFBcXn9A6SgQikhBSU1MpKSmJdRhxydeuITO72sw+MrNKM7svzHwzs0eD89eZ2bl+xiMiIsfzLRGYWTLwQ2AhMAu41cxm9VpsITA9+FgEPOZXPCIiEp6fRwTzgUrn3DbnXCfwa+D6XstcD/zMeVYAeWY2wceYRESkFz/PERQBVSHvq4Hzo1imCNgdupCZLcI7YgBoNrOPTjKm0cD+k1x3KMR7fBD/MSq+gVF8AxPP8U3ua4aficDCTOs9biuaZXDOPQE8MeCAzMr6usQ6HsR7fBD/MSq+gVF8AxPv8fXFz66hamBiyPtioPYklhERER/5mQg+BKabWYmZpQG3AM/3WuZ54H8ERw9dADQ553b3/iAREfGPb11DzrluM7sLeAlIBp50zm0wszuC8x8HlgPXAJVAK/BFv+IJGnD3ks/iPT6I/xgV38AovoGJ9/jCOuXKUIuIyOBSrSERkQSnRCAikuCGZSKI59IWZjbRzF43s01mtsHM7g6zzGVm1mRm5cGH/3evPnb7O8ysIrjt424HF+P9NyNkv5Sb2UEz+0avZYZ8/5nZk2a2z8zWh0zLN7M/mdmW4POoPtaN+H31Mb4lZrY5+G/4rJnl9bFuxO+Dj/E9aGY1If+O1/Sxbqz2329CYtthZuV9rOv7/hsw59yweuCdmN4KnAakAWuBWb2WuQb4A951DBcAHwxhfBOAc4OvRwAfh4nvMuD3MdyHO4DREebHbP+F+bfeA0yO9f4DLgXOBdaHTPs/wH3B1/cB/9rH3xDx++pjfFcBKcHX/xouvmi+Dz7G9yBwTxTfgZjsv17zvwd8K1b7b6CP4XhEENelLZxzu51zq4OvDwGb8K6mPpXES2mQK4CtzrmdMdj2MZxzbwENvSZfD/x38PV/AzeEWTWa76sv8TnnXnbOdQffrsC7jicm+th/0YjZ/jvMzAy4GXhqsLc7VIZjIuirbMWJLuM7M5sCzAU+CDP7QjNba2Z/MLMzhzYyHPCyma0KlvfoLS72H961KX3954vl/jtsnAteFxN8HhtmmXjZl1/CO8oLp7/vg5/uCnZdPdlH11o87L9LgL3OuS19zI/l/ovKcEwEg1bawk9mlgMsBb7hnDvYa/ZqvO6Oc4D/Bzw3lLEBFznnzsWrDnunmV3aa3487L804Drg6TCzY73/TkQ87MsHgG7gl30s0t/3wS+PAVOBOXj1x74XZpmY7z/gViIfDcRq/0VtOCaCuC9tYWapeEngl865Z3rPd84ddM41B18vB1LNbPRQxeecqw0+7wOexTv8DhUPpUEWAqudc3t7z4j1/gux93CXWfB5X5hlYv1d/AJwLfCXLtih3VsU3wdfOOf2OucCzrke4Md9bDfW+y8FuAn4TV/LxGr/nYjhmAjiurRFsD/xP4FNzrnv97HM+OBymNl8vH+n+iGKL9vMRhx+jXdCcX2vxeKhNEifv8Jiuf96eR74QvD1F4BlYZaJ5vvqCzO7GrgXuM4519rHMtF8H/yKL/S80419bDdm+y/o08Bm51x1uJmx3H8nJNZnq/144I1q+RhvNMEDwWl3AHcEXxveTXO2AhVA6RDGdjHeoes6oDz4uKZXfHcBG/BGQKwAPjGE8Z0W3O7aYAxxtf+C28/Ca9hzQ6bFdP/hJaXdQBfer9S/BgqAV4Etwef84LKFwPJI39chiq8Sr3/98Pfw8d7x9fV9GKL4fh78fq3Da9wnxNP+C07/6eHvXciyQ77/BvpQiQkRkQQ3HLuGRETkBCgRiIgkOCUCEZEEp0QgIpLglAhERBKcEoGIz8yrhvr7WMch0hclAhGRBKdEIBJkZreb2cpg3fj/MLNkM2s2s++Z2Woze9XMxgSXnWNmK0Jq+Y8KTp9mZq8EC96tNrOpwY/PMbPfmVf//5chVz4/bGYbg5/zbzH60yXBKRGIAGY2E/gLvAJhc4AA8JdANl5No3OBN4FvB1f5GXCvc+5svKtfD0//JfBD5xW8+wTe1ajgVZn9BjAL72rTi8wsH690wpnBz/knP/9Gkb4oEYh4rgDOAz4M3mnqCrwGu4ejBcV+AVxsZrlAnnPuzeD0/wYuDdaUKXLOPQvgnGt3R2v4rHTOVTuvgFo5MAU4CLQDPzGzm4Cw9X5E/KZEIOIx4L+dc3OCjxnOuQfDLBepJku4ksiHdYS8DuDdGawbrxLlUryb1vzxxEIWGRxKBCKeV4HPmtlYOHK/4cl4/0c+G1zmNuAd51wTcMDMLglO/zzwpvPuK1FtZjcEPyPdzLL62mDwnhS5ziuV/Q28uvsiQy4l1gGIxAPn3EYz+we8O0kl4VWZvBNoAc40s1VAE955BPDKSj8ebOi3AV8MTv888B9m9o/Bz/hchM2OAJaZWQbe0cTfDvKfJRIVVR8VicDMmp1zObGOQ8RP6hoSEUlwOiIQEUlwOiIQEUlwSgQiIglOiUBEJMEpEYiIJDglAhGRBPf/ARP4K8F3LWfhAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(3,32,32), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "\n",
    "# 피클로 저장\n",
    "train_acc_list_title = 'train_acc_list' + title +'.pickle'\n",
    "test_acc_list_title = 'test_acc_list' + title +'.pickle'\n",
    "# save\n",
    "with open(train_acc_list_title , 'wb') as fw:\n",
    "    pickle.dump(trainer.train_acc_list, fw)\n",
    "    \n",
    "\n",
    "# save\n",
    "with open(test_acc_list_title, 'wb') as fw:\n",
    "    pickle.dump(trainer.test_acc_list, fw)\n",
    "    \n",
    "#ploting 하기\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
